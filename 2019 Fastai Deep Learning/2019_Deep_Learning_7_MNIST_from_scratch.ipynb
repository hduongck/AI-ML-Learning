{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2019_Deep_Learning_7_MNIST_from_scratch.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hduongck/AI-ML-Learning/blob/master/2019%20Fastai%20Deep%20Learning/2019_Deep_Learning_7_MNIST_from_scratch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-elV2JWBcF6F",
        "colab_type": "text"
      },
      "source": [
        "[Video](https://youtu.be/nWpdkZE2_cc) / [Course Forum](https://forums.fast.ai/t/lesson-7-official-resources/32553)\n",
        "\n",
        "Welcome to lesson 7! The last lesson of part 1. This will be a pretty intense lesson. Don't let that bother you because partly what I want to do is to give you enough things to think about to keep you busy until part 2. In fact, some of the things we cover today, I'm not going to tell you about some of the details. I'll just point out a few things. I'll say like okay that we're not talking about yet, that we're not talking about yet. Then come back in part 2 to get the details on some of these extra pieces. So today will be a lot of material pretty quickly. You might require a few viewings to fully understand at all or a few experiments and so forth. That's kind of intentional. I'm trying to give you stuff to to keep you amused for a couple of months.\n",
        "\n",
        "![alt text](https://github.com/hiromis/notes/blob/master/lesson7/1.png?raw=true)\n",
        "\n",
        "I wanted to start by showing some cool work done by a couple of students; Reshama and Nidhin who have developed an Android and an iOS app, so check out [Reshma's post on the forum] about that because they have a demonstration of how to create both Android and iOS apps that are actually on the Play Store and on the Apple App Store, so that's pretty cool. First ones I know of that are on the App Store's that are using fast.ai. Let me also say a huge thank you to Reshama for all of the work she does both for the fast.ai community and the machine learning community more generally, and also the Women in Machine Learning community in particular. She does a lot of fantastic work including providing lots of fantastic documentation and tutorials and community organizing and so many other things. So thank you, Reshama and congrats on getting this app out there."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j3uVqAJ_csp7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%reload_ext autoreload\n",
        "%autoreload 2\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3rK-Es-tcZpV",
        "colab_type": "text"
      },
      "source": [
        "# MNIST CNN [2:04](https://youtu.be/nWpdkZE2_cc?t=124)\n",
        "\n",
        "We have lots of lesson 7 notebooks today, as you see. The first notebook we're going to look at is [lesson7-resnet-mnist.ipynb](https://github.com/fastai/course-v3/blob/master/nbs/dl1/lesson7-resnet-mnist.ipynb). What I want to do is look at some of the stuff we started talking about last week around convolutions and convolutional neural networks, and start building on top of them to create a fairly modern deep learning architecture largely from scratch. When I say from scratch, I'm not going to re-implement things we already know how to implement, but use the pre-existing PyTorch bits of those. So we're going to use the MNIST dataset. URLs.MNIST has the whole MNIST dataset, often we've done stuff with a subset of it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2yD-qCuGRVqx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from fastai.vision import *"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "naf406xUc46y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path = untar_data(URLs.MNIST)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JyZWapD8c8gH",
        "colab_type": "code",
        "outputId": "1650ffe4-43dd-4d01-e8dc-9bfc13b9eeea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "path.ls()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[PosixPath('/root/.fastai/data/mnist_png/training'),\n",
              " PosixPath('/root/.fastai/data/mnist_png/testing')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6_jqw-U9dE9D",
        "colab_type": "text"
      },
      "source": [
        "## More understanding Datablock\n",
        "\n",
        "In there, there's a training folder and a testing folder. As I read this in, I'm going to show some more details about pieces of the data blocks API, so that you see what's going on. Normally with the date blocks API, we've kind of said blah.blah.blah.blah.blah and done it all in one cell, but let's do it in one cell at a time."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_BbmuHlrdGpj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "il = ImageList.from_folder(path,convert_mode=\"L\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CCw2Y5JodZ8t",
        "colab_type": "text"
      },
      "source": [
        "First thing you say is what kind of item list do you have. So in this case it's an item list of images. Then where are you getting the list of file names from. In this case, by looking in a folder recursively. That's where it's coming from.\n",
        "\n",
        "You can pass in arguments that end up going to Pillow because Pillow (a.k.a. PIL) is the thing that actually opens that for us, and in this case these are black and white rather than RGB, so you have to use Pillow's **convert_mode='L'**. For more details refer to the python imaging library documentation to see what their convert modes are. But this one is going to be a grayscale which is what MNIST is."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rmNvcDGBdfzN",
        "colab_type": "code",
        "outputId": "37610cb1-ae63-416b-cb47-45a2b4b875e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "il.items[0]"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PosixPath('/root/.fastai/data/mnist_png/training/2/20247.png')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ryr3zqOdney",
        "colab_type": "text"
      },
      "source": [
        "So inside an item list is an **items** attribute, and the **items** attribute is kind of thing that you gave it. It's the thing that it's going to use to create your items. So in this case, the thing you gave it really is a list of file names. That's what it got from the folder."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2O8GgmzRdNdH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "defaults.cmap='binary'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g500VI7fd4mX",
        "colab_type": "text"
      },
      "source": [
        "When you show images, normally it shows them in RGB. In this case, we want to use a binary color map. In fast.ai, you can set a default color map. For more information about cmap and color maps, refer to the matplotlib documentation. And **defaults.cmap='binary'** world set the default color map for fast.ai."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HUAXJuwKd3db",
        "colab_type": "code",
        "outputId": "d3468c00-943f-4299-dc52-fbdd2f73b5ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "il"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ImageList (70000 items)\n",
              "Image (1, 28, 28),Image (1, 28, 28),Image (1, 28, 28),Image (1, 28, 28),Image (1, 28, 28)\n",
              "Path: /root/.fastai/data/mnist_png"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QLkRFDyoe0Bv",
        "colab_type": "text"
      },
      "source": [
        "Our image item list contains 70,000 items, and it's a bunch of images that are 1 by 28 by 28. Remember that PyTorch puts channel first, so they are one channel 28x28. **You might think why aren't there just 28 by 28 matrices rather than a 1 by 28 by 28 rank 3 tensor. It's just easier that way. All the Conv2d stuff and so forth works on rank 3 tensors, so you want to include that unit axis at the start, so fast.ai will do that for you even when it's reading one channel images**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wCPeUNuLeAgb",
        "colab_type": "code",
        "outputId": "726b6ef5-f7ad-4750-e97f-6059e23d7cab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        }
      },
      "source": [
        "il[0].show()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAMUAAADDCAYAAAAyYdXtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAA2FJREFUeJzt3VFum1AQQNG46r6SrCzJypyszP2s\ndMWrQAYD9TmfqJLtqleI6QCX2+32Avz1a+8vAEcjCghRQIgCQhQQooAQBcTvB3+e/xThSC5TB50p\nIEQBIQoIUUCIAkIUEKKAEAWEKCBEASEKCFFAiAJCFBCigBAFhCggRAEhCghRQIgCQhQQooAQBYQo\nIEQBIQqIRz9LlgW+v78XHR/5+vqa/Wev1+vk8be3t0WfeWbOFBCigBAFhCggRAFxud0e+nKhp36T\n0efn5+TxJdOhvXx8fEweH/2mk/AmI5hDFBCigBAFhCgg7D7dabSHNDVRWrqzdCQ/Pz97f4WHcaaA\nEAWEKCBEASEKCLtPd7pcJtdnVjG62+319XXy+Bp7SEt/z4P//azN7hPMIQoIUUCIAkIUEHafDmCv\nu9rOvIu1JWcKCFFAiAJCFBCigDB9utPoKd1Tjvbk7iXTp6N99y05U0CIAkIUEKKAcKF9pzNcgC55\nDM/I6Mam/5EzBYQoIEQBIQoIUUCYPj2BNdY5Tv4ar0WcKSBEASEKCFFAiALCA5afwJKHJp/8gclL\necAyzCEKCFFAiAJCFBB2nw5stLO0xp10Ly/nuGtwD84UEKKAEAWEKCBEAWH3aSNTE6K1pkZb2utV\nYzux+wRziAJCFBCigBAFhOnTnd7f3yeP/28vbh/tSY2eRn6SaZXpE8whCghRQIgCQhQQpk8znXnK\nNNpnWmKt/azr9Tp5fKe7AE2fYA5RQIgCQhQQLrRjtJ5wpBuBRva4iB0NGkaDiZGdbm5yoQ1ziAJC\nFBCigBAFhOlTnGGdYzRNGk2fjmTp3+/Ub13xd5o+wRyigBAFhCggRAFh+hRLXsS+tYPdkLOpJTtU\nK07fTJ9gDlFAiAJCFBCigDB9ii13n57s1VmbWXpX3z+mUqZPMIcoIEQBIQoIUUCYPsVoyrR0+mSi\ndAqmTzCHKCBEASEKCFFAmD7xzEyfYA5RQIgCQhQQooAQBYQoIEQBIQoIUUCIAkIUEKKAEAWEKCBE\nASEKCFFAiAJCFBCigBAFhCggRAEhCghRQIgCQhQQvx/8eZMPtIUjcaaAEAWEKCBEASEKCFFAiAJC\nFBCigBAFhCggRAEhCghRQIgCQhQQooAQBYQoIEQBIQoIUUCIAuIPulq5aU+IZhQAAAAASUVORK5C\nYII=\n",
            "text/plain": [
              "<Figure size 216x216 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "neYq9po2fQg9",
        "colab_type": "text"
      },
      "source": [
        "The **.items** attribute contains the things that's read to build the image which in this case is the file name, but if you just index into an item list directly, you'll get the actual image object. The actual image object has a show method, and so there's the image."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a4p0gexhfHgv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sd = il.split_by_folder(train='training',valid='testing')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IUXr70rnf2P1",
        "colab_type": "text"
      },
      "source": [
        "Once you've got an image item list, you then split it into training versus validation. You nearly always want validation. If you don't, you can actually use the **.no_split** method to create an empty validation set. You can't skip it entirely. You have to say how to split, and one of the options is **no_split**.\n",
        "\n",
        "So remember, that's always the order. First create your item list, then decide how to split. In this case, we're going to do it based on folders. The validation folder for MNIST is called **testing**. In fast.ai parlance, we use the same kind of parlance that Kaggle does which is the training set is what you train on, the validation set has labels and you do it for testing that your models working. The test set doesn't have labels and you use it for doing inference, submitting to a competition, or sending it off to somebody who's held out those labels for vendor testing or whatever. So just because a folder in your data set is called **testing**, doesn't mean it's a test set. This one has labels, so it's a validation set.\n",
        "\n",
        "If you want to do inference on lots of things at a time rather than one thing at a time, you want to use the **test=** in fast.ai to say this is stuff which has no labels and I'm just using for inference.\n",
        "\n",
        "[6:54](https://youtu.be/nWpdkZE2_cc?t=414)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KsfGygMjfcbp",
        "colab_type": "code",
        "outputId": "bdcbe9d6-6bb6-47b9-c4da-93815f78a6d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "sd\n"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ItemLists;\n",
              "\n",
              "Train: ImageList (60000 items)\n",
              "Image (1, 28, 28),Image (1, 28, 28),Image (1, 28, 28),Image (1, 28, 28),Image (1, 28, 28)\n",
              "Path: /root/.fastai/data/mnist_png;\n",
              "\n",
              "Valid: ImageList (10000 items)\n",
              "Image (1, 28, 28),Image (1, 28, 28),Image (1, 28, 28),Image (1, 28, 28),Image (1, 28, 28)\n",
              "Path: /root/.fastai/data/mnist_png;\n",
              "\n",
              "Test: None"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nMche5H71OvQ",
        "colab_type": "text"
      },
      "source": [
        "So my split data is a training set and a validation set, as you can see."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q00GZhQZgJc5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "b5fbcd90-ccb4-4868-87f8-c3553c48a718"
      },
      "source": [
        "(path/'training').ls()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[PosixPath('/root/.fastai/data/mnist_png/training/2'),\n",
              " PosixPath('/root/.fastai/data/mnist_png/training/4'),\n",
              " PosixPath('/root/.fastai/data/mnist_png/training/3'),\n",
              " PosixPath('/root/.fastai/data/mnist_png/training/5'),\n",
              " PosixPath('/root/.fastai/data/mnist_png/training/9'),\n",
              " PosixPath('/root/.fastai/data/mnist_png/training/1'),\n",
              " PosixPath('/root/.fastai/data/mnist_png/training/6'),\n",
              " PosixPath('/root/.fastai/data/mnist_png/training/7'),\n",
              " PosixPath('/root/.fastai/data/mnist_png/training/8'),\n",
              " PosixPath('/root/.fastai/data/mnist_png/training/0')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q1sOZ63l1YOH",
        "colab_type": "text"
      },
      "source": [
        "Inside the training set, there's a folder for each class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wRLERuI61VZJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ll = sd.label_from_folder()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2OH75HYi1o5V",
        "colab_type": "text"
      },
      "source": [
        "Now we can take that split data and say label_from_folder.\n",
        "\n",
        "So first you create the item list, then you split it, then you label it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iVvAx0Eb1p9m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "bfda299a-a779-4f58-b194-0ff4c2df0f1a"
      },
      "source": [
        "ll"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LabelLists;\n",
              "\n",
              "Train: LabelList (60000 items)\n",
              "x: ImageList\n",
              "Image (1, 28, 28),Image (1, 28, 28),Image (1, 28, 28),Image (1, 28, 28),Image (1, 28, 28)\n",
              "y: CategoryList\n",
              "2,2,2,2,2\n",
              "Path: /root/.fastai/data/mnist_png;\n",
              "\n",
              "Valid: LabelList (10000 items)\n",
              "x: ImageList\n",
              "Image (1, 28, 28),Image (1, 28, 28),Image (1, 28, 28),Image (1, 28, 28),Image (1, 28, 28)\n",
              "y: CategoryList\n",
              "2,2,2,2,2\n",
              "Path: /root/.fastai/data/mnist_png;\n",
              "\n",
              "Test: None"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9rXwj4bk16Ho",
        "colab_type": "text"
      },
      "source": [
        "You can see now we have an x and the y, and the y are category objects. Category object is just a class basically."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cSafaVRU1hGD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x,y = ll.train[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U8AEnZRy2R1m",
        "colab_type": "text"
      },
      "source": [
        "If you index into a label list such as ll.train as a label list, you will get back an independent variable and independent variable (i.e. x and y). In this case, the x will be an image object which I can show, and the y will be a category object which I can print:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gWlQOiCi2Afx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        },
        "outputId": "0d3e4c35-3dcf-4485-cc54-84034c9c9d9b"
      },
      "source": [
        "x.show()\n",
        "print(y,x.shape)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2 torch.Size([1, 28, 28])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAMUAAADDCAYAAAAyYdXtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAA2FJREFUeJzt3VFum1AQQNG46r6SrCzJypyszP2s\ndMWrQAYD9TmfqJLtqleI6QCX2+32Avz1a+8vAEcjCghRQIgCQhQQooAQBcTvB3+e/xThSC5TB50p\nIEQBIQoIUUCIAkIUEKKAEAWEKCBEASEKCFFAiAJCFBCigBAFhCggRAEhCghRQIgCQhQQooAQBYQo\nIEQBIQqIRz9LlgW+v78XHR/5+vqa/Wev1+vk8be3t0WfeWbOFBCigBAFhCggRAFxud0e+nKhp36T\n0efn5+TxJdOhvXx8fEweH/2mk/AmI5hDFBCigBAFhCgg7D7dabSHNDVRWrqzdCQ/Pz97f4WHcaaA\nEAWEKCBEASEKCLtPd7pcJtdnVjG62+319XXy+Bp7SEt/z4P//azN7hPMIQoIUUCIAkIUEHafDmCv\nu9rOvIu1JWcKCFFAiAJCFBCigDB9utPoKd1Tjvbk7iXTp6N99y05U0CIAkIUEKKAcKF9pzNcgC55\nDM/I6Mam/5EzBYQoIEQBIQoIUUCYPj2BNdY5Tv4ar0WcKSBEASEKCFFAiALCA5afwJKHJp/8gclL\necAyzCEKCFFAiAJCFBB2nw5stLO0xp10Ly/nuGtwD84UEKKAEAWEKCBEAWH3aSNTE6K1pkZb2utV\nYzux+wRziAJCFBCigBAFhOnTnd7f3yeP/28vbh/tSY2eRn6SaZXpE8whCghRQIgCQhQQpk8znXnK\nNNpnWmKt/azr9Tp5fKe7AE2fYA5RQIgCQhQQLrRjtJ5wpBuBRva4iB0NGkaDiZGdbm5yoQ1ziAJC\nFBCigBAFhOlTnGGdYzRNGk2fjmTp3+/Ub13xd5o+wRyigBAFhCggRAFh+hRLXsS+tYPdkLOpJTtU\nK07fTJ9gDlFAiAJCFBCigDB9ii13n57s1VmbWXpX3z+mUqZPMIcoIEQBIQoIUUCYPsVoyrR0+mSi\ndAqmTzCHKCBEASEKCFFAmD7xzEyfYA5RQIgCQhQQooAQBYQoIEQBIQoIUUCIAkIUEKKAEAWEKCBE\nASEKCFFAiAJCFBCigBAFhCggRAEhCghRQIgCQhQQvx/8eZMPtIUjcaaAEAWEKCBEASEKCFFAiAJC\nFBCigBAFhCggRAEhCghRQIgCQhQQooAQBYQoIEQBIQoIUUCIAuIPulq5aU+IZhQAAAAASUVORK5C\nYII=\n",
            "text/plain": [
              "<Figure size 216x216 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yCCwERUi2cBY",
        "colab_type": "text"
      },
      "source": [
        "That's the number 2 category, and there's the 2.\n",
        "\n",
        "[7:56](https://youtu.be/nWpdkZE2_cc?t=476)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qxf5CPYF2WTG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tfms = ([*rand_pad(padding=3,size=28,mode ='zeros')],[])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "he3ZypKP3QIt",
        "colab_type": "text"
      },
      "source": [
        "Next thing we can do is to add transforms. In this case, we're not going to use the normal **get_transforms** function because we're doing digit recognition and digit recognition, you wouldn't want to flip it left right. That would change the meaning of it. You wouldn't want to rotate it too much, that would change the meaning of it. Also because these images are so small, doing zooms and stuff is going to make them so fuzzy as to be unreadable. So normally, for small images of digits like this, you just add a bit of random padding. So I'll use the random padding function which actually returns two transforms; the bit that does the padding and the bit that does the random crop. So you have to use star`(*)` to say put both these transforms in this list."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eflYW_K-3MUf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ll = ll.transform(tfms)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OcR2L_bw3qTd",
        "colab_type": "text"
      },
      "source": [
        "Now we call transform. This empty array here is referring to the validation set transforms:\n",
        "\n",
        "![alt text](https://github.com/hiromis/notes/raw/master/lesson7/3.png?raw=true)\n",
        "\n",
        "So no transforms with the validation set.\n",
        "\n",
        "Now we've got a transformed labeled list, we can pick a batch size and choose data bunch:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "24qc-hPq32WV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bs = 128"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ObYfvb113dl-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# not using imagenet_stats because not using pretrained model\n",
        "data = ll.databunch(bs=bs).normalize()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O8EDxSmI5Vsh",
        "colab_type": "text"
      },
      "source": [
        "We can choose normalize. In this case, we're not using a pre-trained model, so there's no reason to use ImageNet stats here. **So if you call normalize like this without passing in stats, it will grab a batch of data at random and use that to decide what normalization stats to use**. That's a good idea if you're not using a pre-trained model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QKQ1toNS7IRH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x,y = data.train_ds[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iDLYbjo75KtK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        },
        "outputId": "0d34a293-54a0-4fbb-8efc-5df306a9a3fd"
      },
      "source": [
        "x.show()\n",
        "print(y)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAMUAAADDCAYAAAAyYdXtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAA2hJREFUeJzt3UFu01AUQNEGsa+2K2u7srQrK0PE\nxR/8ieM45ZyhByRBXFl+PNunz8/PB+Cnb7f+AnA0ooAQBYQoIEQBIQoIUUB83/nz/KcIR3JaOuhM\nASEKCFFAiAJCFBCigBAFhCggRAEhCghRQIgCQhQQooAQBYQoIPa+yYgren9/nzq+5O3tbeozz+fz\n4vGnp6epP+dInCkgRAEhCghRQJx2fuq4p3lMeH19XTw+ezF8Cy8vL4vHR7/pRjzNA9YQBYQoIEQB\nIQoIax47Gq1bjKZJM+sZR/Px8XHrr/DPnCkgRAEhCghRQIgCwu7Tjk6nxVWbzYxu7Hl8fFw8vsUe\n0uxv2vnf29/YfYI1RAEhCghRQIgCwu7THbrFXW33vIc1y5kCQhQQooAQBYQoIEyfdjR6GPHIkR5S\nPDt9OtJ3n+VMASEKCFFAiAJCFBCmTzu6h4nM7LOpRkZ3+90DZwoIUUCIAkIUEKKAMH3iF1vtOB3s\n3XZTnCkgRAEhCghRQHjAMr+48wcmz/KAZVhDFBCigBAFhCggrHl8IaMVjS1uHLqHG6S24kwBIQoI\nUUCIAkIUEHafDuCaU6Nru8WrxjZk9wnWEAWEKCBEASEKCNOnHT0/Py8e/4ovbh/tSo0evHyjaZXp\nE6whCghRQIgCQhQQpk9XsjRpuocp02iXadZW+1nn8/m3YxveBWj6BGuIAkIUEKKAEAWE6dOFRjs7\nR7o7buTKk51FowncaC9syYZ3+5k+wRqigBAFhCggRAFh+nShe7ibbjRRWpo+Hc3MDtk//E7TJ1hD\nFBCigBAFhAvtC82+jP2aRheUX+3VXLOrIn+4AHehDWuIAkIUEKKAEAWEl8tfaDTZ2GLN485fnXU1\no7/z0SR15gamhwdnCviNKCBEASEKCFFA2H260OyL4Zf879OkG7L7BGuIAkIUEKKAEAWE6RP/M9Mn\nWEMUEKKAEAWEKCBEASEKCFFAiAJCFBCigBAFhCggRAEhCghRQIgCQhQQooAQBYQoIEQBIQoIUUCI\nAkIUEKKAEAWEKCBEASEKCFFAiAJCFBCigBAFhCggRAEhCghRQHzf+fMWX+YNR+JMASEKCFFAiAJC\nFBCigBAFhCggRAEhCghRQIgCQhQQooAQBYQoIEQBIQoIUUCIAkIUEKKAEAXED75TtuxCmV28AAAA\nAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 216x216 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "941QIILU6Gcc",
        "colab_type": "text"
      },
      "source": [
        "Okay, so we've got a data bunch and in that data bunch is a data set which we've seen already. But what is interesting is that the training data set now has data augmentation because we've got transforms. plot_multi is a fast.ai function that will plot the result of calling some function for each of this row by column grid. So in this case, my function is just grab the first image from the training set and because each time you grab something from the training set, it's going to load it from disk and it's going to transform it on the fly. People sometimes ask how many transformed versions of the image do you create and the answer is infinite. Each time we grab one thing from the data set, we do a random transform on the fly, so potentially every one will look a little bit different. So you can see here, if we plot the result of that lots of times, we get 8's in slightly different positions because we did random padding."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CaqmmXUe5gOF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 484
        },
        "outputId": "1ec8deb7-cc20-4e5a-f306-8f8f7d96f47b"
      },
      "source": [
        "def _plot(i,j,ax): data.train_ds[0][0].show(ax,cmap='gray')\n",
        "plot_multi(_plot,3,3,figsize=(8,8))"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAd0AAAHTCAYAAABiN8IeAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAEPdJREFUeJzt3VFS5EgSBUBpbe4FdTLgZMDJtB+M\nbS9ZCSRq6WVKcv9rjBlVd0XpmSyiIudlWSYAYH//6f0CAOAqhC4AhAhdAAgRugAQInQBIEToAkCI\n0AWAkH+SF5vn2ZeCL2xZlrnHddXdtfWoOzV3bd/VnCddAAgRugAQInQBIEToAkCI0AWAEKELACFC\nFwBChC4AhAhdAAgRugAQInQBIEToAkCI0AWAEKELACFCFwBChC4AhAhdAAgRugAQInQBIEToAkCI\n0AWAEKELACFCFwBChC4AhAhdAAgRugAQ8k/vFwBs5/Hxselnpaenpx9/53a73f3s7e2t4VVxJmU9\ntdTXNK2rsTPWlyddAAgRugAQInQBIEToAkDIvCxL7mLznLsYw1mWZe5x3bPU3fPz893PWoZT9vTy\n8vLpz7XX2FuPujtqzZXv32j1NU1j1ljpu5rzpAsAIUIXAEKELgCECF0ACLGRaiO2tPA3avVS1kZr\nTSU9PDz0fgk0Kuundu8ZrcbOWF+edAEgROgCQIjQBYAQyzEa+ML4NizH+NpWn8Nav//9/f3uZ2vq\npeU1znOXt/hblmN82KvGtqqvaTpujZUsxwCAAQhdAAgRugAQInQBIOTyyzF8YZwj2/OUn9Hqnrw9\nhzavWl+edAEgROgCQIjQBYCQy/d0X19fN/n/JL8wftVeyJmVh1rUpA+6aKkzh28cx2g1dtX68qQL\nACFCFwBChC4AhAhdAAi5/CDVGr4wztZ6D4zU6q7lNK3awCBjGq3GrlpfnnQBIEToAkCI0AWAkMv3\ndH1hHNbX3ZYHLHBua2rsjPXlSRcAQoQuAIQIXQAIEboAEDKXJ9jserF5zl3sIMrhgpZTj/ZczrGn\nZVnmHtdVdz9ruQ/Mc5e376/1qDs1d+/MNVb6ruY86QJAiNAFgBChCwAhQhcAQi6/kao3W1rYUq2e\n1p4gZPMZNWU9qa/f8aQLACFCFwBChC4AhFiO0ZkvjO/vqHW3Ve9sK5aytDtCzbX0/5P1NU33NXaE\n+qqxHAMABiB0ASBE6AJAiNAFgBCDVBvZ8wvjt9tt5asai0Gqr9VOl2pZnNJbWa/v7+93v9N7GMYg\n1Yeyxo5YX9N0X2O966vGIBUADEDoAkCI0AWAED3dgi+M70dP94/R+mu1xRct1n4WyjmFPZffX7Gn\nO+KMwJoa26q+pil7wIKeLgAMQOgCQIjQBYAQoQsAIZcfpBptoKXFGb8wvqfedVd7L9LDeKW9Bplq\nn5/aUE9pzxOMzj5IdYT6mqb9aqylvqYpO5BqkAoABiB0ASBE6AJAyKV6ur4wPu4Xxvd09bob8RCN\nllmK8nWvfc1n7+mqr3st/yZ7vm49XQAYgNAFgBChCwAhQhcAQk47SOUL48f6wvieeg9SJT9jvYfl\n1mpZqrF28OXsg1TJ+pqm7AlRW2q5RyaG9zzpAkCI0AWAEKELACFCFwBCTjtIZUvLvZG3tOyp9yDV\nVrW450k8R9AyHFir1bMPUm15r0sOVo5obY2VDFIBwACELgCECF0ACDltT9cXxtuM8oXxPfXu6db6\nay09t6v10/Zy9p6u+hqPni4ADEDoAkCI0AWAEKELACGnHaTyhfHtJL4wvqfeg1T0dfZBKsZjkAoA\nBiB0ASBE6AJAyGl7ur4wPh49XXrQ0yVNTxcABiB0ASBE6AJAiNAFgJDTDlIxHoNU9GCQijSDVAAw\nAKELACFCFwBChC4AhAhdAAgRugAQInQBIEToAkBIdDkGAFyZJ10ACBG6ABAidAEgROgCQIjQBYAQ\noQsAIUIXAEKELgCECF0ACBG6ABAidAEgROgCQIjQBYAQoQsAIUIXAEKELgCECF0ACBG6ABAidAEg\nROgCQIjQBYAQoQsAIUIXAEKELgCE/JO82DzPS/J6jGVZlrnHddXdtfWoOzV3bd/VnCddAAgRugAQ\nInQBIEToAkCI0AWAEKELACFCFwBChC4AhAhdAAgRugAQInQBIEToAkCI0AWAkOgpQwAc2+Pj47d/\n/srT09OPv3O73T79+e3trfFVHYcnXQAIEboAECJ0ASBkXpYld7F5zl2M4SzLMve4rrq7th51d9Sa\ne35+/vTnlj7snl5eXu5+Vr7GEX1Xc550ASBE6AJAiNAFgBChCwAhlmMAXEC5xKI2JNW66CLl4eGh\n90vYnCddAAgRugAQInQBIMRyjM7WLA9fszh8mvovD7ccgx4sx/iw1b2+vI+8v7/f/c7aBRYtr3Ge\nu9xGfsVyDAAYgNAFgBChCwAhQhcAQizH2EltkCB5Ysfr6+vdz456YgfQx573jNEWcaR40gWAEKEL\nACFCFwBChC4AhBikWqE2AFAOSY04JHDGEzv4Wa0W99p81nvrGV+rbakrJd+/lho8Yz150gWAEKEL\nACFCFwBCnDK0wpb/Znud2NH6GpMndjhlaHtlbSQXsNSMuIDFKUNjKHu4tQU+pRHrqYVThgBgAEIX\nAEKELgCECF0ACLEcI8iJHfxG+Z7WhqRGe98tYOEra5ZhHGFo6rc86QJAiNAFgBChCwAhlmOsMOKi\n7pYlCbXX1LIEfSuWY/zOVp/N2vteLmFZ2ztreY3JBSw1lmOM4Qi1shXLMQBgAEIXAEKELgCECF0A\nCLEcY4X0kFSpNsjVcrpM7QQjzsUCFvZW1sHa+1Hv+2gvnnQBIEToAkCI0AWAED3dA1q7nOOMy8PP\nrGVxSbIvNuJSGNarvZ8th2zsef3yHnXGe5YnXQAIEboAECJ0ASBE6AJAiFOGDuiop3U4ZehYykGX\n19fXH/+bPZdzrOWUoQ/l+3eEZSd7npC1J6cMAcAAhC4AhAhdAAgRugAQYiNVZ07sYFRrNlCNONRy\nRbWht96DU7Uhu5/U7n0tW7Nq29xGuUd60gWAEKELACFCFwBCLMfYyFa92a1YUvDHmetuT0ddwlI6\n+3KM2uc6ea+p2bOnumZpyzTd3xP3vB9ajgEAAxC6ABAidAEgROgCQIhBqhVG/OJ5i94ndhik6qNW\nmy0LBkq1+qkNzIzm7INUve9HI9ZFy7/Jnq/bIBUADEDoAkCI0AWAED3dBmV/oHf/ds3i8Gla/4X5\nss+x9kvuerp/Z6ve7JaSCwfWOntPN3kPn6bt7gdpLUs1yr/L2h6vni4ADEDoAkCI0AWAEKELACEG\nqQpHOLFjy8GFNSd2rD3ByCDV74w2wNeiZQHLNGUHrs4+SLXlcowjDMbtqeX+1zJcZZAKAAYgdAEg\nROgCQIiebsHy8HstvcWWL5Xr6X6td93VrFnCstUClmnabnbh7D3dlqUpNVfr1ybp6QLAAIQuAIQI\nXQAIEboAEGKQquDEjp/VhjTKQaDa3+Px8dEg1b/KIZbRFrBM03a12FIvNVstajj7IBXjMUgFAAMQ\nugAQInQBIEToAkCIQarCVpuB1p7EcxZf/DsapPpX7xOEWjaIJbV87tZuazNIRZpBKgAYgNAFgBCh\nCwAheroFJ3bsxylDfyQ/d3suvthT+bmr9X1HPd1qxJojR08XAAYgdAEgROgCQIjQBYAQg1TEGKT6\nY6vlGFudxHNULacV9VjKMmLNkWOQCgAGIHQBIEToAkCIni4xerp/lD1cC1j2YzkGaXq6ADAAoQsA\nIUIXAEKELgCEGKQixiAVPRikIs0gFQAMQOgCQIjQBYAQoQsAIUIXAEKELgCECF0ACBG6ABASXY4B\nAFfmSRcAQoQuAIQIXQAIEboAECJ0ASBE6AJAiNAFgBChCwAhQhcAQoQuAIQIXQAIEboAECJ0ASBE\n6AJAiNAFgBChCwAhQhcAQoQuAIQIXQAIEboAECJ0ASBE6AJAiNAFgBChCwAhQhcAQv5JXmye5yV5\nPcayLMvc47rq7tp61J2au7bvas6TLgCECF0ACBG6ABAidAEgROgCQIjQBYAQoQsAIUIXAEKELgCE\nCF0ACBG6ABAidAEgROgCQEj0lCEAzu/x8bHpZ6Wnp6cff+d2u33689vbW+OrGoMnXQAIEboAECJ0\nASBkXpYld7F5zl2M4SzLMve4rrq7th51d+aae35+/vTnlj7snl5eXu5+Vr7GtO9qzpMuAIQIXQAI\nEboAECJ0ASDEcgwApmm6X2BRG5JqWXKR9PDw0Psl/IonXQAIEboAECJ0ASDEcgxiLMegB8sx2m2V\nB7VDCN7f3z/9ee0Ci5bXOM9dbjX/YzkGAAxA6AJAiNAFgBChCwAhlmPAQdSWErQsKmg5BeZ2u939\nrDYMA6U9T/kZbRHHFjzpAkCI0AWAEKELACFCFwBCDFINxrDMNdUGT1re0628vr7e/awckNlqOIZx\n1e4RpeQ9o+Xed7R7mCddAAgRugAQInQBIERPN0jf7ppqfanyfR9xCcDDw0Pvl0BY7/5o+TlouT+W\npxeNzpMuAIQIXQAIEboAECJ0ASDEINVGWgYADMtcU22AbY3akEs5RLJ2EG5ZlrufjVivnNuaZRhH\nG/70pAsAIUIXAEKELgCEzLVezm4Xm+fcxcK2+ndM9+1K8zyv+n83Xn+///k3etfd2trYc3FJ2Ttr\n6TvvWRt76lF3vWvuqHrfo7byXc150gWAEKELACFCFwBChC4AhFiO0dlewzIWG4zjdrv9+Dvp013W\nLCGAVrX6WnOC0Blr0JMuAIQIXQAIEboAEKKnu5HR+natPd0z9kxG0/vfuFYLLf20cikL17NVb3bL\n65dzLw48AACqhC4AhAhdAAgRugAQYpBqI6MNy7QONxiWOb+1izCONqDC3ytPmxpxyU55b3t4eLj7\nndp9bZR69qQLACFCFwBChC4AhAhdAAiZl2XJXWyecxe7mHJIoDZIVRuWadmktZVlWebYxf7P1euu\n5TM+z13emogedXeEmiuHpqap/+BUeepai7UbsWr3vq0GYr+rOU+6ABAidAEgROgCQIie7kkcoW+n\np/t3tjzxpexdJXv7aXq6H1rmPpL27KnWPiu1Hnap7CmvXaihpwsAAxC6ABAidAEgROgCQIhBqsFs\nNSzTexFGjUGqP8r3tPa+JwddaksJRjmV5W8ZpPrQ+wSh0Yb3WpaDrL2PGqQCgAEIXQAIEboAEKKn\nu5OW3uw0Xatvd9We7oiL5VuU/az39/e73zlC31dP90PyXr/n4os9lZ/L2me3pTetpwsAAxC6ABAi\ndAEgROgCQIhBqo30/uL5WslhmSsMUo04NFUboGuxZshvxAEag1QftrpHbXUSz1G1nFb0+PhokAoA\nehO6ABAidAEgRE93BX27dX27M/Z0y35WctlJzZ491VqNt/S3rriUZcR7XcshG6Wr9Wu3YjkGAAxA\n6AJAiNAFgBChCwAhBqkaGJb5/bBMbQDjjINUvZeitJx4ktQ6ZJh83QapSDNIBQADELoAECJ0ASBE\n6AJAiEGqBoZlPmsZlqkNdn138sae9qy75OdnxBN8WrQM59X+HlvVuUEq0gxSAcAAhC4AhAhdAAjR\n022gb/ezsm/3xUKN0/V0t+r39z6Jp7eWBSxre7x6uqTp6QLAAIQuAIQIXQAIEboAEGKQqoFhmW2c\n8ZShshZaa+NK73tvBqlIM0gFAAMQugAQInQBIERPt8Gavp2e3b0z9nQZn54uaXq6ADAAoQsAIUIX\nAEKELgCEGKQixiAVPRikIs0gFQAMQOgCQIjQBYAQoQsAIUIXAEKELgCECF0ACBG6ABASXY4BAFfm\nSRcAQoQuAIQIXQAIEboAECJ0ASBE6AJAiNAFgBChCwAhQhcAQoQuAIQIXQAIEboAECJ0ASBE6AJA\niNAFgBChCwAhQhcAQoQuAIQIXQAIEboAECJ0ASBE6AJAiNAFgJD/Avn9XE/AWZlXAAAAAElFTkSu\nQmCC\n",
            "text/plain": [
              "<Figure size 576x576 with 9 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tbk2eu0n7quz",
        "colab_type": "text"
      },
      "source": [
        "[10:27](https://youtu.be/nWpdkZE2_cc?t=627)\n",
        "\n",
        "You can always grab a batch of data then from the data bunch, because remember, data bunch has data loaders, and data loaders are things you grab a batch at a time. So you can then grab a X batch and a Y batch, look at their shape - batch size by channel by row by column:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YT4VFiPa6oQf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3e8ddc16-c07e-43a1-beaa-de14deabf711"
      },
      "source": [
        "xb,yb =data.one_batch()\n",
        "xb.shape,yb.shape"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([128, 1, 28, 28]), torch.Size([128]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GG_n32zM74Tc",
        "colab_type": "text"
      },
      "source": [
        "All fast.ai data bunches have a show_batch which will show you what's in it in some sensible way:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RG4udufJ7wxy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        },
        "outputId": "54a435ae-0579-4155-83c1-18bef230ae4f"
      },
      "source": [
        "data.show_batch(rows=3,figsize=(5,5))"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVIAAAFgCAYAAADpZ/FJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nASAQhRQAAlFIASAQhRQAAlFIASDQ/wNSjwxK7/HChgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 360x360 with 9 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eaggzF3g8Sus",
        "colab_type": "text"
      },
      "source": [
        "That was a quick walk through with a data block API stuff to grab our data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UtvHZWXK8TdU",
        "colab_type": "text"
      },
      "source": [
        "## Basic CNN with batch norm : using only Pytorch [11:01](https://youtu.be/nWpdkZE2_cc?t=661) \n",
        "\n",
        "Let's start out creating a simple CNN. The input is 28 by 28. I like to define when I'm creating architectures a function which kind of does the things that I do again and again and again. I don't want to call it with the same arguments because I'll forget or I make a mistake. In this case, all of my convolution is going to be kernel size 3 stride 2 padding 1. So let's just create a simple function to do a conv with those parameters:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "48lC3IxA8BaL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def conv(ni,nf):\n",
        "    return nn.Conv2d(ni,nf,kernel_size=3,stride=2,padding=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TrQbuRem9HK2",
        "colab_type": "text"
      },
      "source": [
        "**Each time you have a convolution, it's skipping over one pixel so it's jumping two steps each time -> stride = 2**. That means that each time we have a convolution, it's going to halve the grid size. I've put a comment here showing what the new grid size is after each one."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U-izx2D486c1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model  = nn.Sequential(\n",
        "            conv(1,8), #14\n",
        "            nn.BatchNorm2d(8),\n",
        "            nn.ReLU(),\n",
        "            conv(8,16), #7\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.ReLU(),\n",
        "            conv(16,32), #4\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "            conv(32,16), #2\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.ReLU(),\n",
        "            conv(16,10), #1\n",
        "            nn.BatchNorm2d(10),\n",
        "            Flatten() #remove (1,1) grid\n",
        "        )\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iZRpYB14AH6T",
        "colab_type": "text"
      },
      "source": [
        "After the first convolution, we have one channel coming in because it's a grayscale image with one channel, and then how many channels coming out? Whatever you like. So remember, you always get to pick how many filters you create regardless of whether it's a fully connected layer in which case it's just the width of the matrix you're multiplying by, or in this case with the 2D conv, it's just how many filters do you want. So I picked 8 and so after this, it's stride 2 to so the 28 by 28 image is now a 14 by 14 feature map with 8 channels. Specifically therefore, it's an 8 by 14 by 14 tensor of activations.\n",
        "\n",
        "Then we'll do a batch norm, then we'll do ReLU. The number of input filters to the next conv has to equal the number of output filters from the previous conv, and we can just keep increasing the number of channels because we're doing stride 2, it's got to keep decreasing the grid size. Notice here, it goes from 7 to 4 because if you're doing a stride 2 conv over 7, it's going to be **math.ceiling** of 7/2.\n",
        "\n",
        "Batch norm, ReLU, conv. We are now down to 2 by 2. Batch norm, ReLU, conv, we're now down to 1 by 1. After this, we have a feature map of 10 by 1 by 1. Does that make sense? We've got a grid size of one now. It's not a vector of length 10, it's a rank 3 tensor of 10 by 1 by 1. **Our loss functions expect (generally) a vector not a rank 3 tensor, so you can chuck flatten at the end, and flatten just means remove any unit axes. So that will make it now just a vector of length 10 which is what we always expect.**\n",
        "\n",
        "That's how we can create a CNN. Then we can return that into a learner by passing in the data and the model and the loss function and optionally some metrics. We're going to use cross-entropy as usual. We can then call **learn.summary()** and confirm."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hLrV_MAO-Zsj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn = Learner(data,model,loss_func=nn.CrossEntropyLoss(),metrics=accuracy)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RJ_luj3eAyKs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "outputId": "2b19d939-dc82-4c47-9f7d-c3c7b5143eef"
      },
      "source": [
        "learn.summary()"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "======================================================================\n",
              "Layer (type)         Output Shape         Param #    Trainable \n",
              "======================================================================\n",
              "Conv2d               [8, 14, 14]          80         True      \n",
              "______________________________________________________________________\n",
              "BatchNorm2d          [8, 14, 14]          16         True      \n",
              "______________________________________________________________________\n",
              "ReLU                 [8, 14, 14]          0          False     \n",
              "______________________________________________________________________\n",
              "Conv2d               [16, 7, 7]           1,168      True      \n",
              "______________________________________________________________________\n",
              "BatchNorm2d          [16, 7, 7]           32         True      \n",
              "______________________________________________________________________\n",
              "ReLU                 [16, 7, 7]           0          False     \n",
              "______________________________________________________________________\n",
              "Conv2d               [32, 4, 4]           4,640      True      \n",
              "______________________________________________________________________\n",
              "BatchNorm2d          [32, 4, 4]           64         True      \n",
              "______________________________________________________________________\n",
              "ReLU                 [32, 4, 4]           0          False     \n",
              "______________________________________________________________________\n",
              "Conv2d               [16, 2, 2]           4,624      True      \n",
              "______________________________________________________________________\n",
              "BatchNorm2d          [16, 2, 2]           32         True      \n",
              "______________________________________________________________________\n",
              "ReLU                 [16, 2, 2]           0          False     \n",
              "______________________________________________________________________\n",
              "Conv2d               [10, 1, 1]           1,450      True      \n",
              "______________________________________________________________________\n",
              "BatchNorm2d          [10, 1, 1]           20         True      \n",
              "______________________________________________________________________\n",
              "Flatten              [10]                 0          False     \n",
              "______________________________________________________________________\n",
              "\n",
              "Total params: 12,126\n",
              "Total trainable params: 12,126\n",
              "Total non-trainable params: 0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pmpKF41yBGiE",
        "colab_type": "text"
      },
      "source": [
        "After that first conv, we're down to 14 by 14 and after the second conv 7 by 7, 4 by 4, 2 by 2, 1 by 1. The **flatten** comes out (calling it a **Lambda**), that as you can see it gets rid of the 1 by 1 and it's now just a length 10 vector for each item in the batch so 128 by 10 matrix in the whole mini batch.\n",
        "\n",
        "Just to confirm that this is working okay, we can grab that mini batch of X that we created earlier (there's a mini batch of X), pop it onto the GPU, and call the model directly. Any PyTorch module, we can pretend it's a function and that gives us back as we hoped a 128 by 10 result."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HOC0OhqcA3bJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xb = xb.cuda()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Au0dAHSVBOSW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1afaac6a-1d1a-4e7f-e1e0-726ca4d4c3a2"
      },
      "source": [
        "model(xb).shape"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([128, 10])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2rQrzRTtBYyg",
        "colab_type": "text"
      },
      "source": [
        "That's how you can directly get some predictions out. LR find, fit one cycle, and bang. We already have a 98.6% accurate conv net."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BQT8FzLdBTYw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "outputId": "d00eb510-1f43-45b6-fa94-76edebce15a9"
      },
      "source": [
        "learn.lr_find(end_lr=100)\n",
        "learn.recorder.plot()"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nURARkWYqCiIi0kxFQUREmv0/XIeDOXbU+YAAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wNJ5tVD_BeGi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "outputId": "fe2f664c-c200-4ea2-907e-fe2647a841d0"
      },
      "source": [
        "learn.fit_one_cycle(3,max_lr=0.1)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.217414</td>\n",
              "      <td>0.222348</td>\n",
              "      <td>0.928500</td>\n",
              "      <td>00:32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.133073</td>\n",
              "      <td>0.085261</td>\n",
              "      <td>0.971500</td>\n",
              "      <td>00:32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.070303</td>\n",
              "      <td>0.040906</td>\n",
              "      <td>0.987300</td>\n",
              "      <td>00:31</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d0EDwJcnCIAp",
        "colab_type": "text"
      },
      "source": [
        "This is trained from scratch, of course, it's not pre-trained. We've literally created our own architecture. It's about the simplest possible architecture you can imagine. 18 seconds to train, so that's how easy it is to create a pretty accurate digit detector."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cLtYrJRFCvk1",
        "colab_type": "text"
      },
      "source": [
        "##Refactor [15:42](https://youtu.be/nWpdkZE2_cc?t=942): fastai tweaks\n",
        "\n",
        "Let's refactor that a little. Rather than saying conv, batch norm, ReLU all the time, fast.ai already has something called **conv_layer** which **lets you create conv, batch norm, ReLU combinations**. It has various other options to do other tweaks to it, but the basic version is just exactly what I just showed you. So we can refactor that like so:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AhSshnjSBlvn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def conv2(ni,nf): return conv_layer(ni,nf,stride=2) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ka-NFGspDMJQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = nn.Sequential(\n",
        "        conv2(1,8), #14\n",
        "        conv2(8,16), #7\n",
        "        conv2(16,32), #4\n",
        "        conv2(32,16), #2\n",
        "        conv2(16,10), #1\n",
        "        Flatten() # remove (1,1) grid\n",
        "      )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DYF_zgiqDmi1",
        "colab_type": "text"
      },
      "source": [
        "That's exactly the same neural net"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t1XV3OTDDhw0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn = Learner(data,model,loss_func=nn.CrossEntropyLoss(),metrics=accuracy)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PfcF1xifDxih",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "outputId": "88414a67-6e1a-4bf6-de07-3cc4897de4bd"
      },
      "source": [
        "learn.fit_one_cycle(10,max_lr=0.1)"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.239158</td>\n",
              "      <td>0.197799</td>\n",
              "      <td>0.933500</td>\n",
              "      <td>00:31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.191847</td>\n",
              "      <td>0.270177</td>\n",
              "      <td>0.915900</td>\n",
              "      <td>00:32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.168726</td>\n",
              "      <td>0.144540</td>\n",
              "      <td>0.955800</td>\n",
              "      <td>00:31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.130631</td>\n",
              "      <td>0.103725</td>\n",
              "      <td>0.966100</td>\n",
              "      <td>00:31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.125160</td>\n",
              "      <td>0.139571</td>\n",
              "      <td>0.956200</td>\n",
              "      <td>00:32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.095178</td>\n",
              "      <td>0.075221</td>\n",
              "      <td>0.977000</td>\n",
              "      <td>00:31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.088830</td>\n",
              "      <td>0.050993</td>\n",
              "      <td>0.983300</td>\n",
              "      <td>00:32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.065389</td>\n",
              "      <td>0.047365</td>\n",
              "      <td>0.985800</td>\n",
              "      <td>00:32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.049377</td>\n",
              "      <td>0.032323</td>\n",
              "      <td>0.989900</td>\n",
              "      <td>00:31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.043649</td>\n",
              "      <td>0.030366</td>\n",
              "      <td>0.989600</td>\n",
              "      <td>00:32</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SAcQLNNuE4br",
        "colab_type": "text"
      },
      "source": [
        "Let's just try a little bit longer and it's actually 99.1% accurate if we train it for all of a minute, so that's cool."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LKwXNoYbFIKI",
        "colab_type": "text"
      },
      "source": [
        "## Now using pretrained model : ResNet-ish [16:24](https://youtu.be/nWpdkZE2_cc?t=984)\n",
        "\n",
        "How can we improve this? **What we really want to do is create a deeper network, and so a very easy way to create a deeper network would be after every stride 2 conv, add a stride 1 conv. Because the stride 1 conv doesn't change the feature map size at all, so you can add as many as you like. But there's a problem**. The problem was pointed out in this paper, very very very influential paper, called [Deep Residual Learning for Image Recognition](https://arxiv.org/abs/1512.03385) by Kaiming He and colleagues at (then) Microsoft Research.\n",
        "\n",
        "They did something interesting. They said let's look at the training error. So forget generalization even, let's just look at the training error of a network trained on CIFAR-10 and let's try one network of 20 layers just basic 3x3 convs - basically the same network I just showed you, but without batch norm. They trained a 20 layer one and a 56 layer one on the training set.\n",
        "\n",
        "The 56 layer one has a lot more parameters. It's got a lot more of these stride 1 convs in the middle. So the one with more parameters should seriously over fit, right? **So you would expect the 56 layer one to zip down to zero-ish training error pretty quickly and that is not what happens. It is worse than the shallower network**.\n",
        "\n",
        "![alt text](https://github.com/hiromis/notes/blob/master/lesson7/7.png?raw=true)\n",
        "\n",
        "When you see something weird happen, really good researchers don't go \"oh no, it's not working\" they go \"that's interesting.\" So Kaiming He said \"that's interesting. What's going on?\" and he said \"I don't know, but what I do know is this - I could take this 56 layer network and make a new version of it which is identical but has to be at least as good as the 20 layer network and here's how:\n",
        "\n",
        "![](https://github.com/hiromis/notes/blob/master/lesson7/8.png?raw=true)\n",
        "\n",
        "When you see something weird happen, really good researchers don't go \"oh no, it's not working\" they go \"that's interesting.\" So Kaiming He said \"that's interesting. What's going on?\" and he said \"I don't know, but what I do know is this - I could take this 56 layer network and make a new version of it which is identical but has to be at least as good as the 20 layer network and here's how:\n",
        "\n",
        "![](https://github.com/hiromis/notes/blob/master/lesson7/8.png?raw=true)\n",
        "\n",
        "Every to convolutions, I'm going to add together the input to those two convolutions with the result of those two convolutions.\" In other words, he's saying instead of saying:\n",
        "\n",
        "**Output=Conv2(Conv1(x))**\n",
        "\n",
        "nstead, he's saying:\n",
        "\n",
        "**Output=x+Conv2(Conv1(x))**\n",
        "\n",
        "His theory was 56 layers worth of convolutions in that has to be at least good as the 20 layer version because it could always just set conv2 and conv1 to a bunch of 0 weights for everything except for the first 20 layers because the X (i.e. the input) could just go straight through. So this thing here is (as you see) called an **identity connection**. It's the identity function - nothing happens at all. It's also known as a **skip connection**.\n",
        "\n",
        "So that was the theory. That's what the paper describes as the intuition behind this is what would happen if we created something which has to train at least as well as a 20 layer neural network because it kind of contains that 20 layer neural network. There's literally a path you can just skip over all the convolutions. So what happens?\n",
        "\n",
        "What happened was he won ImageNet that year. He easily won ImageNet that year. In fact, even today, we had that record-breaking result on ImageNet speed training ourselves in the last year, we used this too. ResNet has been revolutionary."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fm-IEaxzH62M",
        "colab_type": "text"
      },
      "source": [
        "##ResBlock Trick [20:36](https://youtu.be/nWpdkZE2_cc?t=1236)\n",
        "\n",
        "Here's a trick if you're interested in doing some research. Anytime you find some model for anything whether it's medical image segmentation or some kind of GAN or whatever and it was written a couple of years ago, they might have forgotten to put ResBlocks in. Figure 2 is what we normally call a ResBlock. They might have forgotten to put ResBlocks in. So replace their convolutional path with a bunch of ResBlocks and you will almost always get better results faster. It's a good trick.\n",
        "\n",
        "[Visualizing the Loss Landscape of Neural Nets](https://arxiv.org/abs/1712.09913) [21:16](https://youtu.be/nWpdkZE2_cc?t=1276)\n",
        "\n",
        "At NeurIPS, which Rachel, I, David, and Sylvain all just came back from, we saw a new presentation where they actually figured out how to visualize the loss surface of a neural net which is really cool. This is a fantastic paper and anybody who's watching this lesson 7 is at a point where they will understand the most of the important concepts in this paper. You can read this now. You won't necessarily get all of it, but I'm sure you'll get it enough to find it interesting.\n",
        "\n",
        "![](https://github.com/hiromis/notes/raw/master/lesson7/9.png?raw=true)\n",
        "\n",
        "The big picture was this one. Here's what happens if you if you draw a picture where x and y here are two projections of the weight space, and z is the loss. As you move through the weight space, a 56 layer neural network without skip connections is very very bumpy. That's why this got nowhere because it just got stuck in all these hills and valleys. The exact same network with identity connections (i.e. with skip connections) has this loss landscape (on the right). So it's kind of interesting how Kaiming He recognized back in 2015 this shouldn't happen, here's a way that must fix it and it took three years before people were able to say oh this is kind of why it fixed it. It kind of reminds me of the batch norm discussion we had a couple of weeks ago that people realizing a little bit after the fact sometimes what's going on and why it helps."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yNEdXvZkD1p-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ResBlock(nn.Module):\n",
        "    def __init__(self,nf):\n",
        "        super().__init__()\n",
        "        self.conv1 = conv_layer(nf,nf)\n",
        "        self.conv2 = conv_layer(nf,nf)\n",
        "    \n",
        "    def forward(self,x) : return x +  self.conv2(self.conv1(x))\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zf4zV7y-LRwg",
        "colab_type": "text"
      },
      "source": [
        "In our code, we can create a ResBlock in just the way I described. We create a nn.Module, we create two conv layers (remember, a **conv_layer** is Conv2d, ReLU, batch norm), so create two of those and then in forward we go **conv1(x)**, **conv2** of that and then add **x**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FQHkvBlhLO5X",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "3637a4c7-4dab-4812-c2fd-f6261e1eb3ab"
      },
      "source": [
        "help(res_block)"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Help on function res_block in module fastai.layers:\n",
            "\n",
            "res_block(nf, dense:bool=False, norm_type:Union[fastai.layers.NormType, NoneType]=<NormType.Batch: 1>, bottle:bool=False, **conv_kwargs)\n",
            "    Resnet block of `nf` features. `conv_kwargs` are passed to `conv_layer`.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GvftfZaoLu6F",
        "colab_type": "text"
      },
      "source": [
        "There's a res_block function already in fast.ai so you can just call res_block instead, and you just pass in something saying how many filters you want."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fOsEwR4lLo22",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = nn.Sequential(\n",
        "        conv2(1,8),\n",
        "        res_block(8),\n",
        "        conv2(8,16),\n",
        "        res_block(16),\n",
        "        conv2(16,32),\n",
        "        res_block(32),\n",
        "        conv2(32,16),\n",
        "        res_block(16),\n",
        "        conv2(16,10),\n",
        "        Flatten()\n",
        "        )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lC9EbqM5M2sn",
        "colab_type": "text"
      },
      "source": [
        "There's the ResBlock that I defined in our notebook, and so with that ResBlock, I've just copied the previous CNN and after every conv2 except the last one, I added a res_block so this has now got three times as many layers, so it should be able to do more compute. But it shouldn't be any harder to optimize.\n",
        "\n",
        "**Let's just refactor it one more time**. Since I go **conv2 res_block** so many times, let's just pop that into a little mini sequential model here and so I can refactor that like so:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hZJNsQIKMUty",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def conv_and_res(ni,nf): return nn.Sequential(conv2(ni,nf),res_block(nf))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "loxFWegoNIWS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = nn.Sequential(\n",
        "    conv_and_res(1,8),\n",
        "    conv_and_res(8,16),\n",
        "    conv_and_res(16,32),\n",
        "    conv_and_res(32,16),\n",
        "    conv2(16,10),\n",
        "    Flatten()\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pT-pphwAOT5c",
        "colab_type": "text"
      },
      "source": [
        "Keep refactoring your architectures if you're trying novel architectures because you'll make less mistakes. Very few people do this. Most research code you look at is clunky as all heck and people often make mistakes in that way, so don't do that. You're all coders, so use your coding skills to make life easier.\n",
        "\n",
        "[24:47](https://youtu.be/nWpdkZE2_cc?t=1487)\n",
        "\n",
        "Okay, so there's my ResNet-ish architecture. **lr_find** as usual, **fit** for a while, and I get 99.54%."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4d6_7yXKN70F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn = Learner(data,model,loss_func=nn.CrossEntropyLoss(),metrics=accuracy)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "taZipcdnOwrp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "outputId": "eb48cf3f-3ea7-4d22-e46e-5761b95be3d1"
      },
      "source": [
        "learn.lr_find()\n",
        "learn.recorder.plot()"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zSjfrTXtO_g1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        },
        "outputId": "6b8d956f-02aa-43f3-9e75-d312bd5097b2"
      },
      "source": [
        "learn.fit_one_cycle(12,max_lr=0.05)"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.238437</td>\n",
              "      <td>0.170562</td>\n",
              "      <td>0.951100</td>\n",
              "      <td>00:31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.131322</td>\n",
              "      <td>0.110652</td>\n",
              "      <td>0.964600</td>\n",
              "      <td>00:32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.105091</td>\n",
              "      <td>0.114328</td>\n",
              "      <td>0.964500</td>\n",
              "      <td>00:31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.089622</td>\n",
              "      <td>0.109394</td>\n",
              "      <td>0.964200</td>\n",
              "      <td>00:31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.075272</td>\n",
              "      <td>0.101326</td>\n",
              "      <td>0.969900</td>\n",
              "      <td>00:31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.060685</td>\n",
              "      <td>0.070216</td>\n",
              "      <td>0.978200</td>\n",
              "      <td>00:30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.049984</td>\n",
              "      <td>0.045595</td>\n",
              "      <td>0.986500</td>\n",
              "      <td>00:31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.046828</td>\n",
              "      <td>0.035584</td>\n",
              "      <td>0.988800</td>\n",
              "      <td>00:31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.037641</td>\n",
              "      <td>0.026890</td>\n",
              "      <td>0.991800</td>\n",
              "      <td>00:30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.030043</td>\n",
              "      <td>0.016961</td>\n",
              "      <td>0.995100</td>\n",
              "      <td>00:31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.020654</td>\n",
              "      <td>0.016802</td>\n",
              "      <td>0.994800</td>\n",
              "      <td>00:30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.019780</td>\n",
              "      <td>0.015703</td>\n",
              "      <td>0.995300</td>\n",
              "      <td>00:32</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cXjJNmwCRKy8",
        "colab_type": "text"
      },
      "source": [
        "## Benefit of ResNet\n",
        "\n",
        "That's interesting because we've trained this literally from scratch with an architecture we built from scratch, I didn't look out this architecture anywhere. It's just the first thing that came to mind. But in terms of where that puts us, 0.45% error is around about the state of the art for this data set as of three or four years ago.\n",
        "\n",
        "![](https://github.com/hiromis/notes/raw/master/lesson7/11.png?raw=true)\n",
        "\n",
        "Today MNIST considered a trivially easy dataset, so I'm not saying like wow, we've broken some records here. People have got beyond 0.45% error, **but what I'm saying is this kind of ResNet is a genuinely extremely useful network still today**. This is really all we use in our fast ImageNet training still. And one of the reasons as well is that it's so popular so the vendors of the library spend a lot of time optimizing it, so things tend to work fast. Where else, some more modern style architectures using things like separable or group convolutions tend not to actually train very quickly in practice.\n",
        "\n",
        "![alt text](https://github.com/hiromis/notes/blob/master/lesson7/12.png?raw=true)\n",
        "\n",
        "If you look at the definition of **res_block** in the fast.ai code, you'll see it looks a little bit different to this, and that's because I've created something called a **MergeLayer**. A **MergeLayer** is something which in the forward (just skip dense for a moment), the forward says **x+x.orig**. So you can see there's something ResNet-ish going on here. \n",
        "- **What is x.orig?** Well, if you create a special kind of sequential model called a SequentialEx so this is like fast.ai's sequential extended. It's just like a normal sequential model, but we store the input in **x.orig**. \n",
        "\n",
        "So this SequentialEx, conv_layer, conv_layer, MergeLayer, will do exactly the same as ResBlock. So you can create your own variations of ResNet blocks very easily with this **SequentialEx** and **MergeLayer**.\n",
        "\n",
        "There's something else here which is when you create your MergeLayer, you can optionally set **dense=True**, and what happens if you do? Well, if you do, it doesn't go **x+x.orig**, it goes **cat([x,x.orig])**. In other words, rather than putting a plus in this connection, it does a concatenate. **That's pretty interesting because what happens is that you have your input coming in to your Res block, and once you use concatenate instead of plus, it's not called a Res block anymore, it's called a dense block. And it's not called a ResNet anymore, it's called a DenseNet.**\n",
        "\n",
        "The DenseNet was invented about a year after the ResNet, and if you read the DenseNet paper, it can sound incredibly complex and different, but actually it's literally identical but plus here is placed with cat. So you have your input coming into your dense block, and you've got a few convolutions in here, and then you've got some output coming out, and then you've got your identity connection, and remember it doesn't plus, it concats so the channel axis gets a little bit bigger. Then we do another dense block, and at the end of that, we have the result of the convolution as per usual, but this time the identity block is that big.\n",
        "\n",
        "![alt text](https://github.com/hiromis/notes/blob/master/lesson7/13.png?raw=true)\n",
        "\n",
        "So you can see that what happens is that with dense blocks it's getting bigger and bigger and bigger, and kind of interestingly the exact input is still here. So actually, no matter how deep you get the original input pixels are still there, and the original layer 1 features are still there, and the original layer 2 features are still there. So as you can imagine, **DenseNets are very memory intensive**. There are ways to manage this. From time to time, you can have a regular convolution and it squishes your channels back down, but they are memory intensive. But, they have very few parameters. **So for dealing with small datasets, you should definitely experiment with dense blocks and DenseNets. They tend to work really well on small datasets.**\n",
        "\n",
        "Also, because it's possible to keep those original input pixels all the way down the path, they work really well for segmentation. Because for segmentation, you want to be able to reconstruct the original resolution of your picture, so having all of those original pixels still there is a super helpful."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aEEdwj2HP6pF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}