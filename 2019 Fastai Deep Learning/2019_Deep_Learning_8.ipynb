{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2019_Deep_Learning_8.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hduongck/AI-ML-Learning/blob/master/2019%20Fastai%20Deep%20Learning/2019_Deep_Learning_8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V5EG-oyiIEu8",
        "colab_type": "text"
      },
      "source": [
        "This time part 2 is very different from the 2018 version. The course name is “Deep Learning from the Foundations”. **We will learn to implement a lot of things that are inside Fastai and PyTorch. Basically, we will learn things that we could use to build our own deep learning libraries**. Along the way, we will learn to implement papers which is an important skill to master when making state of the art models.\n",
        "\n",
        "Purpose of this part is opposite to part 1. This time we don’t learn practical things that we will use for something but more like how to learn these things by ourselves after this course ends. This is important nowadays because this area is moving so fast.\n",
        "\n",
        "**On the last two lessons, we will learn about Swift**. The reason we will learn another programming language that doesn’t have proper deep learning libraries is that the person (Chris Lattner) who created the most used compiling tools is now focusing on deep learning and Swift (which he also created). Current deep learning libraries are more or less developed by a bunch of deep learning nerds that doesn’t necessarily have as much knowledge about programming as compiler guys. This means that Swift is much better for DL than Python because it is faster and more optimized.\n",
        "\n",
        "\n",
        "```\n",
        "“There is no way I will be missing out that boat.” — Jeremy\n",
        "```\n",
        "\n",
        "Another language that has also potential is Julia. It is not as potential as Swift but you shouldn’t put all eggs into one basket. Learning Julia at a high level doesn’t take much time but it can pay off well in the future.\n",
        "\n",
        "**Next, we will start to implement Fastai from scratch**. To make this interesting Jeremy made some rules about what tools/libraries we can use.\n",
        "- Python\n",
        "- Python standard libraries\n",
        "- Non-data science modules (like requests library for http)\n",
        "- PyTorch — ONLY for creating arrays, random number generation, and indexing into arrays\n",
        "- Fastai.datasets (datasets like MNIST)\n",
        "- Matplotlib (for plots)\n",
        "\n",
        "After we have implemented some part of Fastai or PyTorch we will use it normally to make the code easier to read.\n",
        "\n",
        "**Creating a great model consists three steps:**\n",
        "- Overfit (Validation loss starts to increase)\n",
        "- Reduce overfitting\n",
        "- Visualize the outputs\n",
        "\n",
        "Creating an model that overfit isn’t that complicated. To reduce overfitting you need to do the following things (in order):\n",
        "- More data\n",
        "- Data augmentation\n",
        "- Generalizable architectures\n",
        "- Regularization\n",
        "- Reduce architecture complexity\n",
        "\n",
        "![alt text](https://github.com/hduongck/AI-ML-Learning/blob/master/Pic/Annotation%202019-06-30%20135010.png?raw=true)\n",
        "\n",
        "We learned these things in the part 1.\n",
        "\n",
        "**Papers often contain a lot of math that might be hard to understand right away**. It is important to learn Greek letters. The person who wrote the paper doesn’t necessarily have the talent to explain things simply. That is why you also should read blog posts or watch videos about the paper you are reading.\n",
        "\n",
        "![alt text](https://github.com/hduongck/AI-ML-Learning/blob/master/Pic/Annotation%202019-06-30%20134828.png?raw=true)\n",
        "\n",
        "If there is mathematical symbols that you doesn’t understand: \n",
        "\n",
        "https://en.wikipedia.org/wiki/List_of_mathematical_symbols http://detexify.kirelabs.org/classify.html\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "84VPUptKLzL8",
        "colab_type": "text"
      },
      "source": [
        "# Steps to a basic CNN models\n",
        "\n",
        "![alt text](https://github.com/hduongck/AI-ML-Learning/blob/master/Pic/cnn%20workflow.png?raw=true)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TX5CGTIkNGfp",
        "colab_type": "text"
      },
      "source": [
        "## Start with matmul\n",
        "\n",
        "Matrix multiplication from foundations\n",
        "\n",
        "The foundations we'll assume throughout this course are:\n",
        "\n",
        "- Python\n",
        "- Python modules (non-DL)\n",
        "- pytorch indexable tensor, and tensor creation (including RNGs - random number generators)\n",
        "- fastai.datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0JuRlt05QzkX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pathlib import Path\n",
        "from IPython.core.debugger import set_trace\n",
        "from fastai import datasets\n",
        "import pickle,gzip,math,torch, matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "from torch import tensor\n",
        "\n",
        "MNIST_URL='http://deeplearning.net/data/mnist/mnist.pkl'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c3TDjp1ERXrK",
        "colab_type": "code",
        "outputId": "dd5b4b6e-4b43-4bb5-bbf3-ab9dbf3ce0e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "path = datasets.download_data(MNIST_URL, ext='.gz'); path"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PosixPath('/root/.fastai/data/mnist.pkl.gz')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zo5GHpWSRd7K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with gzip.open(path,'rb') as f:\n",
        "    ((x_train,y_train),(x_valid,y_valid),_)=pickle.load(f,encoding='latin-1')\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MMx3Vl8BRsrO",
        "colab_type": "code",
        "outputId": "0a28ab30-f43f-402c-89fc-3d3b1e2c4cdb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "x_train,y_train,x_valid,y_valid=map(tensor,(x_train,y_train,x_valid,y_valid))\n",
        "n,c = x_train.shape\n",
        "x_train,x_train.shape,y_train,y_train.shape,y_train.min(),y_train.max()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.]]),\n",
              " torch.Size([50000, 784]),\n",
              " tensor([5, 0, 4,  ..., 8, 4, 8]),\n",
              " torch.Size([50000]),\n",
              " tensor(0),\n",
              " tensor(9))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1bbQkkgrSDm7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mpl.rcParams['image.cmap']='gray'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-jTG2hsSTA1w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img = x_train[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wtkZ9AHnTC86",
        "colab_type": "code",
        "outputId": "3cebbe02-5ce6-4186-ffc0-291d94a75a26",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "img.view(28,28).type()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'torch.FloatTensor'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_g8vlfOETFlW",
        "colab_type": "code",
        "outputId": "dd1d0c24-331e-4458-976f-81748b520945",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "source": [
        "plt.imshow(img.view(28,28))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f87d7c93ef0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAADgdJREFUeJzt3X9sXfV5x/HPs9D8QRoIXjUTpWFp\nIhQUIuZOJkwoGkXM5YeCggGhWkLKRBT3j1ii0hQNZX8MNAVFg2RqBKrsqqHJ1KWZBCghqpp0CZBO\nTBEmhF9mKQylqi2TFAWTH/zIHD/74x53Lvh+r3Pvufdc+3m/JMv3nuecex4d5ZPz8/pr7i4A8fxJ\n0Q0AKAbhB4Ii/EBQhB8IivADQRF+ICjCDwRF+IGgCD8Q1GWNXJmZ8TghUGfublOZr6Y9v5ndYWbH\nzex9M3ukls8C0FhW7bP9ZjZL0m8kdUgalPSqpC53H0gsw54fqLNG7PlXSHrf3T9w9wuSfi5pdQ2f\nB6CBagn/Akm/m/B+MJv2R8ys28z6zay/hnUByFndL/i5e5+kPonDfqCZ1LLnH5K0cML7b2bTAEwD\ntYT/VUnXmtm3zGy2pO9J2ptPWwDqrerDfncfNbMeSfslzZK03d3fya0zAHVV9a2+qlbGOT9Qdw15\nyAfA9EX4gaAIPxAU4QeCIvxAUIQfCIrwA0ERfiAowg8ERfiBoAg/EBThB4Ii/EBQhB8IivADQRF+\nICjCDwRF+IGgCD8QFOEHgiL8QFCEHwiK8ANBEX4gKMIPBEX4gaAIPxAU4QeCIvxAUFUP0S1JZnZC\n0llJFyWNunt7Hk0hP7NmzUrWr7zyyrquv6enp2zt8ssvTy67dOnSZH39+vXJ+pNPPlm21tXVlVz2\n888/T9Y3b96crD/22GPJejOoKfyZW939oxw+B0ADcdgPBFVr+F3SATN7zcy682gIQGPUeti/0t2H\nzOzPJP3KzP7b3Q9PnCH7T4H/GIAmU9Oe392Hst+nJD0vacUk8/S5ezsXA4HmUnX4zWyOmc0dfy3p\nu5LezqsxAPVVy2F/q6TnzWz8c/7N3X+ZS1cA6q7q8Lv7B5L+IsdeZqxrrrkmWZ89e3ayfvPNNyfr\nK1euLFubN29ectn77rsvWS/S4OBgsr5t27ZkvbOzs2zt7NmzyWXfeOONZP3ll19O1qcDbvUBQRF+\nICjCDwRF+IGgCD8QFOEHgjJ3b9zKzBq3sgZqa2tL1g8dOpSs1/trtc1qbGwsWX/ooYeS9XPnzlW9\n7uHh4WT9448/TtaPHz9e9brrzd1tKvOx5weCIvxAUIQfCIrwA0ERfiAowg8ERfiBoLjPn4OWlpZk\n/ciRI8n64sWL82wnV5V6HxkZSdZvvfXWsrULFy4kl436/EOtuM8PIInwA0ERfiAowg8ERfiBoAg/\nEBThB4LKY5Te8E6fPp2sb9iwIVlftWpVsv76668n65X+hHXKsWPHkvWOjo5k/fz588n69ddfX7b2\n8MMPJ5dFfbHnB4Ii/EBQhB8IivADQRF+ICjCDwRF+IGgKn6f38y2S1ol6ZS7L8+mtUjaLWmRpBOS\nHnD39B8618z9Pn+trrjiimS90nDSvb29ZWtr165NLvvggw8m67t27UrW0Xzy/D7/TyXd8aVpj0g6\n6O7XSjqYvQcwjVQMv7sflvTlR9hWS9qRvd4h6Z6c+wJQZ9We87e6+/h4Rx9Kas2pHwANUvOz/e7u\nqXN5M+uW1F3regDkq9o9/0kzmy9J2e9T5WZ09z53b3f39irXBaAOqg3/XklrstdrJO3Jpx0AjVIx\n/Ga2S9J/SVpqZoNmtlbSZkkdZvaepL/J3gOYRiqe87t7V5nSbTn3EtaZM2dqWv6TTz6petl169Yl\n67t3707Wx8bGql43isUTfkBQhB8IivADQRF+ICjCDwRF+IGgGKJ7BpgzZ07Z2gsvvJBc9pZbbknW\n77zzzmT9wIEDyToajyG6ASQRfiAowg8ERfiBoAg/EBThB4Ii/EBQ3Oef4ZYsWZKsHz16NFkfGRlJ\n1l988cVkvb+/v2zt6aefTi7byH+bMwn3+QEkEX4gKMIPBEX4gaAIPxAU4QeCIvxAUNznD66zszNZ\nf+aZZ5L1uXPnVr3ujRs3Jus7d+5M1oeHh5P1qLjPDyCJ8ANBEX4gKMIPBEX4gaAIPxAU4QeCqnif\n38y2S1ol6ZS7L8+mPSppnaTfZ7NtdPdfVFwZ9/mnneXLlyfrW7duTdZvu636kdx7e3uT9U2bNiXr\nQ0NDVa97OsvzPv9PJd0xyfR/cfe27Kdi8AE0l4rhd/fDkk43oBcADVTLOX+Pmb1pZtvN7KrcOgLQ\nENWG/0eSlkhqkzQsaUu5Gc2s28z6zaz8H3MD0HBVhd/dT7r7RXcfk/RjSSsS8/a5e7u7t1fbJID8\nVRV+M5s/4W2npLfzaQdAo1xWaQYz2yXpO5K+YWaDkv5R0nfMrE2SSzoh6ft17BFAHfB9ftRk3rx5\nyfrdd99dtlbpbwWYpW9XHzp0KFnv6OhI1mcqvs8PIInwA0ERfiAowg8ERfiBoAg/EBS3+lCYL774\nIlm/7LL0Yyijo6PJ+u2331629tJLLyWXnc641QcgifADQRF+ICjCDwRF+IGgCD8QFOEHgqr4fX7E\ndsMNNyTr999/f7J+4403lq1Vuo9fycDAQLJ++PDhmj5/pmPPDwRF+IGgCD8QFOEHgiL8QFCEHwiK\n8ANBcZ9/hlu6dGmy3tPTk6zfe++9yfrVV199yT1N1cWLF5P14eHhZH1sbCzPdmYc9vxAUIQfCIrw\nA0ERfiAowg8ERfiBoAg/EFTF+/xmtlDSTkmtklxSn7v/0MxaJO2WtEjSCUkPuPvH9Ws1rkr30ru6\nusrWKt3HX7RoUTUt5aK/vz9Z37RpU7K+d+/ePNsJZyp7/lFJf+fuyyT9laT1ZrZM0iOSDrr7tZIO\nZu8BTBMVw+/uw+5+NHt9VtK7khZIWi1pRzbbDkn31KtJAPm7pHN+M1sk6duSjkhqdffx5ys/VOm0\nAMA0MeVn+83s65KelfQDdz9j9v/Dgbm7lxuHz8y6JXXX2iiAfE1pz29mX1Mp+D9z9+eyySfNbH5W\nny/p1GTLunufu7e7e3seDQPIR8XwW2kX/xNJ77r71gmlvZLWZK/XSNqTf3sA6qXiEN1mtlLSryW9\nJWn8O5IbVTrv/3dJ10j6rUq3+k5X+KyQQ3S3tqYvhyxbtixZf+qpp5L166677pJ7ysuRI0eS9See\neKJsbc+e9P6Cr+RWZ6pDdFc853f3/5RU7sNuu5SmADQPnvADgiL8QFCEHwiK8ANBEX4gKMIPBMWf\n7p6ilpaWsrXe3t7ksm1tbcn64sWLq+opD6+88kqyvmXLlmR9//79yfpnn312yT2hMdjzA0ERfiAo\nwg8ERfiBoAg/EBThB4Ii/EBQYe7z33TTTcn6hg0bkvUVK1aUrS1YsKCqnvLy6aeflq1t27Ytuezj\njz+erJ8/f76qntD82PMDQRF+ICjCDwRF+IGgCD8QFOEHgiL8QFBh7vN3dnbWVK/FwMBAsr5v375k\nfXR0NFlPfed+ZGQkuSziYs8PBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0GZu6dnMFsoaaekVkkuqc/d\nf2hmj0paJ+n32awb3f0XFT4rvTIANXN3m8p8Uwn/fEnz3f2omc2V9JqkeyQ9IOmcuz851aYIP1B/\nUw1/xSf83H1Y0nD2+qyZvSup2D9dA6Bml3TOb2aLJH1b0pFsUo+ZvWlm283sqjLLdJtZv5n119Qp\ngFxVPOz/w4xmX5f0sqRN7v6cmbVK+kil6wD/pNKpwUMVPoPDfqDOcjvnlyQz+5qkfZL2u/vWSeqL\nJO1z9+UVPofwA3U21fBXPOw3M5P0E0nvTgx+diFwXKekty+1SQDFmcrV/pWSfi3pLUlj2eSNkrok\ntal02H9C0vezi4Opz2LPD9RZrof9eSH8QP3ldtgPYGYi/EBQhB8IivADQRF+ICjCDwRF+IGgCD8Q\nFOEHgiL8QFCEHwiK8ANBEX4gKMIPBNXoIbo/kvTbCe+/kU1rRs3aW7P2JdFbtfLs7c+nOmNDv8//\nlZWb9bt7e2ENJDRrb83al0Rv1SqqNw77gaAIPxBU0eHvK3j9Kc3aW7P2JdFbtQrprdBzfgDFKXrP\nD6AghYTfzO4ws+Nm9r6ZPVJED+WY2Qkze8vMjhU9xFg2DNopM3t7wrQWM/uVmb2X/Z50mLSCenvU\nzIaybXfMzO4qqLeFZvaimQ2Y2Ttm9nA2vdBtl+irkO3W8MN+M5sl6TeSOiQNSnpVUpe7DzS0kTLM\n7ISkdncv/J6wmf21pHOSdo6PhmRm/yzptLtvzv7jvMrd/75JentUlzhyc516Kzey9N+qwG2X54jX\neShiz79C0vvu/oG7X5D0c0mrC+ij6bn7YUmnvzR5taQd2esdKv3jabgyvTUFdx9296PZ67OSxkeW\nLnTbJfoqRBHhXyDpdxPeD6q5hvx2SQfM7DUz6y66mUm0ThgZ6UNJrUU2M4mKIzc30pdGlm6abVfN\niNd544LfV61097+UdKek9dnhbVPy0jlbM92u+ZGkJSoN4zYsaUuRzWQjSz8r6QfufmZirchtN0lf\nhWy3IsI/JGnhhPffzKY1BXcfyn6fkvS8SqcpzeTk+CCp2e9TBffzB+5+0t0vuvuYpB+rwG2XjSz9\nrKSfuftz2eTCt91kfRW13YoI/6uSrjWzb5nZbEnfk7S3gD6+wszmZBdiZGZzJH1XzTf68F5Ja7LX\nayTtKbCXP9IsIzeXG1laBW+7phvx2t0b/iPpLpWu+P+PpH8ooocyfS2W9Eb2807RvUnapdJh4P+q\ndG1kraQ/lXRQ0nuS/kNSSxP19q8qjeb8pkpBm19QbytVOqR/U9Kx7Oeuorddoq9CthtP+AFBccEP\nCIrwA0ERfiAowg8ERfiBoAg/EBThB4Ii/EBQ/weCC5r/92q6mAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TJZsUf0dTgxp",
        "colab_type": "text"
      },
      "source": [
        "initial python model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xTGqT9u4TIk7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "weights = torch.rand(784,10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hAjf22dITnJc",
        "colab_type": "text"
      },
      "source": [
        "784 is input and 10 is output of model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t4f8-YveTmlJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bias = torch.zeros(10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pILrod-KTzTz",
        "colab_type": "text"
      },
      "source": [
        "We make a matrix multiplication"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5fTlmcoDTuW0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def matmul(a,b):\n",
        "    ar,ac = a.shape #n_rows * n_cols\n",
        "    br,bc = b.shape\n",
        "    assert ac==br\n",
        "    c = torch.zeros(ar,bc)\n",
        "    for i in range(ar):\n",
        "        for j in range(bc):\n",
        "            for k in range(ac): # or br\n",
        "                c[i,j] += a[i,k] * b[k,j]\n",
        "    return c\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ktqCq2DXSik",
        "colab_type": "text"
      },
      "source": [
        "do a small example"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4iCk4v2wXXQb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "m1 = x_valid[:5]\n",
        "m2 = weights"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w0ojEutKXXKv",
        "colab_type": "code",
        "outputId": "ba8c3331-7cba-402d-90be-8e61bdef0daa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "m1.shape,m2.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([5, 784]), torch.Size([784, 10]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XEBJGOUFWllU",
        "colab_type": "code",
        "outputId": "29448cc1-07be-4866-fa09-6420eb7405b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "%time t1 = matmul(m1,m2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 901 ms, sys: 10 µs, total: 901 ms\n",
            "Wall time: 919 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "trlLImhgXf4h",
        "colab_type": "code",
        "outputId": "65811db5-2428-4017-978f-c6afb6a97513",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "t1.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([5, 10])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tcggMgN6X2Rw",
        "colab_type": "code",
        "outputId": "76698a9b-1951-4180-e301-ba71f66e5a0b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(x_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L4e2jIYIXol_",
        "colab_type": "text"
      },
      "source": [
        "when our Mnist dataset has 50000 rows, it will take about 50000 seconds to do a single matrix multiplication in Python. So imaging doing Mnist for every layer for every pass took about 10 hours. It's not going to work right. We don't really write thing in Python when we say Python is too slow. It 's not just 20% too slow, we mean thousand of times too slow.\n",
        "\n",
        "let's see if we could speed it up by 50000 times. We can speed it up by starting in the innermost loop \n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "for k in range(ac): # or br\n",
        "                c[i,j] += a[i,k] * b[k,j]\n",
        "```\n",
        "\n",
        "and we make bit faster. The way to make Python faster is to remove Python by passing something that's written in something other than Python like Pytorch operations\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FXdLdL7wg381",
        "colab_type": "text"
      },
      "source": [
        "###Elementwise operations\n",
        "\n",
        "Operators (+,-,*,/,>,<,==) are usually element-wise.\n",
        "\n",
        "Examples of element-wise operations:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hLMDBMYCXl2k",
        "colab_type": "code",
        "outputId": "ab6277ac-581b-49e1-b4dc-737036b25f8e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "a = tensor([10.,6,-4])\n",
        "b = tensor([2.,8,7])\n",
        "a,b"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([10.,  6., -4.]), tensor([2., 8., 7.]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y0meErqEZ-Nq",
        "colab_type": "code",
        "outputId": "a4de5b32-6c4b-42a4-b347-27e1e4a11c1c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "a + b"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([12., 14.,  3.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "khkjVKoTaHvQ",
        "colab_type": "text"
      },
      "source": [
        "another example: using less than. what percentage of a less than the corresponding item of B."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5nUg5TI-Z_tS",
        "colab_type": "code",
        "outputId": "2f3f1c5e-83f7-4803-9a37-890f566f4838",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "(a<b).float().mean()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.6667)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oMjAng3uaiOn",
        "colab_type": "text"
      },
      "source": [
        "we can do element-wise operations not just on rank-1 tensor, also on rank-2 tensor known as matrix. Below is rank-2 tensor called m"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_oi8qO6UaaTx",
        "colab_type": "code",
        "outputId": "c3759714-ceae-4fd2-b4a2-c4cfeb931084",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "m = tensor([[1.,2,3],[4,5,6],[7,8,9]]); m"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 2., 3.],\n",
              "        [4., 5., 6.],\n",
              "        [7., 8., 9.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CiFqeVrJbFhz",
        "colab_type": "text"
      },
      "source": [
        "Now we learn how to calculate the formular name Frobenius norm:\n",
        "\n",
        "$\\|A\\|_{F}=\\left(\\sum_{i, j=1}^{n}\\left|a_{i j}\\right|^{2}\\right)^{1 / 2}$\n",
        "\n",
        "Now we can start try to translate some equations into code to help us understand these equations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EiT1G6IXa6b4",
        "colab_type": "code",
        "outputId": "26816524-e336-47ec-ce57-07b63bdc8ba8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "(m*m).sum().sqrt()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(16.8819)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dxDlDBZxcmRP",
        "colab_type": "text"
      },
      "source": [
        "Now we use this to replace the 3rd loop in matmul def\n",
        "\n",
        "```\n",
        "for k in range(ac): # or br\n",
        "                c[i,j] += a[i,k] * b[k,j]\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MbCIpZfocWwL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def matmul(a,b):\n",
        "    ar,ac = a.shape #n_rows * n_cols\n",
        "    br,bc = b.shape\n",
        "    assert ac==br\n",
        "    c = torch.zeros(ar,bc)\n",
        "    for i in range(ar):\n",
        "        for j in range(bc):\n",
        "            # any trailing \",:\" can be removed\n",
        "            c[i,j] = (a[i,:]*b[:,j]).sum()\n",
        "    return c\n",
        "    \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LDikCetvdmW1",
        "colab_type": "code",
        "outputId": "afbc1a4a-6861-44dc-bef6-62306a390a3a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%timeit -n 10 _=matmul(m1,m2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10 loops, best of 3: 1.59 ms per loop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ipsmw8M1150T",
        "colab_type": "code",
        "outputId": "978034a6-c3d6-4797-bae4-ad09cf784b67",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "890.1/5"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "178.02"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nd4hCLSpePUx",
        "colab_type": "text"
      },
      "source": [
        "it's 178 times faster. `c[i,j] = (a[i,:]*b[:,j]).sum()`this is not really Python thing, this line will call C code for us and that make 178 times faster.\n",
        "\n",
        "Now we will continue to remove the second loop in matmul def by using a technique called Broadcasting\n",
        "\n",
        "\n",
        "```\n",
        "for j in range(bc):\n",
        "            # any trailing \",:\" can be removed\n",
        "            c[i,j] = (a[i,:]*b[:,j]).sum()\n",
        "```\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MVRAJrAMgyZo",
        "colab_type": "text"
      },
      "source": [
        "###Broadcasting\n",
        "\n",
        "The term broadcasting describes how arrays with different shapes are treated during arithmetic operations. The term broadcasting was first used by Numpy.\n",
        "\n",
        "From the [Numpy Documentation](https://docs.scipy.org/doc/numpy-1.10.0/user/basics.broadcasting.html):\n",
        "\n",
        "\n",
        "```\n",
        "The term broadcasting describes how numpy treats arrays with \n",
        "different shapes during arithmetic operations. Subject to certain \n",
        "constraints, the smaller array is “broadcast” across the larger \n",
        "array so that they have compatible shapes. Broadcasting provides a \n",
        "means of vectorizing array operations so that looping occurs in C\n",
        "instead of Python. It does this without making needless copies of \n",
        "data and usually leads to efficient algorithm implementations.\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "In addition to the efficiency of broadcasting, it allows developers to write less code, which typically leads to fewer errors.\n",
        "\n",
        "This section was adapted from [Chapter 4 ](http://nbviewer.jupyter.org/github/fastai/numerical-linear-algebra/blob/master/nbs/4.%20Compressed%20Sensing%20of%20CT%20Scans%20with%20Robust%20Regression.ipynb#4.-Compressed-Sensing-of-CT-Scans-with-Robust-Regression)of the fast.ai [Computational Linear Algebra course](https://github.com/fastai/numerical-linear-algebra).\n",
        "\n",
        "Broadcasting is the most powerful tool for writing code in Python that runs at C speed or infact with Pytorch if you put it in GPU then it's going to run at CUDA speed. It allows us to get rid of nearly all of our loops\n",
        "\n",
        "**Broadcasting with a scalar**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZDldrpIphVK-",
        "colab_type": "code",
        "outputId": "8f255b16-af4b-4866-f596-52f25a6d04c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "a"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([10.,  6., -4.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tEg2EqY3dw6x",
        "colab_type": "code",
        "outputId": "f869d4dc-81ce-41ec-adce-87d771d2424f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "a > 0"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 1, 0], dtype=torch.uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FsueTqCwiWcU",
        "colab_type": "text"
      },
      "source": [
        "the value 0 is broadcast three times. it does element-wise comparision. You are broadcasting a scaler to a tensor.\n",
        "\n",
        "How are we able to do a > 0? 0 is being broadcast to have the same dimensions as a.\n",
        "\n",
        "For instance you can normalize our dataset by subtracting the mean (a scalar) from the entire data set (a matrix) and dividing by the standard deviation (another scalar), using broadcasting.\n",
        "\n",
        "Other examples of broadcasting with a scalar:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xH6iqOApiL8z",
        "colab_type": "code",
        "outputId": "4156abbf-8ec9-4b00-e087-36f24fa77bf5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "a +1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([11.,  7., -3.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qOuTrUqTi1Ek",
        "colab_type": "code",
        "outputId": "6b533cb7-6e9d-4188-c2ec-e4be22c4b67c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "m"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 2., 3.],\n",
              "        [4., 5., 6.],\n",
              "        [7., 8., 9.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Xo-5rmji7xd",
        "colab_type": "code",
        "outputId": "6ec5f075-82f5-4512-c772-97cf5de4699c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "2*m"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 2.,  4.,  6.],\n",
              "        [ 8., 10., 12.],\n",
              "        [14., 16., 18.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZWl6VGn6i_AQ",
        "colab_type": "text"
      },
      "source": [
        "this is the simplest kind of broadcasting. Anytime you are doing that, you re' not operating at Python speed , you're operating at C or CUDA speed.\n",
        "\n",
        "We can also **broadcast a vector to a matrix**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ybDO86bUi87r",
        "colab_type": "code",
        "outputId": "605a048b-1242-470a-eb9a-6a3f150f98d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "c = tensor([10.,20,30]); c\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([10., 20., 30.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d-hhjBZ7jg7A",
        "colab_type": "code",
        "outputId": "bd8c9e29-d275-4fc6-cbcf-7b8d96d4c50a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "m"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 2., 3.],\n",
              "        [4., 5., 6.],\n",
              "        [7., 8., 9.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LRwkz-2Sjih1",
        "colab_type": "code",
        "outputId": "a47f7ed9-5f86-4b37-df45-dabc100d686a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "m.shape,c.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([3, 3]), torch.Size([3]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qvsi3FzyjkVJ",
        "colab_type": "code",
        "outputId": "d6e63fc1-dd89-460d-ac5f-0d0cf344bbd6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "m + c"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[11., 22., 33.],\n",
              "        [14., 25., 36.],\n",
              "        [17., 28., 39.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "noPJlsjSrOJX",
        "colab_type": "text"
      },
      "source": [
        "again all there was loop behind the m+c but it is a C loop not Python loop. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vEtpYjy8jq2y",
        "colab_type": "code",
        "outputId": "6b76f95c-fe43-40f7-c23e-54e6f64ee4c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "c + m"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[11., 22., 33.],\n",
              "        [14., 25., 36.],\n",
              "        [17., 28., 39.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "me-gL2ScryTr",
        "colab_type": "text"
      },
      "source": [
        "We don't really copy the rows, but it looks as if we did. In fact, the rows are given a stride of 0."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "26NHAlSMrqdD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "t = c.expand_as(m)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DVe-tB9tr5fQ",
        "colab_type": "text"
      },
      "source": [
        "`c.expand_as (m)` shows us what C looks like when broadcast to **m**. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O8l4jixqr3Ih",
        "colab_type": "code",
        "outputId": "ddc6e654-2500-407d-e18c-dbd483be5604",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "t"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[10., 20., 30.],\n",
              "        [10., 20., 30.],\n",
              "        [10., 20., 30.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pU2v-0O5sMJL",
        "colab_type": "text"
      },
      "source": [
        "then m + t is the same as c + m"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H9IGhQD4r4bv",
        "colab_type": "code",
        "outputId": "a4b08a9a-9347-453b-f916-c09468755d21",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "m + t"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[11., 22., 33.],\n",
              "        [14., 25., 36.],\n",
              "        [17., 28., 39.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I5xY5SvFsZ0m",
        "colab_type": "text"
      },
      "source": [
        "so it's actually if it is creating this bigger rank-2 tensor. \n",
        "\n",
        "You may worry t shape look very memory intensive if turning all our rows into a big matrices but fear not. Because you can look inside the actually memory use by pytorch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3XVDR-ANsS8q",
        "colab_type": "code",
        "outputId": "3626335e-690c-44c1-ab74-164a956fcb89",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "t.storage()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              " 10.0\n",
              " 20.0\n",
              " 30.0\n",
              "[torch.FloatStorage of size 3]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jQghHu9ztX3b",
        "colab_type": "text"
      },
      "source": [
        "t matrices above 3 copies of row but actually t.storage() show that the system only store one copy of that data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "37gLFK28tCe4",
        "colab_type": "code",
        "outputId": "ec1a2902-cb09-4677-bc5c-b18400e50191",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "t.stride(),t.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((0, 1), torch.Size([3, 3]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U77OcsTJtl9f",
        "colab_type": "text"
      },
      "source": [
        "t.shape tell us it is 3x3 matrix and t.stride() tells us that it knows when it 's going from column to column it should take 1 step through the storage .But when it goes from row to row it should take zero step so that how come it repeat 10 20 30 10 20 30 10 20 30 . This is very powerful thing that appear in pretty much linear algebra library . Conclusion : Broadcasting functionality gives us C like speed but with no addtional memory overhead.\n",
        "\n",
        "**What if we want to take column instead of the row**. We can have tensor of shape (3,1) from a rank-1 tensor by using the **unsqueeze(1)**. Unsqueeze(1) add addtional dimension of size one to where we ask for."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V1kr3Mh2tZ4X",
        "colab_type": "code",
        "outputId": "b21403b6-b65f-481a-a781-83faa33d2e9a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "c"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([10., 20., 30.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oWRVZ44yvEdw",
        "colab_type": "code",
        "outputId": "4fe3fa29-f859-4fec-88bf-01cf97f68f3b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "c.unsqueeze(0)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[10., 20., 30.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3kgnmQpSvJ55",
        "colab_type": "code",
        "outputId": "a42b9e0a-3834-480a-eac9-5cefd3bdf6c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "c.unsqueeze(1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[10.],\n",
              "        [20.],\n",
              "        [30.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8MoQ8wBvwa42",
        "colab_type": "code",
        "outputId": "5e157c14-2fc3-482d-b4b3-a59b6ffc7291",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "m"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 2., 3.],\n",
              "        [4., 5., 6.],\n",
              "        [7., 8., 9.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g88F07Mjv6p2",
        "colab_type": "text"
      },
      "source": [
        "You can index with the special value [None] or use unsqueeze() to convert a 1-dimensional array into a 2-dimensional array (although one of those dimensions has value 1).\n",
        "\n",
        "c[None , :] means squeeze a new axis in here."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nf5AKZ1xvMoc",
        "colab_type": "code",
        "outputId": "c0229155-5717-46e1-b8d9-041deee6d286",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "c.shape,c.unsqueeze(0).shape,c.unsqueeze(1).shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([3]), torch.Size([1, 3]), torch.Size([3, 1]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5tzEiGL3wZr9",
        "colab_type": "code",
        "outputId": "c3cc31a9-3aed-4fee-9184-c313fefce19c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "c.shape,c[None,:].shape,c[:,None].shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([3]), torch.Size([1, 3]), torch.Size([3, 1]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lk8PQ-ezxF1N",
        "colab_type": "text"
      },
      "source": [
        "You can always skip trailling ':'s. And '...' means 'all preceding dimensions'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4qHtAB3pwsak",
        "colab_type": "code",
        "outputId": "109c8fe1-9916-4554-fd72-e101434f45de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "c[None].shape,c[...,None].shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([1, 3]), torch.Size([3, 1]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "byk2ad-7zfrl",
        "colab_type": "text"
      },
      "source": [
        "c[...,None] -> the ... are used in high rank tensor, especial it would vary , you don't know how big it's going to be ahead"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yCaJqVCFxN6-",
        "colab_type": "code",
        "outputId": "afc4bbee-23dc-47c0-a8b4-82a6c020241a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "c[:,None].expand_as(m)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[10., 10., 10.],\n",
              "        [20., 20., 20.],\n",
              "        [30., 30., 30.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "twv24WaWxiTF",
        "colab_type": "text"
      },
      "source": [
        "this broadcast along the columns instead of rows. When I use c[:,None] to add to m, we are broadcasting the columns instead of row. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P6OQcGa3xe9I",
        "colab_type": "code",
        "outputId": "70ebc972-03c8-40ea-8950-f41ff2b1b55f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "m + c[:,None]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[11., 12., 13.],\n",
              "        [24., 25., 26.],\n",
              "        [37., 38., 39.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "abmAbSe0ya4A",
        "colab_type": "text"
      },
      "source": [
        "Now we can use this to get rig of the loop\n",
        "\n",
        "\n",
        "```\n",
        "for j in range(bc):\n",
        "            # any trailing \",:\" can be removed\n",
        "            c[i,j] = (a[i,:]*b[:,j]).sum()\n",
        "```\n",
        "\n",
        "Now so it is:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DNn8LCb5x3gb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def matmul(a,b):\n",
        "    ar,ac = a.shape\n",
        "    br,bc = b.shape\n",
        "    assert ac==br\n",
        "    c = torch.zeros(ar,bc)\n",
        "    for i in range(ar):\n",
        "        for j in range(bc):\n",
        "            \n",
        "            c[i:] = (a[i ].unsqueeze(-1)*b).sum(dim=0)\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gkphi3i0z7Nz",
        "colab_type": "text"
      },
      "source": [
        "as a[i ] is rank-1 tensor. Now we turn it into rank-2 tensor by adding unsqueeze(-1). -1 always means the last dimension.\n",
        "\n",
        "- `a[i].unsqueeze(1)` can be rewrite into `a[i,None]` \n",
        "- b is also rank-2 tensor\n",
        "\n",
        "Finally, it would get broadcast over this which return a rank-2 tensor. \n",
        "\n",
        "- we then want to sum it over rows\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aifm7Vg11JAr",
        "colab_type": "code",
        "outputId": "361ae594-4419-4514-fe3c-f2d777c9ebd7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%timeit -n 10 _=matmul(m1,m2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10 loops, best of 3: 3.22 ms per loop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kmiVLov21MUM",
        "colab_type": "code",
        "outputId": "1ec1e322-be54-4cb3-d3c1-21b4c7d3165c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "885000/277"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3194.945848375451"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qH1EZRaT2Ozk",
        "colab_type": "text"
      },
      "source": [
        "**There are some broadcasting rules**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bZ3ty43A11n5",
        "colab_type": "code",
        "outputId": "1aed83a1-3da0-4dcf-a006-04fa0c9ef77f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "c[None,:]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[10., 20., 30.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mFVegGg72V3h",
        "colab_type": "code",
        "outputId": "d64aa3b7-8d06-4f99-9431-7673172685d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "c[None,:].shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 3])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gt0j4Ozc2X7P",
        "colab_type": "code",
        "outputId": "843ccf6a-0205-4eba-b9f1-9c27825c6905",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "c[:,None]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[10.],\n",
              "        [20.],\n",
              "        [30.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tmN5k4Rn2a1z",
        "colab_type": "code",
        "outputId": "4a4b5f17-db45-4516-ae94-c93a01e6364e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "c[:,None].shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bZzHxr2q2eB7",
        "colab_type": "code",
        "outputId": "5a9710f6-e012-4754-c267-8a77673b16ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "c[None,:] * c[:,None]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[100., 200., 300.],\n",
              "        [200., 400., 600.],\n",
              "        [300., 600., 900.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dQ277zhx2j_G",
        "colab_type": "code",
        "outputId": "975d199a-5310-4e72-c755-8b054da4b6f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "c[None,:] > c[:,None]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0, 1, 1],\n",
              "        [0, 0, 1],\n",
              "        [0, 0, 0]], dtype=torch.uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NNZr2ag-2q7E",
        "colab_type": "text"
      },
      "source": [
        "When operating on two arrays/tensors, Numpy/PyTorch compares their shapes element-wise. It starts with the trailing dimensions, and works its way forward. Two dimensions are compatible when\n",
        "\n",
        "    - they are equal, or\n",
        "    - one of them is 1, in which case that dimension is broadcasted to make it the same size\n",
        "    \n",
        "Arrays do not need to have the same number of dimensions. For example, if you have a 256*256*3 array of RGB values, and you want to scale each color in the image by a different value, you can multiply the image by a one-dimensional array with 3 values. Lining up the sizes of the trailing axes of these arrays according to the broadcast rules, shows that they are compatible:\n",
        "\n",
        "\n",
        "```\n",
        "mage  (3d array): 256 x 256 x 3\n",
        "Scale  (1d array):             3\n",
        "Result (3d array): 256 x 256 x 3\n",
        "```\n",
        "\n",
        "The numpy documentation includes several examples of what dimensions can and can not be broadcast together."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GipOJkztX2Uj",
        "colab_type": "text"
      },
      "source": [
        "###Einstein summation\n",
        "\n",
        "Einstein summation (einsum) is a compact representation for combining products and sums in a general way. From the numpy docs:\n",
        "\n",
        "\"The subscripts string is a comma-separated list of subscript labels, where each label refers to a dimension of the corresponding operand. Whenever a label is repeated it is summed, so **np.einsum('i,i', a, b)** is equivalent to np.inner(a,b). If a label appears only once, it is not summed, so **np.einsum('i', a)** produces a view of a with no changes.\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g8AuxEU12oPQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# c[i,j] += a[i,k] * b[k,j]\n",
        "# ik,kj -> ij\n",
        "# c[i,j] = (a[i,:] * b[:,j]).sum()\n",
        "def matmul(a,b) : return torch.einsum('ik,kj->ij',a,b)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vn2vRGgVYuda",
        "colab_type": "code",
        "outputId": "a5764dab-07ca-46ee-a808-32d8597f9ee6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "%timeit -n 10 _=matmul(m1,m2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The slowest run took 46.32 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
            "10 loops, best of 3: 52.2 µs per loop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FF2g3gcOY0FV",
        "colab_type": "code",
        "outputId": "e07022e9-8582-4e0d-8d6e-d6c9ba4c1438",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "885000/55"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "16090.90909090909"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3B17Tn7PalyS",
        "colab_type": "text"
      },
      "source": [
        "###Pytorch operation\n",
        "\n",
        "Next thing to show is pytorch operation called matmul. And matmul boost the speed to 50000 times faster than python. WHY? \n",
        "\n",
        "- When you do a matrix multiplication of something that's like 50000 x 768 x 768 x 10. This things are going to fit in like cache in your CPU. So if you do the kind of standard thing of going down all the rows and across all the columns. By the time you cut to the end and you go back to exactly the same column again and it forgot contents, it has to go back to RAM and pull it in again right. So if you re smart what you do is you break your matrix up into litlle smaller matrices and you do a little bit at a time. That way everything is kind of in cache and it goes super fast now. Normally to do that you have to write kind of assembly language code, particulary if you want to kind of get it all runnning in your vector precessor. And that's how you get these 18 microseconds. Currently to get a fast matrix mutiply, things like pytorch that they don't even write it themselves, they basically push that off to something called a blas. Blas is a basic linear algebra subprograms library where companies like Intel, AMD, NVIDIA draft these things for you. For example. cuBlas of Nvidia"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vsxwfbb4Y4cr",
        "colab_type": "code",
        "outputId": "0b6f064e-29fe-4a70-f3dd-60697961fb8c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "%timeit -n 10 t2 = m1.matmul(m2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The slowest run took 66.26 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
            "10 loops, best of 3: 10.9 µs per loop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cJ4RGGDNmDy_",
        "colab_type": "text"
      },
      "source": [
        "the matmul operation is written in one thing that to be turned that pre-existing blas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sWXlWdNPlRlw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "t2 = m1@m2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3AAtWFcknSaT",
        "colab_type": "text"
      },
      "source": [
        "@ is annotation of matmul so they are exact same code with same speed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aXlaNl54wNa0",
        "colab_type": "text"
      },
      "source": [
        "## Relu/init -> FC forward -> BC forward\n",
        "\n",
        "Firstly we create a nomalization function that takes our tensor and subtracts the mean and divides by the standard deviation function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XclJwSyPnRe5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def normalize(x, m, s): return (x-m)/s"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tUXV4C0jxqhk",
        "colab_type": "text"
      },
      "source": [
        "Then let's grab the mean and the std"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PKv-PKSCx1JR",
        "colab_type": "code",
        "outputId": "59f9ddf7-ac28-47b1-cb81-93799a4e8017",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_mean,train_std = x_train.mean(),x_train.std()\n",
        "train_mean,train_std"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.1304), tensor(0.3073))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G7FtODkuyDpZ",
        "colab_type": "text"
      },
      "source": [
        "I notice that they are not 0 and 1. Why? Currently Jeremy states that we want they are 0 and 1. will find out later\n",
        "\n",
        "Before that we will normalize x_train and x_valid. And to make sure x_train and x_valid have same scale by normalizing in the same way."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "trD1BKAsx_0b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = normalize(x_train,train_mean,train_std)\n",
        "# NB : Use training, not validation mean for validation set\n",
        "x_valid = normalize(x_valid,train_mean,train_std)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J3eaWvNXzQJT",
        "colab_type": "code",
        "outputId": "9b6738b6-9bdf-4733-d46f-d5bd12bd5429",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_mean,train_std = x_train.mean(),x_train.std()\n",
        "train_mean,train_std"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.0001), tensor(1.))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jBQV16W-zdae",
        "colab_type": "text"
      },
      "source": [
        "Now train_mean is close 0 and train_std is close to 1. To check these are true, we create a function called test_near_zero"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NwuuWR60zaFE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test_near_zero(a,tol=1e-3): assert a.abs()<tol, f'Near zero:{a}'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fVP07tWjz6uu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_near_zero(x_train.mean())\n",
        "test_near_zero(1-x_train.std())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7AcWGgyy0HXL",
        "colab_type": "code",
        "outputId": "6ce49db2-60be-495a-94df-be3ff6b57983",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "n,m = x_train.shape\n",
        "c = y_train.max()+1\n",
        "n,m,c"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 784, tensor(10))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C0D4C8Xm0Xmt",
        "colab_type": "text"
      },
      "source": [
        "n : number of rows\n",
        "\n",
        "m : number of columns\n",
        "\n",
        "c: number of outputs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-SuzSRf2YgQf",
        "colab_type": "text"
      },
      "source": [
        "### Create a model\n",
        "\n",
        "- one hidden layer\n",
        "- output with 10 activations. But we don't use cross entropy to get 10 activation. We will use mean squared error which means we going to have one activation. We will fix this later as we try to simplify things for now\n",
        "\n",
        "**Basic architecture**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "robwy3Wo0W3z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# num of hidden\n",
        "nh =50"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lEk6vJDzbCNJ",
        "colab_type": "text"
      },
      "source": [
        "for two layers, we re going to need two weight matrices and two bias vectors\n",
        "\n",
        "- w1 : randomize a matrix with m: columns,768 by nh: number of hidden,50\n",
        "- w2 : randomize a matrix with nh by 1 output\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Hyn2mA3a9Wr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# simplified kaiming init / he init\n",
        "w1 = torch.randn(m,nh)/math.sqrt(m)\n",
        "b1 = torch.zeros(nh)\n",
        "w2 = torch.randn(nh,1)/math.sqrt(nh)\n",
        "b2 = torch.zeros(1)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sxTZTr1ufSsg",
        "colab_type": "text"
      },
      "source": [
        "Note that we have input in the first layer with mean 0 and std 1, we also want the input in the second layer with mean 0 and std 1 well. How we are going to do that? Because if just grab some normal random number and we define a linear function called lin. We make the t, output of activattion with X_valid, weight 1 and bias 1. We have t.mean is 1 and t.std is 27 which are very terrible\n",
        "\n",
        "![alt text](https://github.com/hduongck/AI-ML-Learning/blob/master/Pic/model%20architecture.png?raw=true)\n",
        "\n",
        "But instead if we initialize the weights by adding dividing by math.sqrt() then the result is actually good"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YBKjD96Cc5L1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_near_zero(w1.mean())\n",
        "test_near_zero(w1.std()-1/math.sqrt(m))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jt_WSufhdFHK",
        "colab_type": "code",
        "outputId": "c8eb41c1-969d-450e-807b-b1fbd40cff06",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# This should be ~ (0,1) (mean,std)...\n",
        "x_train.mean(),x_train.std()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.0001), tensor(1.))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l4GnAIOBdM03",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def lin(x,w,b): return x@w + b"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fwYx9oCddTPc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "t = lin(x_valid,w1,b1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yKfLu6IcdYXA",
        "colab_type": "code",
        "outputId": "ceaac1b3-42a4-4cb9-f7a4-f03f83c8cdc4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "t.mean(),t.std()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(-0.0356), tensor(0.9623))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DZpQd4CyclNP",
        "colab_type": "text"
      },
      "source": [
        "This method called Kaiming initialization which after we randomize then we add dividing by math.sqrt() which would give us mean of 0 and standard deviation of 1.\n",
        "\n",
        "**def lin(x,w,b): return x@w + b** is not how our first layer is defined. It is defined by ReLU on it\n",
        "\n",
        "\n",
        "```\n",
        "t = relu(lin(x_valid, w1, b1))\n",
        "```\n",
        "\n",
        "Now we define ReLU\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UCrtdtUqcoBu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def relu(x) : return x.clamp_min(0.) # replace any negative with 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-SVh4lylhiX7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "t = relu(lin(x_valid,w1,b1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Uw0BFZPhmY2",
        "colab_type": "code",
        "outputId": "710e729b-68c1-4010-ef9c-2ffc93ab6d4c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "t.mean(),t.std()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.3627), tensor(0.5508))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iCV6DaQthqBH",
        "colab_type": "text"
      },
      "source": [
        "Unfortunately, that does not give mean of 0 or std of 1. Why not? explained in the pic below\n",
        "\n",
        "![alt text](https://github.com/hduongck/AI-ML-Learning/blob/master/Pic/Annotation%202019-07-01%20145636.png?raw=true)\n",
        "\n",
        "There is a fantastic insights [paper](https://arxiv.org/abs/1502.01852) look into this problem.\n",
        "\n",
        "In the paper, it recommend :\n",
        "\n",
        "From pytorch docs: a: the negative slope of the rectifier used after this layer (0 for ReLU by default)\n",
        "\n",
        "$$\\text{std} = \\sqrt{\\frac{2}{(1 + a^2) \\times \\text{fan_in}}}$$\n",
        "\n",
        "This was introduced in the paper that described the Imagenet-winning approach from He et al: Delving Deep into Rectifiers, which was also the first paper that claimed \"super-human performance\" on Imagenet (and, most importantly, it introduced resnets!)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "th9NN-iyhn5-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# kaiming init / he init for relu\n",
        "w1 = torch.randn(m,nh)*math.sqrt(2/m)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_HmPwoE6kc8A",
        "colab_type": "code",
        "outputId": "247883ad-4dbf-45f4-aec7-7e97fce8a437",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "w1.mean(),w1.std()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(-0.0001), tensor(0.0503))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2bWqqE5ckiXr",
        "colab_type": "code",
        "outputId": "f2912cf6-f0d7-41c5-bb58-d39c6af72c58",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "t = relu(lin(x_valid,w1,b1))\n",
        "t.mean(),t.std()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.5573), tensor(0.8265))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VFqo0cGXk1Qq",
        "colab_type": "text"
      },
      "source": [
        "The std result is much closer to 1 although not perfect. But it still does not give us very nice mean as we saw we deleted everything belwo 0. So naturally our mean is 0.5 not 0. There is solution that Jeremy recommend by modyfing the relu() function\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "def relu(x): return x.clamp_min(0.) - 0.5\n",
        "```\n",
        "\n",
        "This would give us nice mean."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gDy6BWG7knr_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.nn import init"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tgisg2AdmVIC",
        "colab_type": "text"
      },
      "source": [
        "Now we replace \n",
        "\n",
        "```\n",
        "w1 = torch.randn(m,nh)*math.sqrt(2/m)\n",
        "```\n",
        "by \n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "init.kaiming_normal(w1,mode='fan_out')\n",
        "```\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tfpKoenimRaa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "w1 = torch.randn(m,nh)\n",
        "init.kaiming_normal_(w1,mode='fan_out')\n",
        "t = relu(lin(x_valid,w1,b1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FvZEtYS1m5kC",
        "colab_type": "text"
      },
      "source": [
        "let's check if we have same result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UT1Yd8Cmm0H_",
        "colab_type": "code",
        "outputId": "12572586-0a94-4673-df15-69423558c355",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "t.mean(),t.std()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.5566), tensor(0.8456))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FfStqxgAnFYU",
        "colab_type": "text"
      },
      "source": [
        "Notice in init.kaiming_normal_ we add something extra with mode ='fan_out'. This means it is used for backward pass to keep the unit variance. Because our weight w1's shape is 784 by 50"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TL0z3hNKpD0-",
        "colab_type": "code",
        "outputId": "1795fd20-8fea-4695-9c53-d81756d6caf3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "w1.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([784, 50])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EYqiy_uWm_dy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rZMQ9PXmovz7",
        "colab_type": "code",
        "outputId": "3187b051-826f-4ca6-b278-78510128c21d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "torch.nn.Linear(m,nh).weight.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([50, 784])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3JjD0Ekjo0Oc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.nn.Linear.forward??"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sH5BNUAzo4XS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.nn.functional.linear??"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cAO23zuIpPPO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.nn.Conv2d??"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "URg2Qa_tpU8t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.nn.modules.conv._ConvNd.reset_parameters??"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L1zg9YTHq4xc",
        "colab_type": "text"
      },
      "source": [
        "get back to model. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QejEh6bfpaUe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def relu(x): return x.clamp_min(0.) - 0.5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eYk-1_n_rk1C",
        "colab_type": "code",
        "outputId": "022a8dee-2c61-4cf9-cc7e-345d0619f062",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "w1 = torch.randn(m,nh)*math.sqrt(2./m)\n",
        "t1 = relu(lin(x_valid,w1,b1))\n",
        "t1.mean(),t1.std()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.0753), tensor(0.8512))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rXC5Bqufr5k2",
        "colab_type": "text"
      },
      "source": [
        "Now I have mean of 0. It also somehow help my std closer to 1. \n",
        "\n",
        "So far, we have relu, linear, ... , we can now do a forward pass"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rGN9xXNNr0uv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model(xb):\n",
        "    l1 = lin(xb,w1,b1)\n",
        "    l2 = relu(l1)\n",
        "    l3 = lin(l2,w2,b2)\n",
        "    return l3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1t5TUlhAspNj",
        "colab_type": "code",
        "outputId": "633b267b-ae08-4d77-8b7d-e5da19b35986",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%timeit -n 10 _= model(x_valid)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10 loops, best of 3: 20.9 ms per loop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oiXRWBQWtUA_",
        "colab_type": "text"
      },
      "source": [
        "Add an assert to make sure this shape seems sensible "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Q-RuVCYswZj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "assert model(x_valid).shape ==torch.Size([x_valid.shape[0],1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YOv5pJ98tQ9e",
        "colab_type": "text"
      },
      "source": [
        "The next thing we need for a forward pass is a loss function as I said we use MSE to simply thing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J9o4vWr1tnVF",
        "colab_type": "text"
      },
      "source": [
        "### Loss function: MSE\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rEYhLUWctNDB",
        "colab_type": "code",
        "outputId": "66c73c05-b1a6-4e3c-db19-7ea492f9a770",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "model(x_valid).shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([10000, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kCnFndfCt0se",
        "colab_type": "text"
      },
      "source": [
        "Our model return something of size 10000 by 1 but the MSE expect a single vector of size 10000. So we want to get rig of unit axis. In Pytorch we use squeeze\n",
        "\n",
        "We need squeeze() to get rid of that trailing (,1), in order to use mse. (Of course, mse is not a suitable loss function for multi-class classification; we'll use a better loss function soon. We'll use mse for now to keep things simple.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ekZ2SxHitt_B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def mse(output,targ): return (output.squeeze(-1) - targ).pow(2).mean()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GzDrhhifu2Na",
        "colab_type": "text"
      },
      "source": [
        "in MSE, we make sure the value are float"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pqsz-yZKufk1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train,y_valid = y_train.float(),y_valid.float()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ltOXT7RPvAZo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "preds = model(x_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YwcToVtUvFgM",
        "colab_type": "code",
        "outputId": "6b843e3d-748d-4f2c-9c3a-190f1c9a64f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "preds.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([50000, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GPhzBuEfvTd6",
        "colab_type": "text"
      },
      "source": [
        "we calculate mse"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6S6lNPpWvJQr",
        "colab_type": "code",
        "outputId": "74b63de2-65aa-4329-bd18-7178fde5610a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "mse(preds,y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(27.4439)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rWqiET7YvSL0",
        "colab_type": "text"
      },
      "source": [
        "Now we have done a forward pass. A forward pass is actually useless , what we need is a backward pass because that thing tells us how to update our parameters. So now we need gradients."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1UWL-L0qv1ki",
        "colab_type": "text"
      },
      "source": [
        "### Gradient and backward pass"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ASh4bAedvMpt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "No"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}