{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "5_Language_Modeling_&_Sentiment_Analysis_of_IMDB.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hduongck/AI-ML-Learning/blob/master/Fastai%20NLP%20course/5_Language_Modeling_%26_Sentiment_Analysis_of_IMDB.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E95zYoA_zPbB",
        "colab_type": "text"
      },
      "source": [
        "This lesson was adapted from the end of [lesson 3](https://course.fast.ai/videos/?lesson=3) and beginning of [lesson 4](https://course.fast.ai/videos/?lesson=4) of the latest fast.ai Practical Deep Learning for Coders course. We will cover all the material you need here in this notebook, so no need to have taken the Deep Learning course. Even if you have taken the DL class, we will go slower and get into more detail here!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GROOPe6JzXYY",
        "colab_type": "text"
      },
      "source": [
        "# Language Modeling & Sentiment Analysis of IMDB movie reviews\n",
        "\n",
        "[Video 8](https://youtu.be/PNNHaQUQqW8)\n",
        "\n",
        "We will be looking at IMDB movie reviews. We want to determine if a review is negative or positive, based on the text. In order to do this, we will be using transfer learning.\n",
        "\n",
        "Transfer learning has been widely used with great success in computer vision for several years, but only in the last year or so has it been successfully applied to NLP (beginning with ULMFit, which we will use here, which was built upon by BERT and GPT-2).\n",
        "\n",
        "As Sebastian Ruder wrote in [The Gradient](https://thegradient.pub/) last summer, [NLP's ImageNet moment has arrived](https://thegradient.pub/nlp-imagenet/)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z9LhSqqd1PFk",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "## Language Models\n",
        "\n",
        "Language modeling can be a fun creative form. Research scientist[ Janelle Shane blogs](https://aiweirdness.com/) & [tweets](https://twitter.com/JanelleCShane) about her creative AI explorations, which often involve text. For instance, see her:\n",
        "\n",
        "- [Why did the neural network cross the road?](https://aiweirdness.com/post/174691534037/why-did-the-neural-network-cross-the-road)\n",
        "- [Try these neural network-generated recipes at your own risk.](https://aiweirdness.com/post/163878889437/try-these-neural-network-generated-recipes-at-your)\n",
        "- [D&D character bios - now making slightly more sense](https://aiweirdness.com/post/183471928977/dd-character-bios-now-making-slightly-more)\n",
        "\n",
        "**Using a GPU**\n",
        "\n",
        "You will need to have the fastai library installed for this lesson, and you will want to use a GPU to train your neural net. If you don't have a GPU you can use in your computer (currently, only Nvidia GPUs are fully supported by the main deep learning libraries), no worries! There are a number of cloud options you can consider:\n",
        "\n",
        "**[GPU Cloud Options](https://course.fast.ai/#using-a-gpu)**\n",
        "\n",
        "Reminder: If you are using a cloud GPU, always be sure to shut it down when you are done!!! Otherwise, you could end up with an expensive bill!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qyZ2JOxUxOSd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%reload_ext autoreload\n",
        "%autoreload 2\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "60konr2G1911",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from fastai import *\n",
        "from fastai.text import *"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CLf1x3rF7Qap",
        "colab_type": "text"
      },
      "source": [
        "Note that language models can use a lot of GPU, so you may need to decrease batchsize here."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-HAdnt1Z2CJa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bs = 48"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uvpZ_Bd67bnD",
        "colab_type": "text"
      },
      "source": [
        "### Preparing the data (on a sample)\n",
        "\n",
        "First let's download the dataset we are going to study. The dataset has been curated by Andrew Maas et al. and contains a total of 100,000 reviews on IMDB. 25,000 of them are labelled as positive and negative for training, another 25,000 are labelled for testing (in both cases they are highly polarized). The remaning 50,000 is an additional unlabelled data (but we will find a use for it nonetheless).\n",
        "\n",
        "We'll begin with a sample we've prepared for you, so that things run quickly before going over the full dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bNQ_LF3Z7S7d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path = untar_data(URLs.IMDB_SAMPLE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "52KbXLJn7hQB",
        "colab_type": "code",
        "outputId": "32ed0447-b34a-4bb5-f8d7-9c60e6a5cc80",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "path.ls()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[PosixPath('/root/.fastai/data/imdb_sample/texts.csv')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OXY67AXx7sxG",
        "colab_type": "text"
      },
      "source": [
        "It only contains one csv file, let's have a look at it.\n",
        "\n",
        "It contains one line per review, with the label ('negative' or 'positive'), the text and a flag to determine if it should be part of the validation set or the training set. If we ignore this flag, we can create a DataBunch containing this data in one line of code:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dhfiT9Rp7jq0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_lm = TextDataBunch.from_csv(path,'texts.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zw7jNn3P8ADh",
        "colab_type": "text"
      },
      "source": [
        "By executing this line a process was launched that took a bit of time. Let's dig a bit into it. Images could be fed (almost) directly into a model because they're just a big array of pixel values that are floats between 0 and 1. A text is composed of words, and we can't apply mathematical functions to them directly. We first have to convert them to numbers. This is done in two differents steps: tokenization and numericalization. A TextDataBunch does all of that behind the scenes for you.\n",
        "\n",
        "Before we delve into the explanations, let's take the time to save the things that were calculated."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_GCOlbDJ91qS",
        "colab_type": "text"
      },
      "source": [
        "### Tokenization\n",
        "\n",
        "The first step of processing we make texts go through is to split the raw sentences into words, or more exactly tokens. The easiest way to do this would be to split the string on spaces, but we can be smarter:\n",
        "\n",
        "- we need to take care of punctuation\n",
        "- some words are contractions of two different words, like isn't or don't\n",
        "- we may need to clean some parts of our texts, if there's HTML code for instance\n",
        "\n",
        "To see what the tokenizer had done behind the scenes, let's have a look at a few texts in a batch.\n",
        "\n",
        "The texts are truncated at 100 tokens for more readability. We can see that it did more than just split on space and punctuation symbols:\n",
        "\n",
        "- the \"'s\" are grouped together in one token\n",
        "- the contractions are separated like his: \"did\", \"n't\"\n",
        "- content has been cleaned for any HTML symbol and lower cased\n",
        "- there are several special tokens (all those that begin by xx), to replace unkown tokens (see below) or to introduce different text fields (here we only have one)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kBT-iBnh-Nkt",
        "colab_type": "text"
      },
      "source": [
        "### Numericalization\n",
        "\n",
        "Once we have extracted tokens from our texts, we convert to integers by creating a list of all the words used. We only keep the ones that appear at least twice with a maximum vocabulary size of 60,000 (by default) and replace the ones that don't make the cut by the unknown token UNK.\n",
        "\n",
        "The correspondance from ids tokens is stored in the vocab attribute of our datasets, in a dictionary called itos (for int to string)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xXwBM1iX70a8",
        "colab_type": "code",
        "outputId": "a01130cd-fc9c-40a2-9d22-40154b2c095a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "data_lm.vocab.itos[:10]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['xxunk',\n",
              " 'xxpad',\n",
              " 'xxbos',\n",
              " 'xxeos',\n",
              " 'xxfld',\n",
              " 'xxmaj',\n",
              " 'xxup',\n",
              " 'xxrep',\n",
              " 'xxwrep',\n",
              " 'the']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QYPPktPJ-uD0",
        "colab_type": "text"
      },
      "source": [
        "And if we look at what a what's in our datasets, we'll see the tokenized text as a representation:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xrz2ppiC-Zai",
        "colab_type": "code",
        "outputId": "52682b18-f7cc-400f-90d0-a843014ecfe6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "data_lm.train_ds[0][0]"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text xxbos xxmaj by 1976 the western was an xxunk genre and the makers of this film clearly knew it . xxmaj still , instead of xxunk the project and saving us from having to watch it , they went ahead and made it anyway . xxmaj apparently in need of an interesting thread to get the audiences to come and see the film , they decided to make it as blatantly violent and unpleasant as possible . xxmaj hell , it worked for xxmaj the xxmaj wild xxmaj bunch so why should n't it work here ? xxmaj of course , xxmaj the xxmaj wild xxmaj bunch had the benefit of a superb script but the script of xxmaj the xxmaj last xxmaj hard xxmaj men is plain old - fashioned rubbish . \n",
              " \n",
              "  xxmaj it 's hard to figure out what attracted xxmaj charlton xxmaj heston and xxmaj james xxmaj coburn to their respective roles . xxmaj heston plays a retired lawman who goes after an escaped bunch of convicts led by a violent xxunk ( xxmaj coburn ) . xxmaj the hunt becomes even more personal when xxmaj heston 's daughter ( xxmaj barbara xxmaj xxunk ) is kidnapped by the convicts and subjected to sexual degradation . \n",
              " \n",
              "  xxmaj this is a xxunk film indeed in which every time someone dies it is displayed in over - the - top detail . xxmaj it 's xxunk disappointing really , because the star xxunk sounds like a mouth - xxunk prospect . xxmaj there 's no sense of pace or xxunk in the film either . xxmaj it takes an eternity to get going , but when the action finally does come it is marred by the emphasis on xxunk . xxmaj all in all , this might be the very worst film that xxmaj heston ever made . i 'm sure it 's one of the productions he is loathe to include on his illustrious xxup xxunk ."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JLIcdd7V-77A",
        "colab_type": "text"
      },
      "source": [
        "**But the underlying data is all numbers**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Kvf0ALH-2r2",
        "colab_type": "code",
        "outputId": "33ec0eba-ead1-4807-baa8-51e17287ff88",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "data_lm.train_ds[0][0].data[:10]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([   2,    5,   48, 4743,    9,  735,   25,   50,    0,  482])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ziYO6oWd_NvF",
        "colab_type": "text"
      },
      "source": [
        "### Alternative apporach: with the data block API\n",
        "We can use the data block API with NLP and have a lot more flexibility than what the default factory methods offer. In the previous example for instance, the data was randomly split between train and validation instead of reading the third column of the csv.\n",
        "\n",
        "With the data block API though, we have to manually call the tokenize and numericalize steps. This allows more flexibility, and if you're not using the defaults from fastai, the various arguments to pass will appear in the step they're revelant, so it'll be more readable."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fv8-og3B_DOT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = (TextList.from_csv(path,'texts.csv',cols='text')\n",
        "                .split_from_df(col=2)\n",
        "                .label_from_df(cols=0)\n",
        "                .databunch())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zMO947f6BFjY",
        "colab_type": "text"
      },
      "source": [
        "### Create a language model\n",
        "\n",
        "Now let's grab the full dataset for what follows."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V9tbIb6tAH6X",
        "colab_type": "code",
        "outputId": "0ffbd851-59a3-429c-cacf-e0fde8f07974",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "path = untar_data(URLs.IMDB)\n",
        "path.ls()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[PosixPath('/root/.fastai/data/imdb/test'),\n",
              " PosixPath('/root/.fastai/data/imdb/train'),\n",
              " PosixPath('/root/.fastai/data/imdb/README'),\n",
              " PosixPath('/root/.fastai/data/imdb/unsup'),\n",
              " PosixPath('/root/.fastai/data/imdb/tmp_lm'),\n",
              " PosixPath('/root/.fastai/data/imdb/tmp_clas'),\n",
              " PosixPath('/root/.fastai/data/imdb/imdb.vocab')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XdDZSKLGBPj-",
        "colab_type": "code",
        "outputId": "7f736dcc-af27-4571-e4de-ce777c36eab7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "(path/'train').ls()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[PosixPath('/root/.fastai/data/imdb/train/neg'),\n",
              " PosixPath('/root/.fastai/data/imdb/train/pos'),\n",
              " PosixPath('/root/.fastai/data/imdb/train/unsupBow.feat'),\n",
              " PosixPath('/root/.fastai/data/imdb/train/labeledBow.feat')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9HEoJmO0B1a5",
        "colab_type": "text"
      },
      "source": [
        "The reviews are in a training and test set following an imagenet structure. The only difference is that there is an unsup folder in train that contains the unlabelled data.\n",
        "\n",
        "We're not going to train a model that classifies the reviews from scratch. Like in computer vision, we'll use a model pretrained on a bigger dataset (a cleaned subset of wikipeia called wikitext-103). That model has been trained to guess what the next word, its input being all the previous words. It has a recurrent structure and a hidden state that is updated each time it sees a new word. This hidden state thus contains information about the sentence up to that point.\n",
        "\n",
        "We are going to use that 'knowledge' of the English language to build our classifier, but first, like for computer vision, we need to fine-tune the pretrained model to our particular dataset. Because the English of the reviews left by people on IMDB isn't the same as the English of wikipedia, we'll need to adjust a little bit the parameters of our model. Plus there might be some words extremely common in that dataset that were barely present in wikipedia, and therefore might no be part of the vocabulary the model was trained on."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pS-Fp3vQCFF9",
        "colab_type": "text"
      },
      "source": [
        "#### More about WikiText-103\n",
        "\n",
        "We will be using the [WikiText-103](https://blog.einstein.ai/the-wikitext-long-term-dependency-language-modeling-dataset/) dataset created by [Stephen Merity](https://smerity.com/) to pre-train a language model.\n",
        "\n",
        "To quote [Stephen's post](https://blog.einstein.ai/the-wikitext-long-term-dependency-language-modeling-dataset/):\n",
        "\n",
        "The WikiText language modeling dataset is a collection of over 100 million tokens extracted from the set of verified Good and Featured articles on Wikipedia. The dataset is available under the Creative Commons Attribution-ShareAlike License.\n",
        "\n",
        "Compared to the preprocessed version of Penn Treebank (PTB), WikiText-2 is over 2 times larger and WikiText-103 is over 110 times larger. The WikiText dataset also features a far larger vocabulary and retains the original case, punctuation and numbers - all of which are removed in PTB. As it is composed of full articles, the dataset is well suited for models that can take advantage of long term dependencies."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ll-YnFYCTYn",
        "colab_type": "text"
      },
      "source": [
        "#### Creating the TextLMDataBunch\n",
        "\n",
        "This is where the unlabelled data is going to be useful to us, as we can use it to fine-tune our model. Let's create our data object with the data block API (next line takes a few minutes)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nq6jROpeBTmg",
        "colab_type": "code",
        "outputId": "a16fde4e-6d2e-4b64-e248-902b530077f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "path.ls()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[PosixPath('/root/.fastai/data/imdb/test'),\n",
              " PosixPath('/root/.fastai/data/imdb/train'),\n",
              " PosixPath('/root/.fastai/data/imdb/README'),\n",
              " PosixPath('/root/.fastai/data/imdb/unsup'),\n",
              " PosixPath('/root/.fastai/data/imdb/tmp_lm'),\n",
              " PosixPath('/root/.fastai/data/imdb/tmp_clas'),\n",
              " PosixPath('/root/.fastai/data/imdb/imdb.vocab')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nb3Dzc_cCg0T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_lm =(TextList.from_folder(path)\n",
        "         #Input: all the text files in path)\n",
        "          .filter_by_folder(include=['train','test','unsup'])\n",
        "          # we may have other temp folders that contain text files so we only keep what's in train and test\n",
        "          .split_by_rand_pct(0.1, seed=42)\n",
        "          # We randomly split and keep 10% (10,000 reviews) for validation\n",
        "          .label_for_lm()\n",
        "          .databunch(bs=bs,num_workers=1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DQSr6oQLDR-v",
        "colab_type": "code",
        "outputId": "4b5ab9b8-3024-4ed4-e45a-1b319f14b628",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(data_lm.vocab.itos),len(data_lm.train_ds)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 90000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GpKD0Tj3EXXu",
        "colab_type": "text"
      },
      "source": [
        "We have to use a special kind of TextDataBunch for the language model, that ignores the labels (that's why we put 0 everywhere), will shuffle the texts at each epoch before concatenating them all together (only for training, we don't shuffle for the validation set) and will send batches that read that text in order with targets that are the next word in the sentence.\n",
        "\n",
        "The line before being a bit long, we want to load quickly the final ids by using the following cell."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yNXYBfVEDbRs",
        "colab_type": "code",
        "outputId": "9ddf11da-e3c4-4e9a-970e-e82c400b9ff6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "data_lm.show_batch()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>idx</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>xxmaj culver xxmaj city in the 50s and have a certain sense of reverence about the xxmaj western genre . ) \\n \\n  xxmaj so i saw the glowing first review and decided to read \" more \" . xxmaj there i found several reviews with 1 or 2 stars that summed up my feelings well about the lack of character development , poor editing , feeling that it</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>13 , \" xxmaj drop xxmaj dead xxmaj gorgeous \" , an incredibly toxic poison was supposedly used to kill the victim . xxmaj this was so toxic and killed so quickly the victim had no time to run or even scream for help . xxmaj yet there was no plausible explanation for how the killer obtained such a powerful poison . \\n \\n  xxmaj in episode 15 ,</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>upon the public . \\n \\n  i 've seen a lot of hateful topics on the forums for this show , and i do n't agree with \" xxmaj mencia 's \" detractors . xxmaj this is not an awful show . xxmaj it had me crying in laughter a few times . xxmaj when it 's funny , it 's very , very funny . xxmaj yes ,</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>time to stop stereotyping xxmaj singaporeans and making such films . xxmaj some of the actors / actresses actually have talent , but sadly it was n't shown much in this film . i was fidgeting in my seat when i watched this , being quite young at that time , my parents dragged me along to see it . xxmaj honestly i could say that i was going to</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>him to ' snap out of it ! ' . xxmaj his brother is a much more human character . xxmaj the ending is inconclusive and puzzling . xxmaj everyone in the cinema ( when i saw the film ) went out muttering about how they nearly fell asleep . xxmaj of course , it should n't have to be a xxmaj hollywood xxmaj bruce xxmaj willis - style '</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MyUSYnXOEcsG",
        "colab_type": "text"
      },
      "source": [
        "Let's save our databunch for next time:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z7Dd9nSwEabH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_lm.save('lm_databunch')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PkfHR2BXEjYS",
        "colab_type": "text"
      },
      "source": [
        "#### Loading saved data, and creating the language model\n",
        "\n",
        "In the future we can load the data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xw_QKYY2EghF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_lm = load_data(path,'lm_databunch',bs=bs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TflK778JE9SC",
        "colab_type": "text"
      },
      "source": [
        "We can then put this in a learner object very easily with a model loaded with the pretrained weights. They'll be downloaded the first time you'll execute the following line and stored in ~/.fastai/models/ (or elsewhere if you specified different paths in your config file)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BaaeSBy0ExzX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn_lm = language_model_learner(data_lm,AWD_LSTM,drop_mult=0.3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v_GCGcnJj8Vf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab = data_lm.vocab"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_h66HWqkiI6t",
        "colab_type": "code",
        "outputId": "cc9bc9ba-0175-447d-afd4-7dc2f4a23bd1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "vocab.stoi['stingray']"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "35747"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ElHwj3EkJCp",
        "colab_type": "code",
        "outputId": "704ba205-f78b-4664-c921-fae4dc3b8d93",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "vocab.itos[vocab.stoi['stingray']]"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'stingray'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qdc4d_gwkRqs",
        "colab_type": "code",
        "outputId": "93034044-7873-4cab-f63b-d193bf8970f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "vocab.itos[vocab.stoi['mobula']]"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'xxunk'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ni-e65VzkYrI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "awd = learn_lm.model[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "30SDKTqvlqD-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from scipy.spatial.distance import cosine as dist"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ScAy7WIAlz-D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "enc = learn_lm.model[0].encoder"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dwaoqNXhl3gx",
        "colab_type": "code",
        "outputId": "0317badc-e2aa-48e5-ce83-48852f0e7896",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "enc.weight.size()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([60000, 400])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v1oiWnVSl8cL",
        "colab_type": "text"
      },
      "source": [
        "#### Difference in vocabulary between IMDB and Wikipedia\n",
        "\n",
        "We are going to load wiki_itos, which can be downloaded along with wikitext-103. We will compare the vocabulary from wikitext with the vocabulary in IMDB. It is to be expected that the two sets have some different vocabulary words, and that is no problem for transfer learning!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-tZ5-Wrl5lo",
        "colab_type": "code",
        "outputId": "d4fb9523-4ade-4e9c-8627-e336e03fd7f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "!wget http://files.fast.ai/models/wt103/itos_wt103.pkl"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-08-03 11:09:35--  http://files.fast.ai/models/wt103/itos_wt103.pkl\n",
            "Resolving files.fast.ai (files.fast.ai)... 67.205.15.147\n",
            "Connecting to files.fast.ai (files.fast.ai)|67.205.15.147|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4161252 (4.0M)\n",
            "Saving to: ‘itos_wt103.pkl’\n",
            "\n",
            "\ritos_wt103.pkl        0%[                    ]       0  --.-KB/s               \ritos_wt103.pkl       86%[================>   ]   3.43M  16.5MB/s               \ritos_wt103.pkl      100%[===================>]   3.97M  18.6MB/s    in 0.2s    \n",
            "\n",
            "2019-08-03 11:09:35 (18.6 MB/s) - ‘itos_wt103.pkl’ saved [4161252/4161252]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Hjq0440mXDI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wiki_itos = pickle.load(open('/content/itos_wt103.pkl', 'rb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZeXYI_StnlZC",
        "colab_type": "code",
        "outputId": "ca0773df-48da-49b1-93dc-66f1169e6dd2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "wiki_itos[:10]"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['_unk_', '_pad_', 'the', ',', '.', 'of', 'and', 'in', 'to', 'a']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "32UAIBv_n2qr",
        "colab_type": "code",
        "outputId": "5caa7bca-45d3-44bd-e31e-617afd40ff05",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(wiki_itos)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "238462"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k5YrFZz_n9Il",
        "colab_type": "code",
        "outputId": "345e3fae-d916-44da-c0e9-3910d74e5b64",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(vocab.itos)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "60000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IgIaAerAo2jW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wiki_words = set(wiki_itos)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0bk9Qm1WpVY8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "imdb_words = set(vocab.itos)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WYcoFHzXpnrw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wiki_not_imbdb = wiki_words.difference(imdb_words)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Cw7_PorpoZD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "imdb_not_wiki = imdb_words.difference(wiki_words)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "faxRfiIXwUVy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wiki_not_imdb_list = []\n",
        "\n",
        "for i in range(100):\n",
        "    word = wiki_not_imbdb.pop()\n",
        "    wiki_not_imdb_list.append(word)\n",
        "    wiki_not_imbdb.add(word)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FhF82DKBwXSw",
        "colab_type": "code",
        "outputId": "90408014-320c-4f61-8e53-dbf6c2a040af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "wiki_not_imdb_list[:15]"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['utvikling',\n",
              " 'iveco',\n",
              " 'glf',\n",
              " 'eskridge',\n",
              " 'nellyville',\n",
              " 'ostinatos',\n",
              " 'gelb',\n",
              " 'eais',\n",
              " 'unpreserved',\n",
              " 'ifriqiya',\n",
              " 'soundwaves',\n",
              " 'ettingshausen',\n",
              " 'revelator',\n",
              " '80-yard',\n",
              " 'bulsara']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eG5cZ36wwcvr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "imdb_not_wiki_list = []\n",
        "\n",
        "for i in range(100):\n",
        "    word = imdb_not_wiki.pop()\n",
        "    imdb_not_wiki_list.append(word)\n",
        "    imdb_not_wiki.add(word)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0mDIlRHNwjej",
        "colab_type": "code",
        "outputId": "299a2e24-f57b-476a-d39b-da0bd0b2024e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "imdb_not_wiki_list[:15]"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['melodramatics',\n",
              " 'lommel',\n",
              " 'movie--',\n",
              " \"i'ts\",\n",
              " 'tamie',\n",
              " 'bullit',\n",
              " 'flunk',\n",
              " 'waaay',\n",
              " 'olenska',\n",
              " 'sawy',\n",
              " 'bruhl',\n",
              " 'ceddie',\n",
              " 'zadora',\n",
              " 'nightie',\n",
              " 'hankies']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bSNC6E36wcdM",
        "colab_type": "text"
      },
      "source": [
        "All words that appear in the IMDB vocab, but not the wikitext-103 vocab, will be initialized to the same random vector in a model. As the model trains, we will learn these weights."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8X3PMtFewn7Q",
        "colab_type": "code",
        "outputId": "268e5176-ab75-45e6-c72b-c1fe55626d54",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "vocab.stoi['modernisation']"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SDu8jZVdwu7N",
        "colab_type": "code",
        "outputId": "8639a524-937e-4e74-9b49-bf3edda6db5d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\"modernisation\" in wiki_words"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9sd40kNpwu3Q",
        "colab_type": "code",
        "outputId": "4abf254c-67df-4bba-fa03-d9723cbb032b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "vocab.stoi['30-something']"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "28149"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "odf2AH1DwuvE",
        "colab_type": "code",
        "outputId": "ac65b39f-d1e8-4629-9031-acf078506763",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\"30-something\" in wiki_words, \"30-something\" in imdb_words"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(False, True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sr-OdXLixMQ5",
        "colab_type": "code",
        "outputId": "1ce999b6-7cf7-4ee0-9156-77eb30e0e138",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "vocab.stoi[\"linklater\"]"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "16236"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "80iW66Y8xMKu",
        "colab_type": "code",
        "outputId": "f19dde39-8e96-436d-f70a-b6b5187933d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\"linklater\" in wiki_words, \"linklater\" in imdb_words"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(True, True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yEj1sURQxMHV",
        "colab_type": "code",
        "outputId": "8c1a437a-e6c4-45f7-e4b9-10e0d04cea20",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\"house\" in wiki_words, \"house\" in imdb_words"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(True, True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E7rSnB0iyATz",
        "colab_type": "text"
      },
      "source": [
        "Here we got these word embeddings .this \"30-something\" weights are randomized the same in both wiki_words and idmb_words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kGOBMbjVxgDn",
        "colab_type": "code",
        "outputId": "2fbfc041-85ea-4f5b-95ec-39f589badf9d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "enc.weight[vocab.stoi[\"30-something\"],:]"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 2.5335e-02,  2.5928e-03,  4.2274e-02, -2.7408e-02, -1.1007e-02,\n",
              "        -9.9722e-03, -6.2764e-02,  1.7945e-01, -1.2754e-01, -2.0963e-01,\n",
              "        -1.2412e-02, -5.5517e-03, -5.0497e-02, -5.0132e-02, -4.2822e-02,\n",
              "         1.7264e-01, -6.5040e-02, -5.7076e-02, -1.1030e-01,  1.8643e-02,\n",
              "         5.2707e-03, -5.8765e-03,  2.9932e-02,  1.9212e-02, -2.3984e-02,\n",
              "         1.4320e-01, -1.0635e-01, -9.7421e-03,  1.0035e-02, -3.9903e-02,\n",
              "         2.8231e-02,  3.1862e-02,  1.2975e-01,  6.8744e-02, -4.6620e-03,\n",
              "         1.6759e-02,  2.0085e-02,  1.3458e-01, -3.3566e-02, -4.4917e-02,\n",
              "         2.6531e-02, -7.5612e-02, -2.2491e-02,  1.9583e-02,  2.2083e-02,\n",
              "         2.1363e-02,  7.7305e-03, -1.3112e-01, -1.3569e-01, -1.2799e-02,\n",
              "         7.3783e-02, -9.0277e-03,  1.6603e-02,  2.6821e-02,  4.5240e-02,\n",
              "         1.6859e-02, -1.9772e-01,  1.6632e-02,  4.5093e-02, -8.1135e-03,\n",
              "         5.8933e-02, -2.6548e-02, -8.7136e-03, -2.9872e-02,  4.2180e-02,\n",
              "        -4.1535e-02, -6.2623e-02,  2.0562e-02, -3.0657e-02, -2.7582e-01,\n",
              "         1.2219e-02,  4.4642e-02, -1.6968e-02,  7.0528e-03,  1.1305e-02,\n",
              "        -1.9801e-02,  1.5385e-02,  2.1163e-03,  3.3255e-02,  5.3079e-02,\n",
              "         8.4422e-02, -2.0810e-02, -1.3449e-01, -1.2234e-02,  2.9190e-02,\n",
              "         1.0539e-02, -1.4057e-01,  6.4911e-02,  9.0854e-02, -5.7713e-02,\n",
              "        -2.3544e-02,  9.3203e-03,  1.0780e-02,  3.2955e-02, -2.2684e-02,\n",
              "        -2.3339e-02, -5.3953e-02,  1.1730e-01,  7.2816e-02, -1.5184e-02,\n",
              "         4.7077e-02, -2.7153e-02, -2.4727e-02, -7.7234e-03,  7.1393e-02,\n",
              "        -1.5132e-02,  1.7839e-02, -4.7394e-02,  4.2199e-02, -1.6575e-03,\n",
              "        -5.8363e-02, -2.1987e-02,  1.5714e-02, -6.7378e-02,  2.3603e-03,\n",
              "        -5.3553e-02,  9.6192e-02, -1.0680e-01, -5.2648e-02, -6.1794e-02,\n",
              "         2.5528e-01,  9.2448e-02,  2.2050e-02, -2.2435e-02,  6.5216e-02,\n",
              "         6.1574e-02, -5.6518e-03, -1.4575e-01, -6.2955e-02,  6.4760e-03,\n",
              "        -6.3202e-02,  9.3461e-02, -1.0415e-02,  4.5993e-02, -1.7525e-03,\n",
              "        -3.6064e-02,  5.6248e-02, -2.7581e-02,  6.1860e-04,  2.2216e-02,\n",
              "         1.0127e-02,  3.7256e-02, -2.8406e-02,  7.6519e-01, -3.3298e-02,\n",
              "        -1.6714e-01,  3.9331e-03,  3.6050e-02, -4.7540e-03,  1.6663e-01,\n",
              "        -8.3493e-03, -3.7114e-02, -1.5342e-02, -8.5655e-03,  5.5274e-02,\n",
              "         2.3244e-02, -1.4728e-01, -4.5679e-02, -3.8161e-02, -8.4069e-02,\n",
              "         3.2108e-02, -7.1940e-02, -2.1234e-02,  5.4865e-04,  1.4925e-02,\n",
              "        -2.8827e-02, -2.3761e-01,  6.5072e-03,  3.6952e-02, -4.3211e-04,\n",
              "        -1.2846e-01, -3.0867e-02, -1.2486e-01, -2.3975e-02,  8.1039e-02,\n",
              "         1.4074e-02, -1.4881e-01, -1.2254e-01,  1.3399e-02,  4.5588e-02,\n",
              "         2.1203e-02, -4.9948e-02, -1.0036e-01,  1.8840e-02,  3.9518e-02,\n",
              "         2.0238e-01,  5.4906e-02, -9.1441e-03, -2.4102e-01,  1.1135e-02,\n",
              "         1.8413e-02, -4.5462e-02,  2.7194e-02,  1.0330e-01, -1.6621e-02,\n",
              "         4.0845e-02, -2.2674e-02,  1.9096e-02,  1.0565e-02,  3.9750e-03,\n",
              "        -6.2551e-02,  2.5769e-02, -1.1735e-01,  7.4392e-02, -1.2344e-02,\n",
              "         2.8734e-03,  6.5088e-02,  7.5542e-02,  3.5328e-02, -8.4041e-03,\n",
              "         5.6973e-02, -4.3548e-02,  5.9791e-02,  1.9136e-01, -4.2444e-02,\n",
              "         1.5786e-02, -9.7147e-03,  2.1304e-02, -7.0585e-02,  1.1066e-01,\n",
              "         1.3638e-01, -1.6435e-02,  3.0443e-02,  1.2169e-03,  3.0149e-02,\n",
              "        -7.4172e-02,  7.3674e-02,  3.1080e-02, -9.6517e-02,  4.1901e-02,\n",
              "         4.0073e-03,  1.3963e-02,  5.9984e-02,  3.1481e-02,  4.0527e-02,\n",
              "         1.7464e-02,  1.2591e-02, -4.4290e-02, -8.9896e-02,  3.7911e-02,\n",
              "         6.0404e-02,  9.4078e-02,  2.5553e-03,  2.2556e-02, -1.0841e-01,\n",
              "         3.8474e-03,  9.0623e-02,  3.3166e-04, -1.8480e-02, -3.3121e-01,\n",
              "        -1.4855e-02, -5.4234e-02,  2.4982e-02, -1.0445e-02, -2.9227e-02,\n",
              "        -4.6419e-02,  1.5086e-02,  2.8657e-02,  2.7857e-02, -6.2527e-02,\n",
              "         4.4352e-02, -1.4464e-02,  1.8574e-02, -8.9173e-03, -7.2781e-02,\n",
              "         9.4139e-03,  6.7750e-02,  5.2762e-02,  4.0525e-02, -2.5521e-02,\n",
              "         9.6799e-02,  1.8574e-02,  9.1878e-03,  6.6399e-02, -1.2262e-01,\n",
              "        -3.3928e-02,  4.8198e-02,  4.0194e-03,  9.0710e-03,  3.9965e-02,\n",
              "        -3.7170e-02,  2.2302e-02,  1.4661e-01, -6.7073e-02,  4.1717e-02,\n",
              "        -1.8205e-02, -7.4282e-02, -4.8822e-02, -9.4059e-04,  3.6781e-02,\n",
              "        -9.4791e-03, -1.2660e-02,  9.0329e-02, -7.6599e-03, -6.0028e-04,\n",
              "        -7.3062e-02,  5.8733e-02,  3.6346e-02, -5.8900e-02,  1.7948e-01,\n",
              "        -5.7199e-01, -7.0864e-02,  8.7996e-02, -7.6982e-03,  1.8575e-02,\n",
              "        -1.4764e-02,  1.3128e-01,  5.3422e-03, -2.9239e-02,  1.7270e-03,\n",
              "        -1.7448e-01,  4.2568e-02, -1.9448e-02,  1.2990e-02, -1.0547e-01,\n",
              "        -4.7016e-04, -4.0284e-02,  8.0881e-03,  1.6944e-02,  4.2752e-04,\n",
              "         3.0630e-02, -8.8706e-02, -3.5135e-02, -3.4949e-02,  1.2839e-01,\n",
              "        -4.8726e-02, -4.2468e-02, -1.0697e-02, -1.0688e-01, -7.6014e-02,\n",
              "        -1.1346e-01, -6.4035e-02,  5.2812e-02,  2.0978e-02, -1.3875e-01,\n",
              "        -2.3215e-02, -2.2187e-02,  2.7356e-02, -7.3708e-02,  1.3543e-01,\n",
              "         5.1856e-02, -8.6770e-02, -5.6008e-02, -1.3793e-02, -9.6148e-02,\n",
              "         6.1393e-03, -3.3932e-02,  1.8407e-02, -5.1984e-02,  1.1047e-01,\n",
              "         5.2659e-02,  4.1319e-02, -4.7716e-02, -1.7815e-01, -1.8264e-01,\n",
              "        -5.5623e-03,  4.7539e-02, -3.5518e-02,  3.4830e-02,  4.2662e-02,\n",
              "        -8.4350e-03, -1.8495e-02,  4.0356e-02, -1.4959e-02,  5.6678e-02,\n",
              "        -6.5708e-02,  1.2372e-01, -9.9855e-03,  7.0696e-02, -2.3437e-02,\n",
              "         6.9280e-02,  2.3212e-02, -1.2937e-02, -9.0564e-02,  1.4153e-01,\n",
              "         9.6515e-02, -6.7672e-02, -2.2178e-03, -1.3922e-01,  8.5446e-03,\n",
              "        -1.2389e-02, -7.6288e-03,  4.9565e-02,  1.9409e-02,  1.3937e-01,\n",
              "         4.2064e-02,  4.9849e-02,  6.6287e-02,  8.5935e-02,  4.2014e-03,\n",
              "         8.4149e-02, -6.6558e-02,  1.8660e-02,  2.4642e-02,  1.4730e-02,\n",
              "        -6.2753e-02,  3.5100e-02,  1.2798e-02,  8.4781e-02, -1.8250e-03],\n",
              "       device='cuda:0', grad_fn=<SliceBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lC4N014axgAg",
        "colab_type": "code",
        "outputId": "ee70fce0-d8d4-4384-f5ed-ae489f296ff2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "np.allclose(enc.weight[vocab.stoi[\"30-something\"], :], \n",
        "            enc.weight[vocab.stoi[\"linklater\"], :])"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VTSeKGR8xf8o",
        "colab_type": "code",
        "outputId": "8ee25f79-2ce1-418e-9c4f-94fdba304cfa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "np.allclose(enc.weight[vocab.stoi[\"30-something\"], :], \n",
        "            enc.weight[vocab.stoi[\"house\"], :])"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kfnXhFFwxf47",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "new_word_vec = enc.weight[vocab.stoi[\"linklater\"], :]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gaw52Bryyy9S",
        "colab_type": "text"
      },
      "source": [
        "#### Generating fake movie reviews (using wiki-text model)\n",
        "\n",
        "Note that learn_lm  is not trained then the model is purely used by Wiki-text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0K7BsrM0xMDi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TEXT = \"The color of the sky is\"\n",
        "N_WORDS = 40\n",
        "N_SENTENCES = 2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9J96G3Cvy3qa",
        "colab_type": "code",
        "outputId": "8f07e23d-eac8-42d6-dff3-f402ff555476",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "print(\"\\n\".join(learn_lm.predict(TEXT,N_WORDS,temperature=0.75) for _ in range(N_SENTENCES)))"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The color of the sky is changed to indicate a location where the station 's colours are raised . This has been used to define stranded weather . This is because of the relationship between the two architecture and a light state , to\n",
            "The color of the sky is visible in sky sky . The sky has the sky in the air ( and the sky ) , and the sky is blue , which is reflected in the visual image of the sky . The sky\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l6obO96Vzaq4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TEXT = \"I hated this movie\"\n",
        "N_WORDS = 30\n",
        "N_SENTENCES = 2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QRnQH6A0zcxC",
        "colab_type": "code",
        "outputId": "d7982679-11bf-45f5-af01-dfb46f150745",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(\"\\n\".join(learn_lm.predict(TEXT,N_WORDS,temperature=0.75) for _ in range(N_SENTENCES)))"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I hated this movie ? The Hollywood Reporter said , \" It 's going to be a good episode \" . The author of the book Something to\n",
            "I hated this movie and its sequels , saying that it was the first time that the movie was shown in the U.S. . In addition to the film , the\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9JwZeeA7zsTy",
        "colab_type": "code",
        "outputId": "6bb7a2ac-46ed-4496-81d2-b9662ba3985b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "print(\"\\n\".join(learn_lm.predict(TEXT,N_WORDS,temperature=0.75) for _ in range(N_SENTENCES)))"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I hated this movie = \n",
            " \n",
            "  \" i ' m a movie reporter \" , is one of the only films shown in the United States to be in English .\n",
            "I hated this movie as a movie , because it is the first film about what he called a \" great company \" . Although he has described the movie as \" a\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3mC0c_hLz1NJ",
        "colab_type": "code",
        "outputId": "f25c2b15-d61d-4d38-cd9b-3e9f38bbe717",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "source": [
        "doc(LanguageLearner.predict)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<h4 id=\"LanguageLearner.predict\" class=\"doc_header\"><code>predict</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/text/learner.py#L116\" class=\"source_link\" style=\"float:right\">[source]</a><a class=\"source_link\" data-toggle=\"collapse\" data-target=\"#LanguageLearner-predict-pytest\" style=\"float:right; padding-right:10px\">[test]</a></h4><blockquote><p><code>predict</code>(<strong><code>text</code></strong>:<code>str</code>, <strong><code>n_words</code></strong>:<code>int</code>=<strong><em><code>1</code></em></strong>, <strong><code>no_unk</code></strong>:<code>bool</code>=<strong><em><code>True</code></em></strong>, <strong><code>temperature</code></strong>:<code>float</code>=<strong><em><code>1.0</code></em></strong>, <strong><code>min_p</code></strong>:<code>float</code>=<strong><em><code>None</code></em></strong>, <strong><code>sep</code></strong>:<code>str</code>=<strong><em><code>' '</code></em></strong>, <strong><code>decoder</code></strong>=<strong><em><code>'decode_spec_tokens'</code></em></strong>)</p>\n",
              "</blockquote>\n",
              "<div class=\"collapse\" id=\"LanguageLearner-predict-pytest\"><div class=\"card card-body pytest_card\"><a type=\"button\" data-toggle=\"collapse\" data-target=\"#LanguageLearner-predict-pytest\" class=\"close\" aria-label=\"Close\"><span aria-hidden=\"true\">&times;</span></a><p>No tests found for <code>predict</code>. To contribute a test please refer to <a href=\"/dev/test.html\">this guide</a> and <a href=\"https://forums.fast.ai/t/improving-expanding-functional-tests/32929\">this discussion</a>.</p></div></div><p>Return the <code>n_words</code> that come after <code>text</code>.</p>\n",
              "<p><a href=\"https://docs.fast.ai/text.learner.html#LanguageLearner.predict\" target=\"_blank\" rel=\"noreferrer noopener\">Show in docs</a></p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yN3XsrI40BSZ",
        "colab_type": "code",
        "outputId": "ded211f0-2783-4b5f-94c1-67855cccf130",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(\"\\n\".join(learn_lm.predict(TEXT, N_WORDS, temperature=0.10) for _ in range(N_SENTENCES)))"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I hated this movie by John Lennon , and he said , \" i ' m not sure what i ' m doing . It 's not a movie .\n",
            "I hated this movie by James Bond . He said , \" It 's a great film . It 's a great film . It 's a great\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lkXOE1nM0BMs",
        "colab_type": "code",
        "outputId": "526bd3b6-d7e1-498d-99f5-bcee7a9cfb06",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(\"\\n\".join(learn_lm.predict(TEXT, N_WORDS, temperature=0.10) for _ in range(N_SENTENCES)))"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I hated this movie by John Lennon , and he said he was \" a fan of the Beatles \" . He said that he was \" very proud of\n",
            "I hated this movie by John Lennon , and he said , \" It 's a bad thing to do . It 's a bad thing . \" The\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GTVz0ffu0NV9",
        "colab_type": "text"
      },
      "source": [
        "#### Training the model\n",
        "Now, we want to choose a good learning rate."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ad-FABpC0BG5",
        "colab_type": "code",
        "outputId": "e8f6497a-1f00-4e2c-c6dc-1ebcc0e6c856",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "learn_lm.lr_find()"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VVNGvYQM0VFO",
        "colab_type": "code",
        "outputId": "73a51dee-4687-4495-9cca-bee78a99f201",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "source": [
        "learn_lm.recorder.plot(skip_end=15)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZgAAAEKCAYAAAAvlUMdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nNJxIAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VbV2j2Y80U32",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lr = 1e-3\n",
        "lr *= bs/48"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mw2oQyL00nNK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn_lm.to_fp16();"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E_Cv-d_V0nKz",
        "colab_type": "code",
        "outputId": "0f1ea637-a796-4fc0-f9e5-daefa0604861",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "learn_lm.fit_one_cycle(1,lr*10,moms=(0.8,0.7))"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>4.148908</td>\n",
              "      <td>4.095057</td>\n",
              "      <td>0.171429</td>\n",
              "      <td>19:04</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MvWINcSP1GXn",
        "colab_type": "text"
      },
      "source": [
        "Since this is relatively slow to train, we will save our weights:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5MHKINRu0nG-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn_lm.save('fit_1')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZDb8tdjL0nDz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn_lm.load('fit_1');"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qZiTFI_Ksh1t",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "To complete the fine-tuning, we can then unfreeze and launch a new training.\n",
        "\n",
        "```\n",
        "The key thing with transfer learning is that typically when you first start fine-tuning it on your dataset, you just want to train the last few layers  and keep the earlier layers frozen which means you are not going to update weights for these earlier layers. Then you will unfreeze those and update all the weights. This is kind of something that helps it learn faster. So here I am going to load in this already\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vuxkXB_41VbB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn_lm.unfreeze()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "74AuDkOX1dk6",
        "colab_type": "code",
        "outputId": "60ee6a33-fe7f-4084-fc6c-64871d5215af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "learn_lm.fit_one_cycle(4,lr,moms=(0.8,0.7))"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>3.828491</td>\n",
              "      <td>3.627628</td>\n",
              "      <td>0.257143</td>\n",
              "      <td>21:54</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>3.769386</td>\n",
              "      <td>3.633922</td>\n",
              "      <td>0.271429</td>\n",
              "      <td>21:55</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>3.647970</td>\n",
              "      <td>3.455968</td>\n",
              "      <td>0.257143</td>\n",
              "      <td>22:51</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>3.549844</td>\n",
              "      <td>3.481542</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>21:59</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BcnJyO761ldL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn_lm.save('fine_tuned')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v8mVYbigDlQV",
        "colab_type": "text"
      },
      "source": [
        "We have to save not just the model but also it's encoder, the part that's responsible for creating and updating the hidden state. For the next part, we don't care about the part that tries to guess the next word."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WByqyASnDl8f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn_lm.save_encoder('fine-tuned_enc')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jf0eb2g3EfmP",
        "colab_type": "text"
      },
      "source": [
        "**Loading our saved weights**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WlLlUVfrEhk2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn_lm.load('fine_tuned');"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HtxE4d8OEppR",
        "colab_type": "text"
      },
      "source": [
        "Now that we've trained our model, different representations have been learned for the words that were in IMDB but not wiki (remember that at the beginning we had initialized them all to the same thing):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jc0kww7GEr1G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "enc = learn_lm.model[0].encoder"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7bfk-4KOEudg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "678614f2-d3cf-4bbf-ba6d-cbed1d545f61"
      },
      "source": [
        "np.allclose(enc.weight[vocab.stoi[\"30-something\"], :], \n",
        "            enc.weight[vocab.stoi[\"linklater\"], :])"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w4nldHXKE1DI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "68a4ef8d-4c64-48f0-b526-014d576c532e"
      },
      "source": [
        "np.allclose(enc.weight[vocab.stoi[\"30-something\"], :], new_word_vec)"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MT8HlnahE5oC",
        "colab_type": "text"
      },
      "source": [
        "#### More generated movie reviews\n",
        "\n",
        "How good is our model? Well let's try to see what it predicts after a few given words.\n",
        "\n",
        "Note that learn_lm  is now trained with Imdb dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7dEAmqYAE8ib",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TEXT = \"i liked this movie because\"\n",
        "N_WORDS = 40\n",
        "N_SENTENCES = 2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qj0YTXeZE-jp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "4172751c-64b0-43db-f26f-5d085443fb83"
      },
      "source": [
        "print(\"\\n\".join(learn_lm.predict(TEXT, N_WORDS, temperature=0.75) for _ in range(N_SENTENCES)))"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "i liked this movie because of its roots in Warner Bros. The movie is very well acted and shot . It is very well - acted by all the actors and is a very good film . The actors do\n",
            "i liked this movie because of the fact that it was a very historically accurate movie . i do know that it was made for TV but this is a very well - made movie . This movie is a very good movie\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ixKED_lFon3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TEXT = \"This movie was\"\n",
        "N_WORDS = 30\n",
        "N_SENTENCES = 2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KLpQunbLFpa5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "12870ebb-2173-403a-f821-561c8d1ed5da"
      },
      "source": [
        "print(\"\\n\".join(learn_lm.predict(TEXT, N_WORDS, temperature=0.75) for _ in range(N_SENTENCES)))"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "This movie was pretty good . i think it was a funny movie , and it does n't have it 's \" wit \" . The movie is a parody of the\n",
            "This movie was so bad that i had to turn it off . It is so bad it 's almost funny . The direction is just awful . There 's\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FGge8dpgFrPX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TEXT = \"I hated this movie\"\n",
        "N_WORDS = 40\n",
        "N_SENTENCES = 2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e3gfS124FtAG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "48a62d98-f018-42ab-bb8d-b93f526febaa"
      },
      "source": [
        "print(\"\\n\".join(learn_lm.predict(TEXT, N_WORDS, temperature=0.75) for _ in range(N_SENTENCES)))"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I hated this movie . In the first six minutes it was okay . The movie starts off slowly , with a lot of good comedy , because it tries to be hilarious , but never comes to the level of being\n",
            "I hated this movie . It starts out like an old TV movie and Bill Paxton ( Bill Paxton ) plays an ex - con who has a hard time with the girl i saw . After\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g5NkYeWrFwKP",
        "colab_type": "text"
      },
      "source": [
        "### Risks of language models\n",
        "\n",
        "We will talk about ethical concerns raised by very accurate language models in lesson 7, but here are a few brief notes:\n",
        "\n",
        "In reference to [OpenAI's GPT-2](https://www.theverge.com/2019/2/14/18224704/ai-machine-learning-language-models-read-write-openai-gpt2): Jeremy Howard said, I’ve been trying to warn people about this for a while. We have the technology to totally fill Twitter, email, and the web up with reasonable-sounding, context-appropriate prose, which would drown out all other speech and be impossible to filter.\n",
        "\n",
        "For a small example, consider when completely incorrect (but reasonable sounding) ML generated answers were [posted to StackOverflow](https://meta.stackoverflow.com/questions/384596/completely-incorrect-machine-learning-generated-answers?stw=2):\n",
        "\n",
        "![alt text](https://github.com/fastai/course-nlp/raw/85e505295efeed88ce61dc0ff5e424bde9741a15/images/robot-overflow.png)\n",
        "\n",
        "![alt text](https://github.com/fastai/course-nlp/raw/85e505295efeed88ce61dc0ff5e424bde9741a15/images/husain-tweet.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YMGmmBU3zLAn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4b403c72-f55a-46f5-a962-7941e6f232d0"
      },
      "source": [
        "import gc\n",
        "gc.collect()"
      ],
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w4dE2SEOzbh2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k_pHwZ5gzRW7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0388f109-4b9f-4126-95b8-1fc783dfd21a"
      },
      "source": [
        "from fastai.utils.mem import gpu_mem_get_all\n",
        "gpu_mem_get_all()"
      ],
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[GPUMemory(total=15079, free=1130, used=13948)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dU4To-fzr7Ix",
        "colab_type": "text"
      },
      "source": [
        "## Create a Classifier [Video 9](https://youtu.be/5gCQvuznKn0?t=5377)\n",
        "\n",
        "Now, we'll create a new data object that only grabs the labelled data and keeps those labels. Again, this line takes a bit of time."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5e79GeOQwL8G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bs = 48"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GNKq72-vyHln",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_clas = (TextList.from_folder(path,vocab= data_lm.vocab)\n",
        "            #grab all the text files in path)\n",
        "             .split_by_folder(valid='text')\n",
        "             # #split by train and valid folder (that only keeps 'train' and 'test' so no need to filter)\n",
        "             .label_from_folder(classes=['neg','pos'])\n",
        "             #label them all with their folders\n",
        "             .databunch(bs=bs,num_workers=1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_mZpQe4_0GN8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_clas.save('imdb_textlist_class')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fn8r3pg00bNq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_clas = load_data(path,\"imdb_textlist_class\",bs=bs,num_workers=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kONpfAYl0hvP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "2f0ead9a-57b1-4634-bfe4-409b94f7270d"
      },
      "source": [
        "data_clas.show_batch()"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>xxbos xxmaj match 1 : xxmaj tag xxmaj team xxmaj table xxmaj match xxmaj bubba xxmaj ray and xxmaj spike xxmaj dudley vs xxmaj eddie xxmaj guerrero and xxmaj chris xxmaj benoit xxmaj bubba xxmaj ray and xxmaj spike xxmaj dudley started things off with a xxmaj tag xxmaj team xxmaj table xxmaj match against xxmaj eddie xxmaj guerrero and xxmaj chris xxmaj benoit . xxmaj according to the rules</td>\n",
              "      <td>pos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>xxbos xxmaj titanic directed by xxmaj james xxmaj cameron presents a fictional love story on the historical setting of the xxmaj titanic . xxmaj the plot is simple , xxunk , or not for those who love plots that twist and turn and keep you in suspense . xxmaj the end of the movie can be figured out within minutes of the start of the film , but the love</td>\n",
              "      <td>pos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>xxbos xxmaj heavy - handed moralism . xxmaj writers using characters as mouthpieces to speak for themselves . xxmaj predictable , plodding plot points ( say that five times fast ) . a child 's imitation of xxmaj britney xxmaj spears . xxmaj this film has all the earmarks of a xxmaj lifetime xxmaj special reject . \\n \\n  i honestly believe that xxmaj jesus xxmaj xxunk and xxmaj</td>\n",
              "      <td>neg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>xxbos xxmaj the freedom of having your own xxmaj sea xxmaj going xxmaj power xxmaj boat , the excitement of going on underwater adventures a rugged , an 's man of an adventurer and xxunk so well endowed ! ) assistants in fine xxmaj bikinis were all definite selling points for \" xxup sea xxup xxunk - 61 ) . \\n \\n  xxmaj just what was the reason for</td>\n",
              "      <td>pos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>xxbos xxmaj by 1987 xxmaj hong xxmaj kong had given the world such films as xxmaj sammo xxmaj hung 's ` xxmaj encounters of the xxmaj spooky xxmaj kind ' xxmaj chow xxmaj yun xxmaj fat in xxmaj john xxmaj woo 's iconic ` a xxmaj better xxmaj tomorrow ' , ` xxmaj zu xxmaj warriors ' and the classic ` xxmaj mr xxmaj vampire ' . xxmaj jackie xxmaj</td>\n",
              "      <td>pos</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "avnFnSLO0mJH",
        "colab_type": "text"
      },
      "source": [
        "We can then create a model to classify those reviews and load the encoder we saved before."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LVJhx9gI0jSC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn_c = text_classifier_learner(data_clas,AWD_LSTM,drop_mult=0.3)#.to_fp16()\n",
        "learn_c.load_encoder('fine-tuned_enc')\n",
        "learn_c.freeze()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AdPtcHLj020q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fcb7d079-dc8c-4858-82d6-5c7427c2d47e"
      },
      "source": [
        "learn_c.lr_find()"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hNiZyXkD1FGg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "0c8b3f2d-4164-4cc4-aa8e-fb88d9bf58db"
      },
      "source": [
        "learn_c.recorder.plot()"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEKCAYAAADjDHn2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nR8iHAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iolnLhA-1G0x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "outputId": "c364bbdf-8625-4740-b252-212e4d8fc062"
      },
      "source": [
        "learn_c.fit_one_cycle(1, 2e-2, moms=(0.8,0.7))"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='0' class='' max='1', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      0.00% [0/1 00:00<00:00]\n",
              "    </div>\n",
              "    \n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>\n",
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='0' class='progress-bar-interrupted' max='520', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      Interrupted\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-112-f51e60874146>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlearn_c\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_one_cycle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2e-2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmoms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastai/train.py\u001b[0m in \u001b[0;36mfit_one_cycle\u001b[0;34m(learn, cyc_len, max_lr, moms, div_factor, pct_start, final_div, wd, callbacks, tot_epochs, start_epoch)\u001b[0m\n\u001b[1;32m     20\u001b[0m     callbacks.append(OneCycleScheduler(learn, max_lr, moms=moms, div_factor=div_factor, pct_start=pct_start,\n\u001b[1;32m     21\u001b[0m                                        final_div=final_div, tot_epochs=tot_epochs, start_epoch=start_epoch))\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcyc_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mlr_find\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mLearner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_lr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_lr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_it\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop_div\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, epochs, lr, wd, callbacks)\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_fns\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlistify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefaults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextra_callback_fns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlistify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdefaults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextra_callbacks\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mdefaults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextra_callbacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m         \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcreate_opt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m->\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(epochs, learn, callbacks, metrics)\u001b[0m\n\u001b[1;32m     99\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprogress_bar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpbar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mloss_batch\u001b[0;34m(model, xb, yb, loss_func, opt, cb_handler)\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_listy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mxb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_listy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0myb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_loss_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastai/text/learner.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    266\u001b[0m                 \u001b[0mraw_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m                 \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmasks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m def get_text_classifier(arch:Callable, vocab_sz:int, n_class:int, bptt:int=70, max_len:int=20*70, config:dict=None,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastai/text/learner.py\u001b[0m in \u001b[0;36mconcat\u001b[0;34m(self, arrs)\u001b[0m\n\u001b[1;32m    251\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marrs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mCollection\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m->\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m         \u001b[0;34m\"Concatenate the `arrs` along the batch dimension.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 253\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange_of\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastai/text/learner.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    251\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marrs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mCollection\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m->\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m         \u001b[0;34m\"Concatenate the `arrs` along the batch dimension.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 253\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange_of\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 290.00 MiB (GPU 0; 14.73 GiB total capacity; 5.30 GiB already allocated; 256.94 MiB free; 466.57 MiB cached)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0in1Tl9q1Z7B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn_c.save('first')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D7Y9IGDG1aWC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn_c.load('first')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wGgbTGWG1cA2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn_c.freeze_to(-2)\n",
        "learn_c.fit_one_cycle(1, slice(1e-2/(2.6**4),1e-2), moms=(0.8,0.7))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_jWDUOgb2_EQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn_c.save('2nd')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "juUBC17K3Asf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn_c.freeze_to(-3)\n",
        "learn_c.fit_one_cycle(1, slice(5e-3/(2.6**4),5e-3), moms=(0.8,0.7))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q7gRnCLH3DpU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn_c.save('3rd')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pp3AmUfi3FJn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn_c.unfreeze()\n",
        "learn_c.fit_one_cycle(2, slice(1e-3/(2.6**4),1e-3), moms=(0.8,0.7))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1olqxu0-3G6s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn_c.save('clas')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ehdRx_JF3U_8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn_c.predict(\"I really loved that movie, it was awesome!\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oLTTNzod3Wk_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn_c.predict(\"I didn't really love that movie, and I didn't think it was awesome.\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pbv1rhFi3aWr",
        "colab_type": "text"
      },
      "source": [
        "# Language Model Zoo\n",
        "\n",
        "fast.ai alumni have applied ULMFit to dozens of different languages, and have beat the SOTA in Thai, Polish, German, Indonesian, Hindi, & Malay.\n",
        "\n",
        "They share tips and best practices in [this forum thread](https://forums.fast.ai/t/language-model-zoo-gorilla/14623) in case you are interested in getting involved!\n",
        "\n",
        "![alt text](https://github.com/fastai/course-nlp/raw/85e505295efeed88ce61dc0ff5e424bde9741a15/images/language_model_zoo.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZdSTDzs53Zgj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}