{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "7_Vietnamese_ULMFIT_from_scratch.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hduongck/AI-ML-Learning/blob/master/Fastai%20NLP%20course/7_Vietnamese_ULMFIT_from_scratch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Sa4U9iy6KPY",
        "colab_type": "text"
      },
      "source": [
        "[Video 10](https://youtu.be/MDX_x6rKXAs?t=1793)\n",
        "\n",
        "The language you're working with may not have pretrained Wikipedia model in Fastai. Today we will learn how to do a pretrained model yourself for other languages from scratch- Vietnamese."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xFGg3MTm550F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%reload_ext autoreload\n",
        "%autoreload 2\n",
        "%matplotlib inline\n",
        "\n",
        "from fastai import *\n",
        "from fastai.text import *"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tldzT1mKfya5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# bs=48\n",
        "bs=24\n",
        "#bs=128"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_jxUqa5Hf45-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_path = Config.data_path()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UXxv5xpsgAFz",
        "colab_type": "text"
      },
      "source": [
        "This will create a **viwiki** folder, containing a **viwiki** text file with the wikipedia contents. (For other languages, replace **vi** with the appropriate code from the list of wikipedias.).\n",
        "\n",
        "Vietnamese code in Wikipedia is **vi**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lSZ-AQCcf7nu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lang = 'vi'\n",
        "# lang = 'zh'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M8GBZjkdgHV5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "name =f'{lang}wiki'\n",
        "path = data_path/name\n",
        "path.mkdir(exist_ok=True,parents=True)\n",
        "lm_fns = [f'{lang}_wt', f'{lang}_wt_vocab']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w348NDLr5ul9",
        "colab_type": "text"
      },
      "source": [
        "f'{lang}_wt' : language model wikitext\n",
        "f'{lang}_wt_vocab' : vocab "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iKz67Kl2giy7",
        "colab_type": "text"
      },
      "source": [
        "# Vietnamese wikipedia model (forward)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IdsYvefAglpj",
        "colab_type": "text"
      },
      "source": [
        "## Download data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eYL-Xyolk3oq",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title from nlputils import get_wiki, split_wiki\n",
        "from fastai.basics import *\n",
        "import re\n",
        "\n",
        "\n",
        "def get_wiki(path,lang):\n",
        "    name = f'{lang}wiki'\n",
        "    if (path/name).exists():\n",
        "        print(f\"{path/name} already exists; not downloading\")\n",
        "        return\n",
        "\n",
        "    xml_fn = f\"{lang}wiki-latest-pages-articles.xml\"\n",
        "    zip_fn = f\"{xml_fn}.bz2\"\n",
        "\n",
        "    if not (path/xml_fn).exists():\n",
        "        print(\"downloading...\")\n",
        "        download_url(f'https://dumps.wikimedia.org/{name}/latest/{zip_fn}', path/zip_fn)\n",
        "        print(\"unzipping...\")\n",
        "        bunzip(path/zip_fn)\n",
        "\n",
        "    with working_directory(path):\n",
        "        if not (path/'wikiextractor').exists(): os.system('git clone https://github.com/attardi/wikiextractor.git')\n",
        "        print(\"extracting...\")\n",
        "        os.system(\"python wikiextractor/WikiExtractor.py --processes 4 --no_templates \" +\n",
        "            f\"--min_text_length 1800 --filter_disambig_pages --log_file log -b 100G -q {xml_fn}\")\n",
        "    shutil.move(str(path/'text/AA/wiki_00'), str(path/name))\n",
        "    shutil.rmtree(path/'text')\n",
        "\n",
        "\n",
        "def split_wiki(path,lang):\n",
        "    dest = path/'docs'\n",
        "    name = f'{lang}wiki'\n",
        "    if dest.exists():\n",
        "        print(f\"{dest} already exists; not splitting\")\n",
        "        return dest\n",
        "\n",
        "    dest.mkdir(exist_ok=True, parents=True)\n",
        "    title_re = re.compile(rf'<doc id=\"\\d+\" url=\"https://{lang}.wikipedia.org/wiki\\?curid=\\d+\" title=\"([^\"]+)\">')\n",
        "    lines = (path/name).open()\n",
        "    f=None\n",
        "\n",
        "    for i,l in enumerate(lines):\n",
        "        if i%100000 == 0: print(i)\n",
        "        if l.startswith('<doc id=\"'):\n",
        "            title = title_re.findall(l)[0].replace('/','_')\n",
        "            if len(title)>150: continue\n",
        "            if f: f.close()\n",
        "            f = (dest/f'{title}.txt').open('w')\n",
        "        else: f.write(l)\n",
        "    f.close()\n",
        "    return dest"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "njCKU8Tdkg8w",
        "colab_type": "code",
        "outputId": "ed58cb0d-57cb-4cac-d978-371585cb6783",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "get_wiki(path,lang)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/root/.fastai/data/viwiki/viwiki already exists; not downloading\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "US7qvYS5lA1x",
        "colab_type": "code",
        "outputId": "9177d104-e8f0-4ec3-af4c-7f82fade924a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "path.ls()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[PosixPath('/root/.fastai/data/viwiki/log'),\n",
              " PosixPath('/root/.fastai/data/viwiki/wikiextractor'),\n",
              " PosixPath('/root/.fastai/data/viwiki/viwiki'),\n",
              " PosixPath('/root/.fastai/data/viwiki/docs'),\n",
              " PosixPath('/root/.fastai/data/viwiki/viwiki-latest-pages-articles.xml'),\n",
              " PosixPath('/root/.fastai/data/viwiki/viwiki-latest-pages-articles.xml.bz2')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "94FAkslGt56T",
        "colab_type": "text"
      },
      "source": [
        "Look at the first 4 lines of the file with **!head -n4**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pGkIVdd0tf0m",
        "colab_type": "code",
        "outputId": "777eae39-80ba-45b7-d3a6-ce00dc40afd2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "!head -n4 {path}/{name}"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<doc id=\"13\" url=\"https://vi.wikipedia.org/wiki?curid=13\" title=\"Tiếng Việt\">\n",
            "Tiếng Việt\n",
            "\n",
            "Tiếng Việt, còn gọi tiếng Việt Nam, tiếng Kinh hay Việt ngữ, là ngôn ngữ của người Việt (dân tộc Kinh) và là ngôn ngữ chính thức tại Việt Nam. Đây là tiếng mẹ đẻ của khoảng 85% dân cư Việt Nam, cùng với hơn 4 triệu Việt kiều. Tiếng Việt còn là ngôn ngữ thứ hai của các dân tộc thiểu số tại Việt Nam. Mặc dù tiếng Việt có một số từ vựng vay mượn từ tiếng Hán và trước đây dùng chữ Nôm – một hệ chữ viết dựa trên chữ Hán – để viết nhưng tiếng Việt được coi là một trong số các ngôn ngữ thuộc ngữ hệ Nam Á có số người nói nhiều nhất (nhiều hơn một số lần so với các ngôn ngữ khác cùng hệ cộng lại). Ngày nay, tiếng Việt dùng bảng chữ cái Latinh, gọi là chữ Quốc ngữ, cùng các dấu thanh để viết.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2mb4xU_ouLsr",
        "colab_type": "text"
      },
      "source": [
        "because this giant downloaded file is hundreds of gigabytes, a bit difficult to work with. What I want to do is to split this file into multiple text files, one for each Wikipedia article. They always start with this pattern , a head on top of the text.\n",
        "\n",
        "![alt text](https://github.com/hduongck/AI-ML-Learning/blob/master/Pic/split_wiki_re.png?raw=true)\n",
        "\n",
        "Here we use regular expression:\n",
        "\n",
        "`<doc id=\"13\" url=\"https://vi.wikipedia.org/wiki?curid=13\" title=\"Tiếng Việt\">`\n",
        "\n",
        "`rf'<doc id=\"\\d+\" url=\"https://{lang}.wikipedia.org/wiki\\?curid=\\d+\" title=\"([^\"]+)\">'`\n",
        "    \n",
        "- replace the number id=\"13\" with id=\"\"\\d+\"\" -> means one or more digits\n",
        "- replace vi with {lang} -> this was replaced with my languague variable \n",
        "- replace curid=\"13\" with curid=\\d+ -> one or more digits\n",
        "- replace title=\"Tieng Viet\" with title=\"([^\"]+)\" -> something followed by anything.\n",
        "\n",
        "`title = title_re.findall(l)[0].replace('/','_')` -> return the things in parentheses\n",
        "\n",
        "**re.compile** -> we'll spending some time turning that string into a faster internal representation and things we are going over millions of lines it\n",
        "\n",
        "                                                                                \n",
        "                                                                                "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TegngF3itnBA",
        "colab_type": "code",
        "outputId": "98088da7-eb3f-471f-a606-acaf169d31d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "dest = split_wiki(path,lang)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/root/.fastai/data/viwiki/docs already exists; not splitting\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eqz56Ya6zG_t",
        "colab_type": "text"
      },
      "source": [
        "after using split_wiki, we end up with directory which contains millions of files. One for each Vietnamese Wikipedia article "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N5QeytkL0EwK",
        "colab_type": "code",
        "outputId": "1f2ecfd0-1fa2-4c87-a254-b5c0f0d85ff0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "dest.ls()[:5]"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[PosixPath('/root/.fastai/data/viwiki/docs/CyanogenMod.txt'),\n",
              " PosixPath('/root/.fastai/data/viwiki/docs/Thám tử lừng danh Conan: Sát thủ bắn tỉa không tưởng.txt'),\n",
              " PosixPath('/root/.fastai/data/viwiki/docs/Hệ Mặt Trời.txt'),\n",
              " PosixPath('/root/.fastai/data/viwiki/docs/Đảng Công nhân Kurd.txt'),\n",
              " PosixPath('/root/.fastai/data/viwiki/docs/Người Duy Ngô Nhĩ.txt')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xbXUwVfH0Lko",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Use this to convert Chinese traditional to simplified characters\n",
        "# ls *.txt | parallel -I% opencc -i % -o ../zhsdocs/% -c t2s.json"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-EgOHPA70xB8",
        "colab_type": "text"
      },
      "source": [
        "## Create pretrained model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TgY3I9bl1xbs",
        "colab_type": "text"
      },
      "source": [
        "we create a language model as same as creating for IMDB dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bsxVj0Yx0zGI",
        "colab_type": "code",
        "outputId": "98988d26-cafe-4ff3-880c-39b88e161ee4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "data = (TextList.from_folder(dest)\n",
        "                .split_by_rand_pct(0.1,seed=42)\n",
        "                .label_for_lm()\n",
        "                .databunch(bs=bs,num_workers=1))\n",
        "\n",
        "data.save(f'{lang}_databunch')\n",
        "len(data.vocab.itos),len(data.train_ds)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 62631)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N7DBRUl66XmZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NdtzsfOV14uC",
        "colab_type": "text"
      },
      "source": [
        "The difference is that we set `pretrained=False`. It will not try to download the English Wikipedia model and fine-tune it because we are not doing English. So this way it will start with random weights. \n",
        "\n",
        "Since it doesn't start with random weights, we will go straight to learn.unfreeze() step"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fSUF9kug2lpU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn = language_model_learner(data,AWD_LSTM,drop_mult=0.5,pretrained=False).to_fp16()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e1oYzx9a3a6e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lr = 1e-2\n",
        "lr *= bs/48 #scale learning rate by batch size"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PhRWOxq4YDvS",
        "colab": {}
      },
      "source": [
        "learn.unfreeze()\n",
        "learn.fit_one_cycle(1,lr,moms=(0.8,0.7))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "saLuF5YI4daU",
        "colab_type": "text"
      },
      "source": [
        "we can have accuracy above 40%"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wy4QJUqH4sGh",
        "colab_type": "text"
      },
      "source": [
        "Now we are going to save the two parts of the language model :\n",
        "- the 1st thing is the actual language model . In this case, I trained the language model with fp16, but most people mostly are going to want to actually get fp32, single precision language model, so I convert back to fp32 then save.\n",
        "\n",
        "```\n",
        "learn.to_fp32().save(mdl_path/lm_fns[0], with_opt=False)\n",
        "```\n",
        "\n",
        "- the 2nd thing to save is vocab. A langugage model starts with a bunch of word embeddings and each row of word embeddings represents a word. So vocab is list of unique words that we're training on.\n",
        "\n",
        "Note: if you create a language model in Fastai, if you say pretrained = True which is default, it will download from Fastai the pretrained Wikipedia model and vocab that it was used. That's why we to save both.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bBgcAXcDvsgM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mdl_path = path/'models'\n",
        "mdl_path.mkdir(exist_ok=True)\n",
        "learn.to_fp32().save(mdl_path/lm_fns[0], with_opt=False)\n",
        "learn.data.vocab.save(mdl_path/(lm_fns[1] + '.pkl'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mQJJJIn9qXS5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "3ee84588-d5a5-4806-b023-d22996ccfe37"
      },
      "source": [
        "mdl_path.ls()"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[PosixPath('/root/.fastai/data/viwiki/models/vi_wt.pth'),\n",
              " PosixPath('/root/.fastai/data/viwiki/models/vi_wt_vocab.pkl'),\n",
              " PosixPath('/root/.fastai/data/viwiki/models/vifine_tuned_enc.pth'),\n",
              " PosixPath('/root/.fastai/data/viwiki/models/vifine_tuned.pth'),\n",
              " PosixPath('/root/.fastai/data/viwiki/models/viclas.pth')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wq3yeTyLpnuz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "12e2dce2-3de7-4bc5-9183-f15f76105971"
      },
      "source": [
        "shutil.move('/content/vi_wt.pth','/root/.fastai/data/viwiki/models/')"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/root/.fastai/data/viwiki/models/vi_wt.pth'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p_EL2eKiq99I",
        "colab_type": "text"
      },
      "source": [
        "## Vietnamese sentiment analysis\n",
        "\n",
        "We need to have a baseline. We need two things : a dataset in vietnamese and example of somebody who try to use that sentiment analysis dataset to predict sentiment.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bT2I9rLItPXZ",
        "colab_type": "text"
      },
      "source": [
        "### Language model:\n",
        "\n",
        "- [Data](https://github.com/ngxbac/aivivn_phanloaisacthaibinhluan/tree/master/data)\n",
        "- [Competition details](https://www.aivivn.com/contests/1)\n",
        "- Top 3 f1 scores: 0.900, 0.897, 0.897\n",
        "\n",
        "The dataset is different to IDMB dataset. Because the reviews of IMDB dataset were generally about 1500 to 2000 words. These Vietnamese reviews are much shorter. So RNNs are particular effective for longer texts. Shorter texts are often not difficult to handle , RNN can do well. But they are not to be as exceptional"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sq3dYkFlFx2E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "38597214-e11f-45e6-ee85-6b600406af86"
      },
      "source": [
        "!git clone https://github.com/ngxbac/aivivn_phanloaisacthaibinhluan.git"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'aivivn_phanloaisacthaibinhluan' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mI4jK0DDtSJ8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "e50d3833-51ed-4073-d3a4-82cfda9244d5"
      },
      "source": [
        "train_df = pd.read_csv('/content/aivivn_phanloaisacthaibinhluan/data/train.csv')\n",
        "train_df.loc[pd.isna(train_df.comment),'comment']='NA'\n",
        "train_df.head()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>comment</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>train_000000</td>\n",
              "      <td>Dung dc sp tot cam on \\nshop Đóng gói sản phẩm...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>train_000001</td>\n",
              "      <td>Chất lượng sản phẩm tuyệt vời . Son mịn nhưng...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>train_000002</td>\n",
              "      <td>Chất lượng sản phẩm tuyệt vời nhưng k có hộp ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>train_000003</td>\n",
              "      <td>:(( Mình hơi thất vọng 1 chút vì mình đã kỳ vọ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>train_000004</td>\n",
              "      <td>Lần trước mình mua áo gió màu hồng rất ok mà đ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             id                                            comment  label\n",
              "0  train_000000  Dung dc sp tot cam on \\nshop Đóng gói sản phẩm...      0\n",
              "1  train_000001   Chất lượng sản phẩm tuyệt vời . Son mịn nhưng...      0\n",
              "2  train_000002   Chất lượng sản phẩm tuyệt vời nhưng k có hộp ...      0\n",
              "3  train_000003  :(( Mình hơi thất vọng 1 chút vì mình đã kỳ vọ...      1\n",
              "4  train_000004  Lần trước mình mua áo gió màu hồng rất ok mà đ...      1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SuSeFWRit4yJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "93f092c7-f50b-451a-b7a7-5f8111181474"
      },
      "source": [
        "test_df = pd.read_csv('/content/aivivn_phanloaisacthaibinhluan/data/test.csv')\n",
        "test_df.loc[pd.isna(test_df.comment),'comment']='NA'\n",
        "test_df.head()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>comment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>test_000000</td>\n",
              "      <td>Chưa dùng thử nên chưa biết</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>test_000001</td>\n",
              "      <td>Không đáng tiềnVì ngay đợt sale nên mới mua n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>test_000002</td>\n",
              "      <td>Cám ơn shop. Đóng gói sản phẩm rất đẹp và chắc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>test_000003</td>\n",
              "      <td>Vải đẹp.phom oki luôn.quá ưng</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>test_000004</td>\n",
              "      <td>Chuẩn hàng đóng gói đẹp</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            id                                            comment\n",
              "0  test_000000                        Chưa dùng thử nên chưa biết\n",
              "1  test_000001   Không đáng tiềnVì ngay đợt sale nên mới mua n...\n",
              "2  test_000002  Cám ơn shop. Đóng gói sản phẩm rất đẹp và chắc...\n",
              "3  test_000003                      Vải đẹp.phom oki luôn.quá ưng\n",
              "4  test_000004                            Chuẩn hàng đóng gói đẹp"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ytFJfh06uq-S",
        "colab_type": "text"
      },
      "source": [
        "Combinde train and test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k8t90JKWuo7k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.concat([train_df,test_df],sort=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9JFJ2hKWu2Q3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_lm = (TextList.from_df(df,path,cols='comment')\n",
        "                    .split_by_rand_pct(0.1,seed=42)\n",
        "                    .label_for_lm()\n",
        "                    .databunch(bs=bs,num_workers=1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R5JNscoTvLUE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn_lm = language_model_learner(data_lm,AWD_LSTM,pretrained_fnames=lm_fns,drop_mult=1.0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lfE4_xm1vW08",
        "colab_type": "text"
      },
      "source": [
        "**pretrained_fnames=lm_fns** : we pass in an array of model file name and vocab file name . That is **`lm_fns = [f'{lang}_wt', f'{lang}_wt_vocab']`**\n",
        "\n",
        "That how we use a pretrained Vietnamese model to create a fine-tuned language model for Vietnamese sentiment analysis. Then we fit the codes identical to IDMB."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WSCuZIDgwmNV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lr = 1e-3\n",
        "lr *= bs/48"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nfzB4tLOwm1K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "outputId": "a02b1505-95a8-40ab-a1f3-f6fedbebf0b4"
      },
      "source": [
        "learn_lm.fit_one_cycle(2,lr*10,moms=(0.8,0.7))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>4.558015</td>\n",
              "      <td>4.233903</td>\n",
              "      <td>0.317331</td>\n",
              "      <td>00:33</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>4.274643</td>\n",
              "      <td>4.110116</td>\n",
              "      <td>0.324308</td>\n",
              "      <td>00:33</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zeS34MKUwvPp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "c83636d3-1941-4e1b-803d-10c7b657d40e"
      },
      "source": [
        "learn_lm.unfreeze()\n",
        "learn_lm.fit_one_cycle(8,lr,moms=(0.8,0.7))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>4.183505</td>\n",
              "      <td>4.037032</td>\n",
              "      <td>0.332821</td>\n",
              "      <td>00:43</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>4.040416</td>\n",
              "      <td>3.908898</td>\n",
              "      <td>0.344075</td>\n",
              "      <td>00:44</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>3.952565</td>\n",
              "      <td>3.814539</td>\n",
              "      <td>0.352035</td>\n",
              "      <td>00:44</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>3.838780</td>\n",
              "      <td>3.752706</td>\n",
              "      <td>0.356838</td>\n",
              "      <td>00:44</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>3.773993</td>\n",
              "      <td>3.717153</td>\n",
              "      <td>0.360341</td>\n",
              "      <td>00:44</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>3.763338</td>\n",
              "      <td>3.696043</td>\n",
              "      <td>0.362154</td>\n",
              "      <td>00:44</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>3.726562</td>\n",
              "      <td>3.688317</td>\n",
              "      <td>0.362486</td>\n",
              "      <td>00:44</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>3.702669</td>\n",
              "      <td>3.687172</td>\n",
              "      <td>0.362985</td>\n",
              "      <td>00:44</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j6abTaS1xUJp",
        "colab_type": "text"
      },
      "source": [
        "We are getting accuracy of 37%"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VR2GeZQdw3U-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn_lm.save(f'{lang}fine_tuned')\n",
        "learn_lm.save_encoder(f'{lang}fine_tuned_enc')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jlFox1g1xZTN",
        "colab_type": "text"
      },
      "source": [
        "### Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aJOSREr2xHZR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_clas = (TextList.from_df(train_df,path,vocab=data_lm.vocab,cols='comment')\n",
        "                     .split_by_rand_pct(0.1,seed=42)\n",
        "                     .label_from_df(cols='label')\n",
        "                     .databunch(bs=bs,num_workers=1))\n",
        "\n",
        "data_clas.save(f'{lang}_textlist_class')\n",
        "                "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FR8g6aHMyLaa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_clas = load_data(path,f'{lang}_textlist_class',bs=bs,num_workers=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c_EWAqYAz8Af",
        "colab_type": "text"
      },
      "source": [
        "The competition use the f1 score which is the average of precision and recall. There isn't a binary f1 built into Fastai but there is 1 built into sklearn lib. \n",
        "\n",
        "In sklearn lib, the func is assumed it getting numpy arrays not torch tensors. So we can create a function which simply called **f1_score** version and add **@np_func** decorator from fastai, it will convert `def f1(inp,targ): return f1_score(targ,np.argmax(inp,axis=-1))` to work with tensors instead of arrays. -> this is nice little trick to use any sklearn metric as a pytorch metric.\n",
        "\n",
        "In learner, we just pass in **metric=[accuracy,f1]**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yX6i7t9jzlpx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "@np_func\n",
        "def f1(inp,targ): return f1_score(targ,np.argmax(inp,axis=-1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x-1oQzRO1aPA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn_c = text_classifier_learner(data_clas,AWD_LSTM,drop_mult=0.5,metrics=[accuracy,f1]).to_fp16()\n",
        "learn_c.load_encoder(f'{lang}fine_tuned_enc')\n",
        "learn_c.freeze()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "274RMkK_113Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lr=2e-2\n",
        "lr *= bs/48"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "huv2Iddl12bS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "outputId": "6cb3f373-5d32-44ab-8bf0-156b2952d3cb"
      },
      "source": [
        "learn_c.fit_one_cycle(2,lr,moms=(0.8,0.7))\n"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>f1</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.365764</td>\n",
              "      <td>0.325883</td>\n",
              "      <td>0.850124</td>\n",
              "      <td>0.824823</td>\n",
              "      <td>00:10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.351074</td>\n",
              "      <td>0.299649</td>\n",
              "      <td>0.864428</td>\n",
              "      <td>0.835478</td>\n",
              "      <td>00:10</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O1PLL8ck18KM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "outputId": "72654937-55b2-472d-d079-509e2d4ed043"
      },
      "source": [
        "learn_c.fit_one_cycle(2,lr,moms=(0.8,0.7))"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>f1</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.351994</td>\n",
              "      <td>0.305872</td>\n",
              "      <td>0.865050</td>\n",
              "      <td>0.831658</td>\n",
              "      <td>00:10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.337251</td>\n",
              "      <td>0.281790</td>\n",
              "      <td>0.884328</td>\n",
              "      <td>0.850461</td>\n",
              "      <td>00:11</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZsemZWDo2Cmi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "outputId": "ec6f2d8e-fd59-412f-e98c-295c9c04cbf6"
      },
      "source": [
        "learn_c.freeze_to(-2)\n",
        "learn_c.fit_one_cycle(2,slice(lr/(2.6**4),lr/2),moms=(0.8,0.7))"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>f1</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.305439</td>\n",
              "      <td>0.257075</td>\n",
              "      <td>0.894901</td>\n",
              "      <td>0.861184</td>\n",
              "      <td>00:13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.308130</td>\n",
              "      <td>0.244332</td>\n",
              "      <td>0.902985</td>\n",
              "      <td>0.876422</td>\n",
              "      <td>00:12</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Esp1L0L2WWi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "outputId": "a61e26c9-066f-4fb3-e7a5-0d70ff7cf0f8"
      },
      "source": [
        "learn_c.freeze_to(-3)\n",
        "learn_c.fit_one_cycle(2, slice(lr/2/(2.6**4),lr/2), moms=(0.8,0.7))"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>f1</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.276878</td>\n",
              "      <td>0.245119</td>\n",
              "      <td>0.902363</td>\n",
              "      <td>0.873948</td>\n",
              "      <td>00:19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.224222</td>\n",
              "      <td>0.239502</td>\n",
              "      <td>0.902985</td>\n",
              "      <td>0.872602</td>\n",
              "      <td>00:18</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VLDGC-ad2W_V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "outputId": "d080ea38-2094-49d9-d23e-80b9573d2b95"
      },
      "source": [
        "learn_c.unfreeze()\n",
        "learn_c.fit_one_cycle(1, slice(lr/10/(2.6**4),lr/10), moms=(0.8,0.7))"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>f1</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.219501</td>\n",
              "      <td>0.243153</td>\n",
              "      <td>0.899254</td>\n",
              "      <td>0.869283</td>\n",
              "      <td>00:24</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vg75Dl9V2pM1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn_c.save(f'{lang}clas')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dfZ-bbZC4M49",
        "colab_type": "text"
      },
      "source": [
        "# Vietnamese ULMFiT from scratch (backwards)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SQeLeOxI2wjP",
        "colab_type": "text"
      },
      "source": [
        "we end up around 89% to 90% while Competition top 3 f1 scores: 0.90, 0.89, 0.89. Winner used an ensemble of 4 models: TextCNN, VDCNN, HARNN, and SARNN.\n",
        "\n",
        "There is a trick that you can improve any model by creating a backward model. A backward langugage model is something which you dont feed wikipedia article , but you feed wikipedia article **in reverse**. \n",
        "\n",
        "```\n",
        "data_clas = load_data(path, f'{lang}_textlist_class_bwd', bs=bs, num_workers=1, backwards=True)\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "That means a language model trained on that will learn to predict the previous word of a sentence given the last words. It's quite a weird thing to do but if you think about it: in language, the next words very often tells you context about what the previous word might have been or how to interpret it. So predicting a previous word of a sentence is likely to be just as useful as predicting the next word of the sentence .\n",
        "\n",
        "**What we did, we re-train the whole model above in backward way.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TtWNVHc97tvq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lm_fns_bwd = [f'{lang}_wt_bwd', f'{lang}_wt_vocab_bwd']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jgSEZkpNiGNQ",
        "colab_type": "text"
      },
      "source": [
        "### pretrained model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YokRNuu7csGC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_bwd = (TextList.from_folder(dest)\n",
        "                    .split_by_rand_pct(0.1,seed=42)\n",
        "                    .label_for_lm()\n",
        "                    .databunch(bs=bs,num_workers=1,backwards=True))\n",
        "\n",
        "data_bwd.save(f'{lang}_databunch_bwd')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IB4qiDFFdEWx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_bwd =load_data(dest,f'{lang}_databunch_bwd',bs=bs,backwards=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8EAP_3qXdWQF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn_bwd = language_model_learner(data_bwd,AWD_LSTM,drop_mult=0.5,pretrained=False).to_fp16()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cNisYu-qdgGl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lr = 3e-3\n",
        "lr *= bs/48 #scale learning rate by batch_size"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZRDJHjIqdm8F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "outputId": "f08ec646-c72c-483d-f6ea-1c5b25529b35"
      },
      "source": [
        "learn_bwd.unfreeze()\n",
        "learn_bwd.fit_one_cycle(1,lr,moms=(0.8,0.7)) # number of epochs shoule be 10"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='0' class='' max='1', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      0.00% [0/1 00:00<00:00]\n",
              "    </div>\n",
              "    \n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>\n",
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='20747' class='' max='65600', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      31.63% [20747/65600 38:38<1:23:31 3.6794]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Buffered data was truncated after reaching the output size limit."
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EZDHtxN-eE4v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn_bwd.to_fp32().save(mdl_path/lm_fns_bwd[0],with_opt=False)\n",
        "learn_bwd.data.vocab.save(mdl_path/(lm_fns_bwd[1]+'.pkl'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EykbKjTeTDuz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "c186892d-0ee8-456d-d560-415cc29f48ef"
      },
      "source": [
        "mdl_path.ls()"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[PosixPath('/root/.fastai/data/viwiki/models/vi_wt.pth'),\n",
              " PosixPath('/root/.fastai/data/viwiki/models/vi_wt_vocab.pkl'),\n",
              " PosixPath('/root/.fastai/data/viwiki/models/vifine_tuned_enc_bwd.pth'),\n",
              " PosixPath('/root/.fastai/data/viwiki/models/vi_wt_vocab_bwd.pkl'),\n",
              " PosixPath('/root/.fastai/data/viwiki/models/vifine_tuned_enc.pth'),\n",
              " PosixPath('/root/.fastai/data/viwiki/models/vifine_tuned.pth'),\n",
              " PosixPath('/root/.fastai/data/viwiki/models/vi_wt_bwd.pth'),\n",
              " PosixPath('/root/.fastai/data/viwiki/models/viclas.pth'),\n",
              " PosixPath('/root/.fastai/data/viwiki/models/vifine_tuned_bwd.pth')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1GpqLZWpS5hw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2d56e741-c58c-4eb6-ee58-ff7e8dcffa71"
      },
      "source": [
        "shutil.copy('/root/.fastai/data/viwiki/models/vi_wt_vocab_bwd.pkl','/content/')"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/vi_wt_vocab_bwd.pkl'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u_5KV87Se0o0",
        "colab_type": "text"
      },
      "source": [
        "### Language model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VrJMhBr6e7Fu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df = pd.read_csv('/content/aivivn_phanloaisacthaibinhluan/data/train.csv')\n",
        "train_df.loc[pd.isna(train_df.comment),'comment']='NA'\n",
        "\n",
        "test_df = pd.read_csv('/content/aivivn_phanloaisacthaibinhluan/data/train.csv')\n",
        "test_df.loc[pd.isna(test_df.comment),'comment']='NA'\n",
        "test_df['label'] = 0\n",
        "\n",
        "df = pd.concat([train_df,test_df])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OcBCcyhXfWwj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_lm_bwd = (TextList.from_df(df,path,cols='comment')\n",
        "                       .split_by_rand_pct(0.1,seed=42)\n",
        "                       .label_for_lm()\n",
        "                       .databunch(bs=bs,num_workers=1,backwards=True))\n",
        "learn_lm_bwd = language_model_learner(data_lm_bwd,AWD_LSTM,config={**awd_lstm_lm_config,'n_hid':1152},\n",
        "                                      pretrained_fnames=lm_fns_bwd,drop_mult=1.0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qy1vJwnWhH19",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lr = 1e-3\n",
        "lr *=bs/48"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_lQ6DvwnhNUL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "outputId": "8aa37427-bbfa-4169-fb92-419891485eb4"
      },
      "source": [
        "learn_lm_bwd.fit_one_cycle(2,lr*10,moms=(0.8,0.7))"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>4.302429</td>\n",
              "      <td>3.994674</td>\n",
              "      <td>0.336155</td>\n",
              "      <td>00:41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>4.095187</td>\n",
              "      <td>3.872484</td>\n",
              "      <td>0.345929</td>\n",
              "      <td>00:38</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m9-heC4AhUMt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "outputId": "a1527245-6fbd-466d-a5b6-0b8bfdbdf81f"
      },
      "source": [
        "learn_lm_bwd.unfreeze()\n",
        "learn_lm_bwd.fit_one_cycle(2,lr,moms=(0.8,0.7))"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>3.825342</td>\n",
              "      <td>3.646230</td>\n",
              "      <td>0.371119</td>\n",
              "      <td>00:53</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>3.710225</td>\n",
              "      <td>3.584261</td>\n",
              "      <td>0.377988</td>\n",
              "      <td>00:53</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "utcSoeT8heMj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn_lm_bwd.save(f'{lang}fine_tuned_bwd')\n",
        "learn_lm_bwd.save_encoder(f'{lang}fine_tuned_enc_bwd')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7v7UnZl4iKgV",
        "colab_type": "text"
      },
      "source": [
        "### Classfier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZBt4Q4cQiQht",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_clas_bwd = (TextList.from_df(train_df, path, vocab=data_lm_bwd.vocab, cols='comment')\n",
        "    .split_by_rand_pct(0.1, seed=42)\n",
        "    .label_from_df(cols='label')\n",
        "    .databunch(bs=bs, num_workers=1, backwards=True))\n",
        "\n",
        "data_clas_bwd.save(f'{lang}_textlist_class_bwd')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YvyaQJ5qilrz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_clas_bwd = load_data(path, f'{lang}_textlist_class_bwd', bs=bs, num_workers=1, backwards=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gI9VUWVziqmX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "@np_func\n",
        "def f1(inp,targ): return f1_score(targ, np.argmax(inp, axis=-1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DIEZN88qitnD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn_c_bwd = text_classifier_learner(data_clas_bwd, AWD_LSTM, drop_mult=0.5, metrics=[accuracy,f1]).to_fp16()\n",
        "learn_c_bwd.load_encoder(f'{lang}fine_tuned_enc_bwd')\n",
        "learn_c_bwd.freeze()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0heUCpwTi9oL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lr=2e-2\n",
        "lr *= bs/48"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rpy2hyqzjC2v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "outputId": "66cf6d0c-e712-4fe6-9116-4a87d7db92c4"
      },
      "source": [
        "learn_c_bwd.fit_one_cycle(2, lr, moms=(0.8,0.7))"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>f1</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.396237</td>\n",
              "      <td>0.336419</td>\n",
              "      <td>0.843905</td>\n",
              "      <td>0.800749</td>\n",
              "      <td>00:10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.377389</td>\n",
              "      <td>0.313789</td>\n",
              "      <td>0.863806</td>\n",
              "      <td>0.827192</td>\n",
              "      <td>00:11</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sfWfZXh6jFwZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "outputId": "e2257003-ba65-469e-aee2-e88b0e89d8df"
      },
      "source": [
        "learn_c_bwd.freeze_to(-2)\n",
        "learn_c_bwd.fit_one_cycle(2, slice(lr/(2.6**4),lr), moms=(0.8,0.7))"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>f1</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.323246</td>\n",
              "      <td>0.275257</td>\n",
              "      <td>0.883085</td>\n",
              "      <td>0.846457</td>\n",
              "      <td>00:13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.274870</td>\n",
              "      <td>0.243117</td>\n",
              "      <td>0.901119</td>\n",
              "      <td>0.871046</td>\n",
              "      <td>00:14</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Cp32qcmjKb9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "outputId": "fe518e2c-f684-4a5f-f3ae-d495694f79fb"
      },
      "source": [
        "learn_c_bwd.freeze_to(-3)\n",
        "learn_c_bwd.fit_one_cycle(2, slice(lr/2/(2.6**4),lr/2), moms=(0.8,0.7))"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>f1</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.262463</td>\n",
              "      <td>0.232588</td>\n",
              "      <td>0.904229</td>\n",
              "      <td>0.879229</td>\n",
              "      <td>00:20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.247088</td>\n",
              "      <td>0.223597</td>\n",
              "      <td>0.914179</td>\n",
              "      <td>0.888134</td>\n",
              "      <td>00:18</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FLZdo7h7jLtI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "outputId": "4385b340-0001-4146-9508-40314cf1d1d5"
      },
      "source": [
        "learn_c_bwd.unfreeze()\n",
        "learn_c_bwd.fit_one_cycle(1, slice(lr/10/(2.6**4),lr/10), moms=(0.8,0.7))"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>f1</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.199528</td>\n",
              "      <td>0.222531</td>\n",
              "      <td>0.906095</td>\n",
              "      <td>0.875279</td>\n",
              "      <td>00:26</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YySMz040jMDD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "learn_c_bwd.save(f'{lang}clas_bwd')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lhcXoEHK8f9B",
        "colab_type": "text"
      },
      "source": [
        "# Ensemble \n",
        "\n",
        "[Video 10](https://youtu.be/MDX_x6rKXAs?t=3378)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8y8Okohw5LCI",
        "colab_type": "text"
      },
      "source": [
        "Now we have two models : forward and backward . What we simple do, we ensemble them together. In Ensemble, it simply means you combine the prediction of two models, often by taking the average . \n",
        "\n",
        "Loading up forward classfier "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xq2qJfkAkAnI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_clas = load_data(path,f'{lang}_textlist_class',bs=bs,num_workers=1)\n",
        "learn_c = text_classifier_learner(data_clas,AWD_LSTM,drop_mult=0.5,metrics=[accuracy,f1]).to_fp16()\n",
        "learn_c.load(f'{lang}clas',purge=False);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tp-fPBg7sA_n",
        "colab_type": "text"
      },
      "source": [
        "get the prediction of forward classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J3ljJhpesGDT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b327a429-acaa-4652-c18a-5e17448dc026"
      },
      "source": [
        "preds,targs=learn_c.get_preds(ordered=True)\n",
        "accuracy(preds,targs),f1(preds,targs)"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.8993), tensor(0.8818))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HWJ_isgms6cZ",
        "colab_type": "text"
      },
      "source": [
        "Loading up the backward classifer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hTJp4VmNsRwV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_clas_bwd = load_data(path,f'{lang}_textlist_class_bwd',bs=bs,num_workers=1,backwards=True)\n",
        "learn_c_bwd = text_classifier_learner(data_clas_bwd,AWD_LSTM,drop_mult=0.5,metrics=[accuracy,f1]).to_fp16()\n",
        "learn_c_bwd.load(f'{lang}clas_bwd',purge=False);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7LaUV201s9BL",
        "colab_type": "text"
      },
      "source": [
        "get the prediction of backward classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hsShhrzws_yf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "84de3e2c-8c4f-4e10-85c4-b4224558d777"
      },
      "source": [
        "preds_b,targs_b=learn_c_bwd.get_preds(ordered=True)\n",
        "accuracy(preds_b,targs_b),f1(preds_b,targs_b)"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.9061), tensor(0.8891))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rcg722l6tUwv",
        "colab_type": "text"
      },
      "source": [
        "take the average of two predictions and then calculate the accuracy and f1 score , 0.9154 and 0.9016 respectively.\n",
        "\n",
        "The work here included downloading the Vietnamese wikipedia, and finding a Vietnamese sentiment analysis, we have won the popular competition. The trick of ensemble in the forwards and backwards can often give you a significant lift, particularly in the situation you don't have many data. \n",
        "\n",
        "**The appoach of creating your own pretrained model, it's not only useful for different language, but it's extremely useful if you're dealing with a extremely different domain , particular one would be medicine if you have a huge vocabulary of medical terms . If it appears on Wikipedia, you would create a pretrained model.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6gdi-QvwvNQ4",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fWDD3eNYtQlw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}