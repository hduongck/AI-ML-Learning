{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "8-Predicting-English-word-version-of-numbers-using-an-RNN.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hduongck/AI-ML-Learning/blob/master/Fastai%20NLP%20course/8_Predicting_English_word_version_of_numbers_using_an_RNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U2PkfAJahM11",
        "colab_type": "text"
      },
      "source": [
        "This notebook was part of [Lesson 7](https://course.fast.ai/videos/?lesson=7) of the Practical Deep Learning for Coders course."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fZLNHYcKhDoV",
        "colab_type": "text"
      },
      "source": [
        "# Predicting English word version of numbers using an RNN\n",
        "\n",
        "[Video 10](https://youtu.be/MDX_x6rKXAs?t=5353)\n",
        "\n",
        "We were using RNNs as part of our language model in the previous lesson. Today, we will dive into more details of what RNNs are and how they work. We will do this using the problem of trying to predict the English word version of numbers.\n",
        "\n",
        "Let's predict what should come next in this sequence:\n",
        "\n",
        "`eight thousand one , eight thousand two , eight thousand three , eight thousand four , eight thousand five , eight thousand six , eight thousand seven , eight thousand eight , eight thousand nine , eight thousand ten , eight thousand eleven , eight thousand twelve...`\n",
        "\n",
        "Jeremy created this **synthetic dataset** to have a better way to check if things are working, to debug, and to understand what was going on. When experimenting with new ideas, it can be nice to have a smaller dataset to do so, to quickly get a sense of whether your ideas are promising (for other examples, see [Imagenette and Imagewoof](https://github.com/fastai/imagenette). This English word numbers will serve as a good dataset for learning about RNNs. Our task today will be to predict which word comes next when counting.\n",
        "\n",
        "    - Synthetic dataset technique: during the developing of FastAi lib, Jeremy write something 12 times wrong and it's very hard to know something wrong, particular with machine learning, it could be wrong in subtle way. So for something, which I clearly know what the next answer ought to be, it was just easier for me to see how it was wrong. It's just much easier to develope an algorithm using something that can train in 5 or 10s rather than 5 to 10h. Imagenette and Imagewoof is a slight different variant which it's not a synthetic dataset but it's but smaller dataset in computer vision that people are struggling for a long time. They either trains things on the imagenet dataset which used to take days to train or they're trained on something called Cifar which was so small that was actually turned out to be useless. There were 32x32 pixels and it turns out things that work out and 32x32 pixels actually don't work well on normal size images. So I created something with full-sized images but less of them and I kind of tried to create one version that would be easy to classify and one version that would be hard to classify. So I guess in general, if I try to come up with different sampling versions of the problem that you're trying to solve, that is like one of the really important things is a machine learning practitioner. So you can quickly iterate and we identify your mistakes even you don't make as many mistakes as I do.\n",
        "    \n",
        "\n",
        "**In deep learning, there are 2 types of numbers**\n",
        "\n",
        "**Parameters** are numbers that are learned. **Activations** are numbers that are calculated (by affine functions & element-wise non-linearities).\n",
        "\n",
        "When you learn about any new concept in deep learning, ask yourself: is this a parameter or an activation?\n",
        "\n",
        "Note to self: Point out the hidden state, going from the version without a for-loop to the for loop. This is the step where people get confused."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OEcjvYM1uBFU",
        "colab_type": "text"
      },
      "source": [
        "## Data\n",
        "\n",
        "this does not see in the real world but it's very informative for us to understand RNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PEjNaWoJgr-f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from fastai.text import *"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JsYgDtPUudyb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bs = 64\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wqah2BnoueyS",
        "colab_type": "code",
        "outputId": "cb1a207c-36f8-45f6-b555-c2a36e26f739",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "path = untar_data(URLs.HUMAN_NUMBERS)\n",
        "path.ls()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[PosixPath('/root/.fastai/data/human_numbers/train.txt'),\n",
              " PosixPath('/root/.fastai/data/human_numbers/valid.txt')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JnvBOmKju6uI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def readnums(d): return [', '.join(o.strip() for o  in open(path/d).readlines())]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vs7YP1A8vRA9",
        "colab_type": "text"
      },
      "source": [
        "train.txt gives us a sequence of numbers written out as English words:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "85a4t8ozvQdF",
        "colab_type": "code",
        "outputId": "f27a943e-66d1-4c83-a8db-e3bb0c0277ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_txt = readnums('train.txt'); train_txt[0][:80]"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'one, two, three, four, five, six, seven, eight, nine, ten, eleven, twelve, thirt'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5m-S2Lp_vcPA",
        "colab_type": "code",
        "outputId": "40d808b1-d293-49cd-d304-6b652cce215a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "valid_txt = readnums('valid.txt'); valid_txt[0][-80:]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' nine thousand nine hundred ninety eight, nine thousand nine hundred ninety nine'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wT9ZNhI9vmCN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = TextList(train_txt,path=path)\n",
        "valid = TextList(valid_txt,path=path)\n",
        "\n",
        "src = ItemLists(path=path,train=train,valid=valid).label_for_lm()\n",
        "data = src.databunch(bs=bs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B2siG-TMwGzl",
        "colab_type": "code",
        "outputId": "2b769435-d103-4b50-ac07-869b7d279a14",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train[0].text[:80]"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'xxbos one , two , three , four , five , six , seven , eight , nine , ten , eleve'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TEm0OybKwUyj",
        "colab_type": "code",
        "outputId": "e3408913-c3d4-454e-f41e-d3beb48f1a30",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(data.valid_ds[0][0].data)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13017"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "56A5ZfZVwaX8",
        "colab_type": "text"
      },
      "source": [
        "**bptt** stands for back-propagation through time. This tells us how many steps of history we are considering.\n",
        "\n",
        "what we want the network to predict what the next word , 71st"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cwTWoV_awYci",
        "colab_type": "code",
        "outputId": "2879c929-9e60-4038-9cf0-248e112efb17",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "data.bptt,len(data.valid_dl)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(70, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OEltxDCyw8r1",
        "colab_type": "text"
      },
      "source": [
        "We have 3 batches in our validation set:\n",
        "\n",
        "13017 tokens, with about ~70 tokens in about a line of text, and 64 lines of text per batch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FkYhb-TRwq3T",
        "colab_type": "code",
        "outputId": "65c26761-56fa-4350-b2a7-9f423416ce73",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "13017/70/bs"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2.905580357142857"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h1Vi8_FYxakL",
        "colab_type": "text"
      },
      "source": [
        "We will store each batch in a separate variable, so we can walk through this to understand better what the RNN does at each step:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pgovpWwKxWad",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "it = iter(data.valid_dl)\n",
        "x1,y1 = next(it)\n",
        "x2,y2 = next(it)\n",
        "x3,y3 = next(it)\n",
        "it.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9QsitFIsxp-i",
        "colab_type": "code",
        "outputId": "d03abaa6-df5e-40e0-abc1-3c57062a7ec5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "x1"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 2, 19, 11,  ..., 36,  9, 19],\n",
              "        [ 9, 19, 11,  ..., 24, 20,  9],\n",
              "        [11, 27, 18,  ...,  9, 19, 11],\n",
              "        ...,\n",
              "        [20, 11, 20,  ..., 11, 20, 10],\n",
              "        [20, 11, 20,  ..., 24,  9, 20],\n",
              "        [20, 10, 26,  ..., 20, 11, 20]], device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0IB3gz8ex6p4",
        "colab_type": "text"
      },
      "source": [
        "numel() is a PyTorch method to return the number of elements in a tensor:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "meDeN-GQx5vp",
        "colab_type": "code",
        "outputId": "540c14b0-6e01-4323-c56d-3ecdceb46188",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x1.numel()+x2.numel()+x3.numel()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13440"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z-pFFmS9x-Kk",
        "colab_type": "code",
        "outputId": "e5c9c897-757d-41d9-93cf-d1cfcd44a0ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x1.shape,y1.shape"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([64, 70]), torch.Size([64, 70]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jxVKgKjjyK5N",
        "colab_type": "code",
        "outputId": "be5f427a-c12c-4281-c87d-79f9bbdf5857",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x2.shape,y2.shape"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([64, 70]), torch.Size([64, 70]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ck8DRKpMyOpN",
        "colab_type": "code",
        "outputId": "9570b245-c094-4845-de55-d048405a3685",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x3.shape,y3.shape"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([64, 70]), torch.Size([64, 70]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hVRXrg4XyQ3j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "v = data.valid_ds.vocab"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UQqhjUgryhUB",
        "colab_type": "code",
        "outputId": "6e004f24-3acc-4a1f-e198-a56ac1ad4c76",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        }
      },
      "source": [
        "v.itos"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['xxunk',\n",
              " 'xxpad',\n",
              " 'xxbos',\n",
              " 'xxeos',\n",
              " 'xxfld',\n",
              " 'xxmaj',\n",
              " 'xxup',\n",
              " 'xxrep',\n",
              " 'xxwrep',\n",
              " ',',\n",
              " 'hundred',\n",
              " 'thousand',\n",
              " 'one',\n",
              " 'two',\n",
              " 'three',\n",
              " 'four',\n",
              " 'five',\n",
              " 'six',\n",
              " 'seven',\n",
              " 'eight',\n",
              " 'nine',\n",
              " 'twenty',\n",
              " 'thirty',\n",
              " 'forty',\n",
              " 'fifty',\n",
              " 'sixty',\n",
              " 'seventy',\n",
              " 'eighty',\n",
              " 'ninety',\n",
              " 'ten',\n",
              " 'eleven',\n",
              " 'twelve',\n",
              " 'thirteen',\n",
              " 'fourteen',\n",
              " 'fifteen',\n",
              " 'sixteen',\n",
              " 'seventeen',\n",
              " 'eighteen',\n",
              " 'nineteen',\n",
              " 'xxfake']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ouSHTW_X3Xum",
        "colab_type": "text"
      },
      "source": [
        "[1:40](https://youtu.be/MDX_x6rKXAs?t=5859)\n",
        "\n",
        "Tokenization is always implementation-dependent. It's going to depend on particular library how things are tokenized"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9cPDlj52yjLP",
        "colab_type": "code",
        "outputId": "440494ed-fe3c-4efd-8a3a-36a5c13f28e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "x1[:,0]"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 2,  9, 11, 12, 13, 11, 10,  9, 10, 14, 19, 25, 19, 15, 16, 11, 19,  9,\n",
              "        10,  9, 19, 25, 19, 11, 19, 11, 10,  9, 19, 20, 11, 26, 20, 23, 20, 20,\n",
              "        24, 20, 11, 14, 11, 11,  9, 14,  9, 20, 10, 20, 35, 17, 11, 10,  9, 17,\n",
              "         9, 20, 10, 20, 11, 20, 11, 20, 20, 20], device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y0kIDm3dynBp",
        "colab_type": "code",
        "outputId": "a0960f2c-28a1-4383-d208-8f92728e6205",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "y1[:,0]"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([19, 19, 27, 10,  9, 12, 32, 19, 26, 10, 11, 15, 11, 10,  9, 15, 11, 19,\n",
              "        26, 19, 11, 18, 11, 18,  9, 18, 21, 19, 10, 10, 20,  9, 11, 16, 11, 11,\n",
              "        13, 11, 13,  9, 13, 14, 20, 10, 20, 11, 24, 11,  9,  9, 16, 17, 20, 10,\n",
              "        20, 11, 24, 11, 19,  9, 19, 11, 11, 10], device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ROTOT4tQypW4",
        "colab_type": "code",
        "outputId": "8d3851a1-b755-4889-b237-8347c7648cc3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "v.itos[9],v.itos[11],v.itos[12],v.itos[13],v.itos[10]"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(',', 'thousand', 'one', 'two', 'hundred')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R7e8wXfuy7H6",
        "colab_type": "code",
        "outputId": "f7bdea27-bc32-437a-c0ec-35949285b16f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "v.textify(x1[0])"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'xxbos eight thousand one , eight thousand two , eight thousand three , eight thousand four , eight thousand five , eight thousand six , eight thousand seven , eight thousand eight , eight thousand nine , eight thousand ten , eight thousand eleven , eight thousand twelve , eight thousand thirteen , eight thousand fourteen , eight thousand fifteen , eight thousand sixteen , eight thousand seventeen , eight'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G7SGKDPw4C4n",
        "colab_type": "code",
        "outputId": "58e3f405-5c47-4824-9f50-e06f93219f30",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "v.textify(x2[0])"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'thousand eighteen , eight thousand nineteen , eight thousand twenty , eight thousand twenty one , eight thousand twenty two , eight thousand twenty three , eight thousand twenty four , eight thousand twenty five , eight thousand twenty six , eight thousand twenty seven , eight thousand twenty eight , eight thousand twenty nine , eight thousand thirty , eight thousand thirty one , eight thousand thirty two ,'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M-p4C_7K4G35",
        "colab_type": "code",
        "outputId": "0ad2ffc9-45a5-49d1-c296-a92bee74eb99",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "v.textify(x3[0])"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'eight thousand thirty three , eight thousand thirty four , eight thousand thirty five , eight thousand thirty six , eight thousand thirty seven , eight thousand thirty eight , eight thousand thirty nine , eight thousand forty , eight thousand forty one , eight thousand forty two , eight thousand forty three , eight thousand forty four , eight thousand forty five , eight thousand forty six , eight'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OkTtNBuV4B3F",
        "colab_type": "text"
      },
      "source": [
        "note that the kind of way these batches line up is that it's going from one batch to the next , the first line of your first batch is gonna be follow by the first line of second batch.\n",
        "\n",
        "data.show_batch() is another way to get another view of what the batch looks like "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R6505NS2y_Bx",
        "colab_type": "code",
        "outputId": "a7db454f-55bc-4333-b225-1b726a45f3eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "data.show_batch(ds_type=DatasetType.Valid)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>idx</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>thousand forty seven , eight thousand forty eight , eight thousand forty nine , eight thousand fifty , eight thousand fifty one , eight thousand fifty two , eight thousand fifty three , eight thousand fifty four , eight thousand fifty five , eight thousand fifty six , eight thousand fifty seven , eight thousand fifty eight , eight thousand fifty nine , eight thousand sixty , eight thousand sixty</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>eight , eight thousand eighty nine , eight thousand ninety , eight thousand ninety one , eight thousand ninety two , eight thousand ninety three , eight thousand ninety four , eight thousand ninety five , eight thousand ninety six , eight thousand ninety seven , eight thousand ninety eight , eight thousand ninety nine , eight thousand one hundred , eight thousand one hundred one , eight thousand one</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>thousand one hundred twenty four , eight thousand one hundred twenty five , eight thousand one hundred twenty six , eight thousand one hundred twenty seven , eight thousand one hundred twenty eight , eight thousand one hundred twenty nine , eight thousand one hundred thirty , eight thousand one hundred thirty one , eight thousand one hundred thirty two , eight thousand one hundred thirty three , eight thousand</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>three , eight thousand one hundred fifty four , eight thousand one hundred fifty five , eight thousand one hundred fifty six , eight thousand one hundred fifty seven , eight thousand one hundred fifty eight , eight thousand one hundred fifty nine , eight thousand one hundred sixty , eight thousand one hundred sixty one , eight thousand one hundred sixty two , eight thousand one hundred sixty three</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>thousand one hundred eighty three , eight thousand one hundred eighty four , eight thousand one hundred eighty five , eight thousand one hundred eighty six , eight thousand one hundred eighty seven , eight thousand one hundred eighty eight , eight thousand one hundred eighty nine , eight thousand one hundred ninety , eight thousand one hundred ninety one , eight thousand one hundred ninety two , eight thousand</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z0s2rCgRkQZe",
        "colab_type": "text"
      },
      "source": [
        "## Single fully connected model\n",
        "\n",
        "We will iteratively consider a few different models, building up to a more traditional RNN.\n",
        "\n",
        "First we create a model to predict a next word after three words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qfNUZVLz48YO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = src.databunch(bs=bs,bptt=3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8WCeTDi3knuZ",
        "colab_type": "code",
        "outputId": "435fea0c-3ba5-46a3-adee-50e207eeceec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x,y = data.one_batch()\n",
        "x.shape,y.shape"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([64, 3]), torch.Size([64, 3]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IlnHDwjskv0v",
        "colab_type": "code",
        "outputId": "433eba23-32b0-4e22-c251-cca13d51afed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "nv = len(v.itos);nv"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "40"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vw2so7suk4DJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nh =64\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "htKXM0ljk55I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def loss4(input,target): return F.cross_entropy(input,target[:,-1])\n",
        "def acc4(input,target): return accuracy(input,target[:,-1])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mGfFfJlDlTYQ",
        "colab_type": "code",
        "outputId": "f5520525-d09a-4830-9f1c-3f4d6a04ae7a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "x[:,0]"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([13, 13, 10,  9, 18,  9, 11, 11, 13, 19, 16, 23, 24,  9, 12,  9, 13, 14,\n",
              "        15, 11, 10, 22, 15,  9, 10, 14, 11, 16, 10, 28, 11,  9, 20,  9, 15, 15,\n",
              "        11, 18, 10, 28, 23, 24,  9, 16, 10, 16, 19, 20, 12, 10, 22, 16, 17, 17,\n",
              "        17, 11, 24, 10,  9, 15, 16,  9, 18, 11])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zAWOcWrSlfBn",
        "colab_type": "text"
      },
      "source": [
        "**Layer names:**\n",
        "\n",
        "i_h: input to hidden\n",
        "\n",
        "h_h: hidden to hidden\n",
        "\n",
        "h_o: hidden to output\n",
        "\n",
        "bn: batchnorm\n",
        "\n",
        "![alt text](https://github.com/hduongck/AI-ML-Learning/blob/master/Pic/RNN.PNG?raw=true)\n",
        "\n",
        "![alt text](https://github.com/hduongck/AI-ML-Learning/blob/master/Pic/RNN1.PNG?raw=true)\n",
        "\n",
        "![alt text](https://github.com/hduongck/AI-ML-Learning/blob/master/Pic/RNN2.PNG?raw=true)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MlJgqMIZlWiR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Model0(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.i_h = nn.Embedding(nv,nh)\n",
        "        self.h_h = nn.Linear(nh,nh)\n",
        "        self.h_o = nn.Linear(nh,nv)\n",
        "        self.bn = nn.BatchNorm1d(nh)\n",
        "        \n",
        "    def forward(self,x):\n",
        "        h = self.bn(F.relu(self.i_h(x[:,0])))\n",
        "        if x.shape[1]>1:\n",
        "            h = h + self.i_h(x[:,1])\n",
        "            h = self.bn(F.relu(self.h_h(h)))\n",
        "        if x.shape[1]>2:\n",
        "            h = h + self.i_h(x[:,2])\n",
        "            h = self.bn(F.relu(self.h_h(h)))\n",
        "            \n",
        "        return self.h_o(h)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ob4nM83InJk4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn = Learner(data,Model0(),loss_func=loss4,metrics=acc4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FzEEjQqlnRnS",
        "colab_type": "code",
        "outputId": "eb86bc10-7110-410a-b9a1-dfe9dae1cd37",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "source": [
        "learn.fit_one_cycle(6,1e-4)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>acc4</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>3.644249</td>\n",
              "      <td>3.632674</td>\n",
              "      <td>0.061581</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>3.044180</td>\n",
              "      <td>3.223973</td>\n",
              "      <td>0.365809</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>2.411806</td>\n",
              "      <td>2.737695</td>\n",
              "      <td>0.459789</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>2.088001</td>\n",
              "      <td>2.458073</td>\n",
              "      <td>0.463695</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.969697</td>\n",
              "      <td>2.359560</td>\n",
              "      <td>0.465303</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>1.945775</td>\n",
              "      <td>2.345535</td>\n",
              "      <td>0.465993</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OFq-M4aXkTG5",
        "colab_type": "text"
      },
      "source": [
        "## Same thing with a loop\n",
        "\n",
        "Let's refactor this to use a for-loop. This does the same thing as before:\n",
        "\n",
        "![alt text](https://github.com/hduongck/AI-ML-Learning/blob/master/Pic/RNN3.PNG?raw=true)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RhlOikSqnU5c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Model1(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.i_h = nn.Embedding(nv,nh) #green arrow\n",
        "        self.h_h = nn.Linear(nh,nh) #brown arrow\n",
        "        self.h_o = nn.Linear(nh,nv) # blue line\n",
        "        self.bn = nn.BatchNorm1d(nh)\n",
        "        \n",
        "    def forward(self,x):\n",
        "        h = torch.zeros(x.shape[0],nh).to(device=x.device)\n",
        "        for i in range(x.shape[1]):\n",
        "            h = h + self.i_h(x[:,i])\n",
        "            h = self.bn(F.relu(self.h_h(h)))\n",
        "        \n",
        "        return self.h_o(h)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yxer7Qo3ld04",
        "colab_type": "text"
      },
      "source": [
        "This is the difference between unrolled (what we had before) and rolled (what we have now) RNN diagrams:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ihe9u1pplcO4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn = Learner(data,Model1(),loss_func=loss4,metrics=acc4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bpmV0HgjlkgO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "1ab66dac-d808-4153-cd0d-a51ce201c97b"
      },
      "source": [
        "learn.fit_one_cycle(6,1e-4)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>acc4</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>1.937885</td>\n",
              "      <td>2.158800</td>\n",
              "      <td>0.350414</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.764818</td>\n",
              "      <td>2.045693</td>\n",
              "      <td>0.339844</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.636290</td>\n",
              "      <td>1.997185</td>\n",
              "      <td>0.331572</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.577181</td>\n",
              "      <td>1.995895</td>\n",
              "      <td>0.324219</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.554903</td>\n",
              "      <td>2.012139</td>\n",
              "      <td>0.323759</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>1.549862</td>\n",
              "      <td>2.018103</td>\n",
              "      <td>0.322610</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MP62FH9LmAEO",
        "colab_type": "text"
      },
      "source": [
        "Our accuracy is about the same, since we are doing the same thing as before."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Pi958tGnE1i",
        "colab_type": "text"
      },
      "source": [
        "## Multi fully connected model\n",
        "\n",
        "Before, we were just predicting the last word in a line of text. Given 70 tokens, what is token 71? That approach was throwing away a lot of data. Why not predict token 2 from token 1, then predict token 3, then predict token 4, and so on? We will modify our model to do this."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CjhL7xnKoTqu",
        "colab_type": "text"
      },
      "source": [
        "the loop version is a lot slower because nn.RNN write that loop in CUDA C so it runs on the GPU while the python version has to say to the GPU run one step of the loop rather than other loop and each of those takes a lot of time . So that is one of annoying things about working with RNN is that they are not really fast enough to write them in pytorch loops like that. You kind of have to work with the existing machinery . So previous loop version is not something you would work in practice."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zLj4Na5VlnHN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = src.databunch(bs=bs,bptt=20)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-K2QhI_ort7u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d4fdc47e-d1fd-4721-cad4-451fd0594ec5"
      },
      "source": [
        "x,y = data.one_batch()\n",
        "x.shape,y.shape"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([64, 20]), torch.Size([64, 20]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XxyCM2hYryvZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Model2(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.i_h = nn.Embedding(nv,nh)\n",
        "        self.h_h = nn.Linear(nh,nh)\n",
        "        self.h_o = nn.Linear(nh,nv)\n",
        "        self.bn = nn.BatchNorm1d(nh)\n",
        "        \n",
        "    def forward(self,x):\n",
        "        h = torch.zeros(x.shape[0],nh).to(device=x.device)\n",
        "        res = []\n",
        "        for i in range(x.shape[1]):\n",
        "            h = h + self.i_h(x[:,i])\n",
        "            h = F.relu(self.h_h(h))\n",
        "            res.append(self.h_o(self.bn(h)))\n",
        "        return torch.stack(res,dim=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rcxb7xv8srih",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn = Learner(data,Model2(),metrics=accuracy)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BAKTbRIisw-b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "outputId": "d60c19ca-72af-48d7-c876-4d7848c53ce2"
      },
      "source": [
        "learn.fit_one_cycle(10,1e-4,pct_start=0.1)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>3.698139</td>\n",
              "      <td>3.687875</td>\n",
              "      <td>0.039560</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>3.602434</td>\n",
              "      <td>3.583583</td>\n",
              "      <td>0.150639</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>3.478865</td>\n",
              "      <td>3.468043</td>\n",
              "      <td>0.238849</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>3.346398</td>\n",
              "      <td>3.354091</td>\n",
              "      <td>0.273651</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>3.221698</td>\n",
              "      <td>3.258121</td>\n",
              "      <td>0.299077</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>3.116115</td>\n",
              "      <td>3.188085</td>\n",
              "      <td>0.312287</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>3.034905</td>\n",
              "      <td>3.142476</td>\n",
              "      <td>0.318608</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>2.978496</td>\n",
              "      <td>3.117679</td>\n",
              "      <td>0.331108</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>2.943944</td>\n",
              "      <td>3.108143</td>\n",
              "      <td>0.335085</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>2.925942</td>\n",
              "      <td>3.106726</td>\n",
              "      <td>0.335653</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zhmG1_ZOs7rq",
        "colab_type": "text"
      },
      "source": [
        "Note that our accuracy is worse now, because we are doing a harder task. When we predict word k (k<70), we have less history to help us then when we were only predicting word 71."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5BhDYD74s_zM",
        "colab_type": "text"
      },
      "source": [
        "### Maintain state\n",
        "\n",
        "To address this issue, let's keep the hidden state from the previous line of text\n",
        "\n",
        "`res = self.h_o(res)`\n",
        "\n",
        ", so we are not starting over again on each new line of text."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k9r8pD5as1Dx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Model3(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.i_h = nn.Embedding(nv,nh)\n",
        "        self.h_h = nn.Linear(nh,nh)\n",
        "        self.h_o = nn.Linear(nh,nv)\n",
        "        self.bn = nn.BatchNorm1d(nh)\n",
        "        self.h = torch.zeros(bs,nh).cuda()\n",
        "    def forward(self,x):\n",
        "        \n",
        "        res = []\n",
        "        h = self.h\n",
        "        for i in range(x.shape[1]):\n",
        "            h = h + self.i_h(x[:,i])\n",
        "            h = F.relu(self.h_h(h))\n",
        "            res.append(self.bn(h))\n",
        "        self.h = h.detach()\n",
        "        res = torch.stack(res,dim=1)\n",
        "        res = self.h_o(res)\n",
        "        return res"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qS8-329bto6_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn = Learner(data,Model3(),metrics=accuracy)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "251Ov6wLtwjA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 669
        },
        "outputId": "143b0e6b-a120-42d1-e9d2-b9575d6cdde4"
      },
      "source": [
        "learn.fit_one_cycle(20,3e-3)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>3.621734</td>\n",
              "      <td>3.508891</td>\n",
              "      <td>0.114134</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>3.283303</td>\n",
              "      <td>3.012769</td>\n",
              "      <td>0.375994</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>2.637859</td>\n",
              "      <td>2.105673</td>\n",
              "      <td>0.465128</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>2.038377</td>\n",
              "      <td>1.935312</td>\n",
              "      <td>0.338849</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.696197</td>\n",
              "      <td>1.819489</td>\n",
              "      <td>0.430398</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>1.473343</td>\n",
              "      <td>1.779536</td>\n",
              "      <td>0.471094</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>1.288067</td>\n",
              "      <td>1.931935</td>\n",
              "      <td>0.555398</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>1.090811</td>\n",
              "      <td>1.769333</td>\n",
              "      <td>0.497443</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.912858</td>\n",
              "      <td>1.534575</td>\n",
              "      <td>0.570739</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.768918</td>\n",
              "      <td>1.568856</td>\n",
              "      <td>0.578125</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.660622</td>\n",
              "      <td>1.581165</td>\n",
              "      <td>0.656250</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.576208</td>\n",
              "      <td>1.564929</td>\n",
              "      <td>0.622940</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.508743</td>\n",
              "      <td>1.590423</td>\n",
              "      <td>0.623366</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.456530</td>\n",
              "      <td>1.540348</td>\n",
              "      <td>0.676918</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.418257</td>\n",
              "      <td>1.578359</td>\n",
              "      <td>0.633168</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>0.389303</td>\n",
              "      <td>1.567448</td>\n",
              "      <td>0.642330</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>0.366459</td>\n",
              "      <td>1.584456</td>\n",
              "      <td>0.650639</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>0.350312</td>\n",
              "      <td>1.587716</td>\n",
              "      <td>0.651918</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>0.339302</td>\n",
              "      <td>1.595475</td>\n",
              "      <td>0.649858</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>0.332847</td>\n",
              "      <td>1.582491</td>\n",
              "      <td>0.656037</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g1rc9X22uLln",
        "colab_type": "text"
      },
      "source": [
        "Now we are getting greater accuracy than before!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HJxojxRbusHT",
        "colab_type": "text"
      },
      "source": [
        "## nn.RNN\n",
        "\n",
        "Let's refactor the above to use PyTorch's RNN. This is what you would use in practice, but now you know the inside details!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gxLoHzeItz1q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Model4(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.i_h = nn.Embedding(nv,nh)\n",
        "        self.rnn = nn.RNN(nh,nh,batch_first=True)\n",
        "        self.h_o = nn.Linear(nh,nv)\n",
        "        self.bn = BatchNorm1dFlat(nh)\n",
        "        self.h = torch.zeros(1,bs,nh).cuda()\n",
        "        \n",
        "    def forward(self,x):\n",
        "        res,h = self.rnn(self.i_h(x),self.h)\n",
        "        self.h = h.detach()\n",
        "        return self.h_o(self.bn(res))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SWtVap0lvZZe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn = Learner(data,Model4(),metrics=accuracy)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-5p8XjrDvgcK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 669
        },
        "outputId": "84f1009c-079a-4bf1-c988-4fac1216c824"
      },
      "source": [
        "learn.fit_one_cycle(20,3e-3)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>3.586282</td>\n",
              "      <td>3.447632</td>\n",
              "      <td>0.143608</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>3.116198</td>\n",
              "      <td>2.594665</td>\n",
              "      <td>0.441406</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>2.404595</td>\n",
              "      <td>1.953668</td>\n",
              "      <td>0.409162</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.903025</td>\n",
              "      <td>2.058820</td>\n",
              "      <td>0.316832</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.630150</td>\n",
              "      <td>1.789130</td>\n",
              "      <td>0.460014</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>1.419893</td>\n",
              "      <td>1.735064</td>\n",
              "      <td>0.518395</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>1.225648</td>\n",
              "      <td>1.564154</td>\n",
              "      <td>0.515270</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>1.027750</td>\n",
              "      <td>1.508618</td>\n",
              "      <td>0.526278</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.847054</td>\n",
              "      <td>1.431779</td>\n",
              "      <td>0.543253</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.714270</td>\n",
              "      <td>1.392497</td>\n",
              "      <td>0.563139</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.614420</td>\n",
              "      <td>1.401409</td>\n",
              "      <td>0.577202</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.540015</td>\n",
              "      <td>1.426392</td>\n",
              "      <td>0.594247</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.483495</td>\n",
              "      <td>1.393414</td>\n",
              "      <td>0.613139</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.439441</td>\n",
              "      <td>1.343446</td>\n",
              "      <td>0.622230</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.404879</td>\n",
              "      <td>1.343975</td>\n",
              "      <td>0.622443</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>0.376211</td>\n",
              "      <td>1.329729</td>\n",
              "      <td>0.627557</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>0.353247</td>\n",
              "      <td>1.307252</td>\n",
              "      <td>0.635227</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>0.336946</td>\n",
              "      <td>1.334931</td>\n",
              "      <td>0.628196</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>0.325996</td>\n",
              "      <td>1.375788</td>\n",
              "      <td>0.623793</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>0.319607</td>\n",
              "      <td>1.360788</td>\n",
              "      <td>0.625071</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RGXA5_vLvoUZ",
        "colab_type": "text"
      },
      "source": [
        "## 2-layer GRU():\n",
        "\n",
        "When you have long time scales and deeper networks, these become impossible to train. One way to address this is to add mini-NN to decide how much of the green arrow and how much of the orange arrow to keep. These mini-NNs can be GRUs or LSTMs. We will cover more details of this in a later lesson."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lghhe3mYvi6X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Model5(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.i_h = nn.Embedding(nv,nh)\n",
        "        self.rnn = nn.GRU(nh, nh, 2, batch_first=True)\n",
        "        self.h_o = nn.Linear(nh,nv)\n",
        "        self.bn = BatchNorm1dFlat(nh)\n",
        "        self.h = torch.zeros(2, bs, nh).cuda()\n",
        "        \n",
        "    def forward(self, x):\n",
        "        res,h = self.rnn(self.i_h(x), self.h)\n",
        "        self.h = h.detach()\n",
        "        return self.h_o(self.bn(res))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OZCurJyYw-oN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn = Learner(data, Model5(), metrics=accuracy)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q3KcnoADxJLd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "outputId": "c4baa926-128c-487d-ca42-ce15d86c580f"
      },
      "source": [
        "learn.fit_one_cycle(10,1e-2)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>2.883967</td>\n",
              "      <td>2.312016</td>\n",
              "      <td>0.456676</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.789046</td>\n",
              "      <td>1.644801</td>\n",
              "      <td>0.559801</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.922462</td>\n",
              "      <td>1.224658</td>\n",
              "      <td>0.778977</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.451269</td>\n",
              "      <td>0.856259</td>\n",
              "      <td>0.839418</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.224592</td>\n",
              "      <td>0.950845</td>\n",
              "      <td>0.836790</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.117308</td>\n",
              "      <td>1.000393</td>\n",
              "      <td>0.835369</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.065270</td>\n",
              "      <td>1.019392</td>\n",
              "      <td>0.834517</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.039372</td>\n",
              "      <td>1.061049</td>\n",
              "      <td>0.836861</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.025762</td>\n",
              "      <td>1.044991</td>\n",
              "      <td>0.835653</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.018671</td>\n",
              "      <td>1.064459</td>\n",
              "      <td>0.834020</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BFiv7f5txOFJ",
        "colab_type": "text"
      },
      "source": [
        "**Connection to ULMFi**t\n",
        "\n",
        "In the previous lesson, we were essentially swapping out **self.h_o** with a classifier in order to do classification on text.\n",
        "\n",
        "\n",
        "**RNNs are just a refactored, fully-connected neural network.**\n",
        "\n",
        "You can use the same approach for any sequence labeling task (part of speech, classifying whether material is sensitive,..)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4MWt8_AhxLz7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}