{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "A Tutorial to Fine-Tuning BERT with Fast AI: multi labels text classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hduongck/AI-ML-Learning/blob/master/Huggingface/Fine_Tuning_BERT_with_Fast_AI_multi_labels_text_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IqaF0aini2Jh",
        "colab_type": "text"
      },
      "source": [
        "https://mlexplained.com/2019/05/13/a-tutorial-to-fine-tuning-bert-with-fast-ai/\n",
        "\n",
        "https://medium.com/@abhikjha/fastai-integration-with-bert-a0a66b1cecbe\n",
        "\n",
        "https://towardsdatascience.com/best-of-two-worlds-pytorch-transformers-meets-fastai-5fd51ef34b0f\n",
        "\n",
        "https://colab.research.google.com/drive/1KFlyttLs7aAX35lMLiDw9Bb0s_74ILMy?source=post_page-----5fd51ef34b0f----------------------#scrollTo=TSCR44zrlBQw\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kfybPKGaouhQ",
        "colab_type": "code",
        "outputId": "e93ea9e2-b237-49d6-f2a7-38b36e187ae0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 700
        }
      },
      "source": [
        "! pip install pytorch-transformers"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pytorch-transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/b7/d3d18008a67e0b968d1ab93ad444fc05699403fa662f634b2f2c318a508b/pytorch_transformers-1.2.0-py3-none-any.whl (176kB)\n",
            "\r\u001b[K     |█▉                              | 10kB 14.0MB/s eta 0:00:01\r\u001b[K     |███▊                            | 20kB 1.6MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 30kB 2.4MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 40kB 1.6MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 51kB 2.0MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 61kB 2.3MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 71kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 81kB 3.1MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 92kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 102kB 2.6MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 112kB 2.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 122kB 2.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 133kB 2.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 143kB 2.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 153kB 2.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 163kB 2.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 174kB 2.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 184kB 2.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (1.2.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (1.16.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (4.28.1)\n",
            "Collecting regex (from pytorch-transformers)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6f/a6/99eeb5904ab763db87af4bd71d9b1dfdd9792681240657a4c0a599c10a81/regex-2019.08.19.tar.gz (654kB)\n",
            "\u001b[K     |████████████████████████████████| 655kB 39.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (2.21.0)\n",
            "Collecting sacremoses (from pytorch-transformers)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1f/8e/ed5364a06a9ba720fddd9820155cc57300d28f5f43a6fd7b7e817177e642/sacremoses-0.0.35.tar.gz (859kB)\n",
            "\u001b[K     |████████████████████████████████| 860kB 48.6MB/s \n",
            "\u001b[?25hCollecting sentencepiece (from pytorch-transformers)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/3d/efb655a670b98f62ec32d66954e1109f403db4d937c50d779a75b9763a29/sentencepiece-0.1.83-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 43.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (1.9.236)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-transformers) (2019.9.11)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-transformers) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-transformers) (3.0.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->pytorch-transformers) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->pytorch-transformers) (7.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->pytorch-transformers) (0.13.2)\n",
            "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-transformers) (0.2.1)\n",
            "Requirement already satisfied: botocore<1.13.0,>=1.12.236 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-transformers) (1.12.236)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-transformers) (0.9.4)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.236->boto3->pytorch-transformers) (0.15.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.236->boto3->pytorch-transformers) (2.5.3)\n",
            "Building wheels for collected packages: regex, sacremoses\n",
            "  Building wheel for regex (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for regex: filename=regex-2019.8.19-cp36-cp36m-linux_x86_64.whl size=609230 sha256=f14da95ae2439a4f1dc45e53f8e5b19edc4c269c921446c8c831f16aac6704ba\n",
            "  Stored in directory: /root/.cache/pip/wheels/90/04/07/b5010fb816721eb3d6dd64ed5cc8111ca23f97fdab8619b5be\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.35-cp36-none-any.whl size=883999 sha256=e829e7341f0b51a3280f5e8746f54f6778f7b1badb1dcf4ba3d66fe9e6d9671b\n",
            "  Stored in directory: /root/.cache/pip/wheels/63/2a/db/63e2909042c634ef551d0d9ac825b2b0b32dede4a6d87ddc94\n",
            "Successfully built regex sacremoses\n",
            "Installing collected packages: regex, sacremoses, sentencepiece, pytorch-transformers\n",
            "Successfully installed pytorch-transformers-1.2.0 regex-2019.8.19 sacremoses-0.0.35 sentencepiece-0.1.83\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1qCtZTA7xxpJ",
        "colab_type": "code",
        "outputId": "a561e7d5-68fc-4839-886b-1a2e5d6c5d56",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "%reload_ext autoreload\n",
        "%autoreload 2\n",
        "%matplotlib inline\n",
        "\n",
        "import os\n",
        "\n",
        "os.makedirs(\"data\\toxic\",exist_ok=True)\n",
        "os.makedirs(\".kaggle\",exist_ok=True)\n",
        "#!mkdir .kaggle\n",
        "\n",
        "import json \n",
        "token = {\"username\":\"hduongck\",\"key\":\"983e2ab1fbb29cf2734bcbf8811d42fb\"}\n",
        "with open('/content/.kaggle/kaggle.json', 'w') as file:\n",
        "    json.dump(token, file)\n",
        " \n",
        "!chmod 600 /content/.kaggle/kaggle.json\n",
        "\n",
        "!kaggle config set -n path -v{/content/data}\n",
        "\n",
        "!cp /content/.kaggle/kaggle.json ~/.kaggle/kaggle.json\n",
        "!kaggle competitions download -c jigsaw-toxic-comment-classification-challenge -p /content/data/toxic"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/kaggle\", line 6, in <module>\n",
            "    from kaggle.cli import main\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/kaggle/__init__.py\", line 23, in <module>\n",
            "    api.authenticate()\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/kaggle/api/kaggle_api_extended.py\", line 146, in authenticate\n",
            "    self.config_file, self.config_dir))\n",
            "IOError: Could not find kaggle.json. Make sure it's located in /root/.kaggle. Or use the environment method.\n",
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.6 / client 1.5.4)\n",
            "Downloading sample_submission.csv.zip to /content/data/toxic\n",
            "  0% 0.00/1.39M [00:00<?, ?B/s]\n",
            "100% 1.39M/1.39M [00:00<00:00, 47.0MB/s]\n",
            "Downloading test.csv.zip to /content/data/toxic\n",
            " 38% 9.00M/23.4M [00:00<00:00, 37.7MB/s]\n",
            "100% 23.4M/23.4M [00:00<00:00, 67.2MB/s]\n",
            "Downloading train.csv.zip to /content/data/toxic\n",
            " 34% 9.00M/26.3M [00:00<00:00, 32.9MB/s]\n",
            "100% 26.3M/26.3M [00:00<00:00, 66.5MB/s]\n",
            "Downloading test_labels.csv.zip to /content/data/toxic\n",
            "  0% 0.00/1.46M [00:00<?, ?B/s]\n",
            "100% 1.46M/1.46M [00:00<00:00, 98.8MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jEEdxioAydE8",
        "colab_type": "code",
        "outputId": "354b1b96-2cab-45e5-ee68-07e4969b4e0d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "!unzip /content/data/toxic/\\*.zip -d data/toxic/"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/data/toxic/test.csv.zip\n",
            "  inflating: data/toxic/test.csv     \n",
            "\n",
            "Archive:  /content/data/toxic/train.csv.zip\n",
            "  inflating: data/toxic/train.csv    \n",
            "\n",
            "Archive:  /content/data/toxic/sample_submission.csv.zip\n",
            "  inflating: data/toxic/sample_submission.csv  \n",
            "\n",
            "Archive:  /content/data/toxic/test_labels.csv.zip\n",
            "  inflating: data/toxic/test_labels.csv  \n",
            "\n",
            "4 archives were successfully processed.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pSBRyG1So9BZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from typing import *\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "\n",
        "from fastai import *\n",
        "from fastai.text import *\n",
        "from fastai.callbacks import *\n",
        "\n",
        "from fastai.basic_train import *\n",
        "from fastai.basic_train import BasicLearner\n",
        "import sys\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rJXInpydlA0h",
        "colab_type": "text"
      },
      "source": [
        "# A Tutorial to Fine-Tuning BERT with Fast AI\n",
        "\n",
        "\n",
        "Unless you’ve been living under a rock for the past year, you’ve probably heard of fastai. It’s a framework that incorporates best practices for deep learning behind an easy-to-use interface. Chances are, you’ve also heard of BERT. It’s the new hottest method for transfer learning in NLP (if you’re not familiar with BERT, I’ve written a blog post about it in the past).  Although BERT is very powerful, it’s not currently built in as a feature of fastai.\n",
        "\n",
        "In this post, I’ll be covering how to use BERT with fastai (it’s surprisingly simple!). I’ll be using the Jigsaw dataset (a sentence classification task) to demonstrate this and will be diving into the details of fastai in the process.\n",
        "\n",
        "You can find the full notebook for this tutorial [here](https://github.com/keitakurita/Practical_NLP_in_PyTorch/blob/master/fastai/bert_with_fastai.ipynb). I’m also trying something new and publishing my tutorial as a public kernel on Kaggle which you can run here. With kernels, you can run code on GPUs and actually see how the code works on the entire dataset, so if things work out well I’m probably going to continue this."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ALLc36Km94m",
        "colab_type": "text"
      },
      "source": [
        "## The Basics of Fast AI\n",
        "\n",
        "To understand how to use BERT with fastai, you first need an overall picture of how fastai works. Feel free to skip ahead if you’re already familiar with the basics of fastai.\n",
        "\n",
        "Since fastai is built on top of PyTorch, it uses the same underlying primitives to handle data (datasets and dataloaders). However, unlike many other frameworks, it doesn’t directly expose the datasets and dataloaders and instead wraps them up in a **Databunch**.\n",
        "\n",
        "The **Databunch** handles all the processing of data behind the scenes and prepares the data to be passed to a **Learner**.\n",
        "\n",
        "The **Learner** wraps the databunch, the model, and the loss and optimizer as well as everything else necessary for training (e.g. callbacks). \n",
        "\n",
        "![alt text](https://i0.wp.com/mlexplained.com/wp-content/uploads/2019/05/Screen-Shot-2019-05-10-at-11.18.52-AM.png?resize=300%2C250&ssl=1)\n",
        "\n",
        "```The Overview of Important FastAI Primitives```\n",
        "\n",
        "The fact that everything is wrapped up in a convenient object is both a major strength and weakness of fastai. It makes the API very easy to understand and the code readable. On the other hand, it can make customization a bit tedious. We’ll see in this post that customizing the code for BERT is very easy though.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HeSsBl6Ln6Sw",
        "colab_type": "text"
      },
      "source": [
        "### Preprocessing in Databunches\n",
        "\n",
        "Preprocessing is a key part of deep learning and to use BERT, we’ll need to modify the databunch to handle preprocessing according to BERT conventions.\n",
        "\n",
        "In fastai, the preprocessing pipeline is a list of **Preprocessors**, each of which handles a key step in preprocessing. For example, in text-related databunches, **there is a preprocessor handling tokenization and a preprocessor handling numericalization. To customize this pipeline, we simply need to swap in our own custom Preprocessors that each handle a part of the preprocessing or configure the Preprocessors** – which is exactly what we will be doing in this post."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TLC750lhofsO",
        "colab_type": "text"
      },
      "source": [
        "## Using BERT with fastai\n",
        "There are three things we need to be careful of when using BERT with fastai.\n",
        "\n",
        "- BERT uses its own wordpiece tokenizer.\n",
        "- BERT needs [CLS] and [SEP] tokens added to each sequence.\n",
        "- BERT uses its own pre-built vocabulary."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fT1g-mvUqxAE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pytorch_transformers import *"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GWY8jnpPiw10",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Config(dict):\n",
        "    def __init__(self, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        for k, v in kwargs.items():\n",
        "            setattr(self, k, v)\n",
        "    \n",
        "    def set(self, key, val):\n",
        "        self[key] = val\n",
        "        setattr(self, key, val)\n",
        "\n",
        "config = Config(\n",
        "    bert_model_name=\"bert-base-uncased\",\n",
        "    max_lr=3e-5,\n",
        "    epochs=1,\n",
        "    use_fp16= True,\n",
        "    bs= 8,\n",
        "    discriminative=False,\n",
        "    max_seq_len=128,\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HvNC7oT6sNWh",
        "colab_type": "text"
      },
      "source": [
        "### Using the wordpiece tokenizer and handling special tokens\n",
        "\n",
        "Writing our own wordpiece tokenizer and handling the mapping from wordpiece to id would be a major pain. Thankfully, the wonderful pytorch-transformers package gives us all of the necessary information in its BertTokenizer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yxX5YYGisDU-",
        "colab_type": "code",
        "outputId": "eff6ad7c-ec00-4b40-ef75-a1cbe648d05e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#bert_tok = BertTokenizer.from_pretrained(config.bert_model_name,)\n",
        "bert_tok = BertTokenizer.from_pretrained(\n",
        "    config.bert_model_name,\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 231508/231508 [00:00<00:00, 415837.44B/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ED36KzM-sr9a",
        "colab_type": "text"
      },
      "source": [
        "BERT has multiple flavors, so we pass the class the name of the BERT model we’ll be using (in this post we’ll be using the uncased, smaller version).\n",
        "\n",
        "Fastai has internal conventions regarding tokenization so we wrap this tokenizer in its own Tokenizer class. This is a bit confusing, but shouldn’t be much of a hassle.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "48C2Vb5EsfFV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class FastAiBertTokenizer(BaseTokenizer):\n",
        "    \"\"\"Wrapper around BertTokenizer to be compatible with fast.ai\"\"\"\n",
        "    def __init__(self, tokenizer: BertTokenizer, max_seq_len: int=128, **kwargs):\n",
        "        self._pretrained_tokenizer = tokenizer\n",
        "        self.max_seq_len = max_seq_len\n",
        "\n",
        "    def __call__(self, *args, **kwargs):\n",
        "        return self\n",
        "\n",
        "    def tokenizer(self, t:str) -> List[str]:\n",
        "        \"\"\"Limits the maximum sequence length\"\"\"\n",
        "        return [\"[CLS]\"] + self._pretrained_tokenizer.tokenize(t)[:self.max_seq_len - 2] + [\"[SEP]\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lG0a6CYyuZlz",
        "colab_type": "text"
      },
      "source": [
        "As you can see, we’re adding the [CLS] and [SEP] tokens here, as well as limiting the length of the tokenized sequence. \n",
        "\n",
        "Somewhat confusingly, we need to **wrap the above code within another Tokenizer to pass to the preprocessors**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vb35CnMSusTO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fastai_tokenizer = Tokenizer(tok_func=FastAiBertTokenizer(bert_tok, max_seq_len=config.max_seq_len), pre_rules=[], post_rules=[])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EuqaVhhAvRUI",
        "colab_type": "text"
      },
      "source": [
        "This multi-layered tokenization scheme was what confused me the most, but it wasn’t hard to grasp after reading the code a bit. Now, we move on to handling the third point: using BERT’s pre-built vocabulary."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JhLSUAcWv0BB",
        "colab_type": "text"
      },
      "source": [
        "### Using the BERT vocabulary\n",
        "\n",
        "The bert tokenizer also contains the vocabulary as a dictionary mapping from wordpiece to id. As with the tokenizer, since fastai has its own conventions regarding the vocabulary, we’ll need to construct a fastai Vocab object from the bert vocabulary. Thankfully, this is simple – we can do it simply by passing a list of tokens in the vocabulary."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZB2p2_oOv7Pw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fastai_bert_vocab =Vocab(list(bert_tok.vocab.keys()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xrUFktOhwLnZ",
        "colab_type": "text"
      },
      "source": [
        "### Putting it all together\n",
        "\n",
        "Now we have everything we need to build the databunch. We’ll be building the databunch from dataframes in this tutorial, but there are multiple ways of loading data (see the official docs).\n",
        "\n",
        "We first load the data into a dataframe using pandas where we also handle the validation set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yd81XxN6wC41",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "path = '/content/data/toxic/'\n",
        "train,test = [pd.read_csv(f'{path}{fname}') for fname in ['train.csv','test.csv']]\n",
        "train,val = train_test_split(train)\n",
        "\n",
        "#if config.testing:\n",
        "#    train = train.head(1024)\n",
        "#    val = val.head(1024)\n",
        "#    test = test.head(1024)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D2qF977TnxwU",
        "colab_type": "code",
        "outputId": "f0254140-459f-488b-82cd-4d5c057c9038",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "train.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>comment_text</th>\n",
              "      <th>toxic</th>\n",
              "      <th>severe_toxic</th>\n",
              "      <th>obscene</th>\n",
              "      <th>threat</th>\n",
              "      <th>insult</th>\n",
              "      <th>identity_hate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>135581</th>\n",
              "      <td>d516c18e4a785b65</td>\n",
              "      <td>Don't worry, he resorted to using anonymous IP...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61126</th>\n",
              "      <td>a3a5f95df3b1efb7</td>\n",
              "      <td>P.S. Though I did get honors on my second Asso...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17332</th>\n",
              "      <td>2dbffa6d78ef4d2a</td>\n",
              "      <td>@Strikeeagle stop using personnal attacks its ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>85156</th>\n",
              "      <td>e3d29008c01210f6</td>\n",
              "      <td>Typical.  Every time some clown tries to sound...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>112789</th>\n",
              "      <td>5b5cb61acb70b991</td>\n",
              "      <td>How is it disruptive? How else should I write ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                      id  ... identity_hate\n",
              "135581  d516c18e4a785b65  ...             0\n",
              "61126   a3a5f95df3b1efb7  ...             0\n",
              "17332   2dbffa6d78ef4d2a  ...             0\n",
              "85156   e3d29008c01210f6  ...             0\n",
              "112789  5b5cb61acb70b991  ...             0\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LURG5ICOpUzO",
        "colab_type": "code",
        "outputId": "7e51ca2a-1e74-4e5d-d04b-2c166f045148",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "test.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>comment_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>00001cee341fdb12</td>\n",
              "      <td>Yo bitch Ja Rule is more succesful then you'll...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0000247867823ef7</td>\n",
              "      <td>== From RfC == \\n\\n The title is fine as it is...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>00013b17ad220c46</td>\n",
              "      <td>\" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lap...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>00017563c3f7919a</td>\n",
              "      <td>:If you have a look back at the source, the in...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>00017695ad8997eb</td>\n",
              "      <td>I don't anonymously edit articles at all.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 id                                       comment_text\n",
              "0  00001cee341fdb12  Yo bitch Ja Rule is more succesful then you'll...\n",
              "1  0000247867823ef7  == From RfC == \\n\\n The title is fine as it is...\n",
              "2  00013b17ad220c46  \" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lap...\n",
              "3  00017563c3f7919a  :If you have a look back at the source, the in...\n",
              "4  00017695ad8997eb          I don't anonymously edit articles at all."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ZCHEFeMpW-K",
        "colab_type": "code",
        "outputId": "39d45ec1-29db-487c-943b-468c041898a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "val.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>comment_text</th>\n",
              "      <th>toxic</th>\n",
              "      <th>severe_toxic</th>\n",
              "      <th>obscene</th>\n",
              "      <th>threat</th>\n",
              "      <th>insult</th>\n",
              "      <th>identity_hate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>67443</th>\n",
              "      <td>b4753614fe756c7f</td>\n",
              "      <td>Hello \\n\\nI have just blocked you (and your op...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>70356</th>\n",
              "      <td>bc3c488b3deb4ce9</td>\n",
              "      <td>Hi {{u|Maile66]]. Thanks for your note. I left...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>111677</th>\n",
              "      <td>55692fce0e1b83ef</td>\n",
              "      <td>As the newest guy on the block, a question to ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>143550</th>\n",
              "      <td>ffa96ed64823dfa2</td>\n",
              "      <td>Help me! \\n\\n \\nIn December of 2013 I was told...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>94900</th>\n",
              "      <td>fdb7996fa3eca5bb</td>\n",
              "      <td>You clearly don't understand my position on th...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                      id  ... identity_hate\n",
              "67443   b4753614fe756c7f  ...             0\n",
              "70356   bc3c488b3deb4ce9  ...             0\n",
              "111677  55692fce0e1b83ef  ...             0\n",
              "143550  ffa96ed64823dfa2  ...             0\n",
              "94900   fdb7996fa3eca5bb  ...             0\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tPyJkqoglPYF",
        "colab_type": "text"
      },
      "source": [
        "Now, we call the from_df method on the TextDataBunch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z5yl9tS5lHWG",
        "colab_type": "code",
        "outputId": "2f0b9d60-1972-4e53-e40a-fe573aed3c02",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        }
      },
      "source": [
        "label_cols = [\"toxic\",\"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n",
        "\n",
        "databunch = TextDataBunch.from_df(\".\", train, val, test,\n",
        "                  tokenizer=fastai_tokenizer,\n",
        "                  vocab=fastai_bert_vocab,\n",
        "                  include_bos=False,\n",
        "                  include_eos=False,\n",
        "                  text_cols=\"comment_text\",\n",
        "                  label_cols=label_cols,\n",
        "                  bs=config.bs,\n",
        "                  collate_fn=partial(pad_collate, pad_first=False, pad_idx=0),\n",
        "             )\n",
        "databunch"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TextClasDataBunch;\n",
              "\n",
              "Train: LabelList (119678 items)\n",
              "x: TextList\n",
              "[CLS] don ' t worry , he resort ##ed to using anonymous ip ##s to get around that rule [SEP],[CLS] p . s . though i did get honors on my second associate ' s degree in spanish from de an ##za college , i have not taken my bachelor ' s yet , which i could from um ##ass / boston , but the gp ##a would be w / o honors , unlike everyone else in my family , including my younger siblings . it would be in spanish , but i ' ve also re ##app ##lie ##d for school in the fall , san jose state . [SEP],[CLS] @ strike ##ea ##gle stop using person ##nal attacks its called h ##yp ##oc ##ras ##y 86 . 182 . 174 . 123 [SEP],[CLS] typical . every time some clown tries to sound intelligent , he goes and uses words he just looked up . that is not intelligent . having the mind that can reason and not have bias ##es is intelligent . [SEP],[CLS] how is it disrupt ##ive ? how else should i write it ? i added links to prove my accusations , what more could i do ? where exactly do you see personal attacks in the linked comment ? those two accounts have been rev ##ert warring over the template for months , certainly it ' s not a personal attack to call that behavior disrupt ##ive ? also i was invited to the discussion , so why i ' m blocked for stating my opinion ? 90 . 179 . 235 . 249 [SEP]\n",
              "y: MultiCategoryList\n",
              ",,,,\n",
              "Path: .;\n",
              "\n",
              "Valid: LabelList (39893 items)\n",
              "x: TextList\n",
              "[CLS] hello i have just blocked you ( and your opponent ) for 24 hours for violating wikipedia ' s rule against rev ##ert ##ing an article more than three times in a 24 hour period , which you can review here . edit warring is harmful to wikipedia please use this time to think of ways you can come to an agreement when the block ex ##pire ##s . thanks . · ( sc ##ri ##bble ) / [SEP],[CLS] hi { { u | mail ##e ##66 ] ] . thanks for your note . i left it in my last edit summary but i ' ll also leave it here wikipedia : village pump ( technical ) # something is wrong with wi ##kim ##ed ##ia commons and the images . the images show up just fine for me . as to military dating it is noted at w ##p : strong ##nat that is modern format ##ting . that wasn ' t the case when he was in the military when he was in it . i suspect you will rev ##ert it back so i will just say best wishes and thanks for your work on audi ##e ' s article and [SEP],[CLS] as the newest guy on the block , a question to help me understand what is and isn ' t okay . if i were the one making all of the statements above rather than those who are , wouldn ' t i have been smacked down with references to rules about forum , synthesis , and original research , and maybe even weight ? sorry to ask but my common sense just wouldn ' t leave me alone until i put this question out . he is completely confused . i have to admit . i am too . < > [SEP],[CLS] help me ! in december of 2013 i was told that i had 6 month to make corrections and updates to this page or it would be deleted . i edited the page , saved it , but do not see a res ##ub ##mit button . help me with . . . [SEP],[CLS] you clearly don ' t understand my position on the topic or the reason pages are protected . edit wars should not continue and this has therefore been protected . ( t ) [SEP]\n",
              "y: MultiCategoryList\n",
              ",,,,\n",
              "Path: .;\n",
              "\n",
              "Test: LabelList (153164 items)\n",
              "x: TextList\n",
              "[CLS] yo bitch ja rule is more su ##cc ##es ##ful then you ' ll ever be what ##s up with you and hating you sad mo ##fu ##ck ##as . . . i should bitch slap ur pet ##hed ##ic white faces and get you to kiss my ass you guys sick ##en me . ja rule is about pride in da music man . don ##t di ##ss that shit on him . and nothin is wrong bei ##n like tu ##pac he was a brother too . . . fuck ##in white boys get things right next time . , [SEP],[CLS] = = from rfc = = the title is fine as it is , im ##o . [SEP],[CLS] \" = = sources = = * za ##we ashton on lap ##land — / \" [SEP],[CLS] : if you have a look back at the source , the information i updated was the correct form . i can only guess the source hadn ' t updated . i shall update the information once again but thank you for your message . [SEP],[CLS] i don ' t anonymous ##ly edit articles at all . [SEP]\n",
              "y: EmptyLabelList\n",
              ",,,,\n",
              "Path: ."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6wANHoD_okYd",
        "colab_type": "text"
      },
      "source": [
        "Notice we’re passing the include_bos=False and include_eos=False options. This is because fastai adds its own bos and eos tokens by default which interferes with the [CLS] and [SEP] tokens added by BERT. Note that this option is new and might not be available for older versions of fastai."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "va1TuaKDtpNS",
        "colab_type": "text"
      },
      "source": [
        "### What’s going on behind the scenes?\n",
        "\n",
        "Let’s dive a bit deeper to understand what exactly is going on behind the scenes. The above code initializes a TokenizerProcessor and a NumericalizeProcessor with the wordpiece tokenizer and BERT vocabulary, then applies it to each piece of text in the dataframe.\n",
        "\n",
        "In fact, we can also initialize our own TokenizerProcessor and NumericalizeProcessor and pass them to the databunch instead of passing configurations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MK2qwzejt6MK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BertTokenizeProcessor(TokenizeProcessor):\n",
        "    def __init__(self,tokenizer):\n",
        "        super().__init__(tokenizer = tokenizer, include_bos = False, include_eos = False)\n",
        "\n",
        "class BertNumericalizeProcessor(NumericalizeProcessor):\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super().__init__(*args, vocab = Vocab(list(bert_tok.vocab.keys())), **kwargs)\n",
        "\n",
        "def get_bert_processor(tokenizer:Tokenizer = None, vocab: Vocab = None):\n",
        "    \"\"\"\n",
        "    Constructing preprocessors for BERT\n",
        "    We remove sos/eos tokens since we add that ourselves in the tokenizer.\n",
        "    We also use a custom vocabulary to match the numericalization with the original BERT model.\n",
        "    \"\"\"\n",
        "    return [BertTokenizeProcessor(tokenizer=tokenizer),\n",
        "            NumericalizeProcessor(vocab=vocab)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ejvZljAvN6G",
        "colab_type": "text"
      },
      "source": [
        "We’re simply **wrapping the tokenizer and vocabulary, then putting them together in a pipeline** to preprocess the text. To use this pipeline, we’ll need to slightly modify the databunch code to call the **get_bert_processor** internally."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-5gXgt0mu3O8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BertDataBunch(TextDataBunch):\n",
        "    @classmethod\n",
        "    def from_df(cls, path:PathOrStr, train_df: DataFrame, valid_df:DataFrame, test_df: Optional[DataFrame]=None,\n",
        "                tokenizer: Tokenizer = None, vocab: Vocab = None, classes: Collection[str] = None,\n",
        "                text_cols : IntsOrStrs=1, label_cols: IntsOrStrs = 0, label_delim : str=None, **kwargs) -> DataBunch:\n",
        "               \"Create a `TextDataBunch` from DataFrames.\"\n",
        "               p_kwargs, kwargs = split_kwargs_by_func(kwargs, get_bert_processor)\n",
        "               # use our custom processors while taking tokenizer and vocab as kwargs\n",
        "               processor = get_bert_processor(tokenizer= tokenizer, vocab = vocab, **p_kwargs)\n",
        "               if classes is None and is_listy(label_cols) and len(label_cols) > 1: classes = label_cols\n",
        "               src = ItemLists(path, TextList.from_df(train_df, path, cols = text_cols, processor=processor),\n",
        "                               TextList.from_df(valid_df,path, cols = text_cols, processor= processor))\n",
        "               src = src.label_for_lm() if cls == TextLMDataBunch else src.label_from_df(cols = label_cols, classes = classes)\n",
        "               if test_df is not None: src.add_test(TextList.from_df(test_df, path, cols = text_cols))\n",
        "               return src.databunch(**kwargs) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5JrDElRpxiql",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "#this will produce a virtually identical databunch to the code above\n",
        "\n",
        "#databunch = BertDataBunch.from_df(\".\", train, val, test,\n",
        " #                  tokenizer=fastai_tokenizer,\n",
        "  #                text_cols=\"comment_text\",\n",
        "   #                label_cols=label_cols,\n",
        "    #               bs=config.bs,\n",
        "     #              collate_fn=partial(pad_collate, pad_first=False, pad_idx=0),\n",
        "      #        )\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4FL8a_SgyZ8t",
        "colab_type": "text"
      },
      "source": [
        "Both of these approaches should produce the same results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ldPycOSmyfgC",
        "colab_type": "text"
      },
      "source": [
        "### Initializing the Learner\n",
        "\n",
        "Now that we have the databunch prepared, most of the rest is simple fastai magic. We’ll initialize the bert model and the loss function, then pass them to the Learner."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tptHDPpwxoD9",
        "colab_type": "code",
        "outputId": "84edf248-df9c-4c6c-fdc7-a85bf707b6a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "bert_model = BertForSequenceClassification.from_pretrained(config.bert_model_name, num_labels=6)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 313/313 [00:00<00:00, 136467.48B/s]\n",
            "100%|██████████| 440473133/440473133 [00:32<00:00, 13700821.23B/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T30y8CYnz_k-",
        "colab_type": "text"
      },
      "source": [
        "Since this is a multilabel classification problem, we're using BCEWithLogitsLoss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UdVNbVYmzXRn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss_func = nn.BCEWithLogitsLoss()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AXwJM5ht0JIs",
        "colab_type": "text"
      },
      "source": [
        "And now we can build the Learner."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "99OetXph0Fxz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "acc = partial(accuracy_thresh, thresh = 0.25)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RM1wkg7b0R90",
        "colab_type": "text"
      },
      "source": [
        "And we're done! All the rest is fastai magic. For example, you can use **half-precision training simply by calling learner.to_fp16()**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5d2Lhz2U0RUL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#if config.use_fp16 : learner = learner.to_fp16()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GFoYImGb0n0T",
        "colab_type": "text"
      },
      "source": [
        "We can also use the learning rate finder. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DTlI-KO21biS",
        "colab_type": "text"
      },
      "source": [
        "#### BUT WE HAVE A PROBLEM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dR-9EcZ71Qn9",
        "colab_type": "text"
      },
      "source": [
        "We have a problem\n",
        "The solutions and codes provided above all work fine until the update of Pytorch-transformers. If you run through the codes from the above articles which were written before the update. You will likely to be hit with such an exception :\n",
        "\n",
        "![alt text](https://miro.medium.com/max/1852/1*xK6il3hJDPCt5-FK2DBR1g.png)\n",
        "![alt text](https://miro.medium.com/max/1752/1*PFT1aSvxPLKfF5mSvgfslg.png)\n",
        "\n",
        "If you like me, who did not have much experience with Pytorch-transformers, you may feel extremely confused and wonder why it works for others but not on my machine! Without digging too much in the traceback of the exception, I thought it happened because my Torch is outdated. I updated Torch up to the most recent version however still received the exception.\n",
        "After reading the Pytorch-transformers doc I realized the exception was incurred by the change of API in the Pytorch-transformers package. In short, in the old days BEFORE the update of Pytorch-transformers, the model()would produce the result after the forward pass of the network; AFTER the update, the forward method of the model produces a tuple with its first element being the original model output. If you want more details, please [read here](https://github.com/huggingface/pytorch-transformers#models-always-output-tuples).\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "# If you used to have this line in pytorch-pretrained-bert:\n",
        "loss = model(input_ids, labels=labels)\n",
        "# Now just use this line in pytorch-transformers to extract the loss from the output tuple:\n",
        "outputs = model(input_ids, labels=labels)\n",
        "loss = outputs[0]\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X9FGKRi22L4Z",
        "colab_type": "text"
      },
      "source": [
        "#### Solution\n",
        "\n",
        "The solution is that we need to change the code from Fastai to accommodate the change of the model() behavior in Pytorch-transformers.\n",
        "And that key section of code is the loss_batch() in basic_train.py and we can see the model() output is not a tuple and is directly sent to the loss function.\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "def loss_batch(model:nn.Module, xb:Tensor, yb:Tensor, loss_func:OptLossFunc=None, opt:OptOptimizer=None,\n",
        "cb_handler:Optional[CallbackHandler]=None)->Tuple[Union[Tensor,int,float,str]]:\n",
        "    \"Calculate loss and metrics for a batch, call out to callbacks as necessary.\"\n",
        "    cb_handler = ifnone(cb_handler, CallbackHandler())\n",
        "    if not is_listy(xb): xb = [xb]\n",
        "    if not is_listy(yb): yb = [yb]\n",
        "    out = model(*xb) # Here the output is NOT a tuple\n",
        "    out = cb_handler.on_loss_begin(out)\n",
        "if not loss_func: return to_detach(out), yb[0].detach()\n",
        "         loss = loss_func(out, *yb)\n",
        "if opt is not None:\n",
        "        loss,skip_bwd = cb_handler.on_backward_begin(loss)\n",
        "        if not skip_bwd:                     loss.backward()\n",
        "        if not cb_handler.on_backward_end(): opt.step()\n",
        "        if not cb_handler.on_step_end():     opt.zero_grad()\n",
        "return loss.detach().cpu()\n",
        "```\n",
        "Once we find out the exact place in the library, the change is like a breeze: **simply select the first element in the model()** output like below and offer the function a new name:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZNIHaPjH2LBt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def loss_batch_bert(model:nn.Module, xb:Tensor, yb:Tensor, loss_func:OptLossFunc=None, opt:OptOptimizer=None,\n",
        "               cb_handler:Optional[CallbackHandler]=None)->Tuple[Union[Tensor,int,float,str]]:\n",
        "    \"Calculate loss and metrics for a batch, call out to callbacks as necessary.\"\n",
        "    cb_handler = ifnone(cb_handler, CallbackHandler())\n",
        "    if not is_listy(xb): xb = [xb]\n",
        "    if not is_listy(yb): yb = [yb]\n",
        "    out = model(*xb)\n",
        "    #pdb.set_trace()\n",
        "    out = out[0]\n",
        "    out = cb_handler.on_loss_begin(out)\n",
        "\n",
        "    if not loss_func: return to_detach(out), yb[0].detach()\n",
        "    loss = loss_func(out, *yb)\n",
        "\n",
        "    if opt is not None:\n",
        "        loss,skip_bwd = cb_handler.on_backward_begin(loss)\n",
        "        if not skip_bwd:                     loss.backward()\n",
        "        if not cb_handler.on_backward_end(): opt.step()\n",
        "        if not cb_handler.on_step_end():     opt.zero_grad()\n",
        "\n",
        "    return loss.detach().cpu()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JKT-oVqL5KR6",
        "colab_type": "text"
      },
      "source": [
        "Now that we have a new loss_batch_bert() function, we need it to replace the original loss_batch() in Fastai that is loaded in our environment. We could do this by:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7vQEAjWZ5LG3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# To change the loss_batch function in the loaded fastai module\n",
        "module_basic_train = sys.modules['fastai.basic_train']\n",
        "module_basic_train.loss_batch = loss_batch_bert\n",
        "sys.modules['fastai.basic_train'] = module_basic_train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ne5VfHrN5uDc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learner = Learner(\n",
        "    databunch, bert_model,\n",
        "    loss_func=loss_func, metrics = acc\n",
        ").to_fp16()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VRl9xhKv0pz2",
        "colab_type": "code",
        "outputId": "f9025d8d-2d8a-4cf2-8f07-e9cc16eda5c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        }
      },
      "source": [
        "learner.lr_find()\n",
        "learner.recorder.plot()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEKCAYAAADjDHn2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nxhgT0P8HTg6nyH/kvCcAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o_fdYUWNoxho",
        "colab_type": "code",
        "outputId": "26ad0714-73f3-4785-d926-0f08aedd0d66",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        }
      },
      "source": [
        "learner.fit_one_cycle(1, max_lr= 1e-04, moms=(0.8,0.7))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='1' class='' max='7', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      14.29% [1/7 2:53:27<17:20:45]\n",
              "    </div>\n",
              "    \n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy_thresh</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.049062</td>\n",
              "      <td>0.051294</td>\n",
              "      <td>0.968981</td>\n",
              "      <td>2:53:27</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>\n",
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='718' class='' max='14959', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      4.80% [718/14959 06:41<2:12:37 0.0569]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Buffered data was truncated after reaching the output size limit."
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GSPhZ0kTzrSJ",
        "colab_type": "text"
      },
      "source": [
        "## Predictions\n",
        "Now to generate predictions. This is where you can get tripped up because the databunch does not load data in sorted order. So we'll have to do reorder the generated predictions to match their original order."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JzvmVSGxISBO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_preds_as_nparray(ds_type) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    the get_preds method does not yield the elements in order by default\n",
        "    we borrow the code from the RNNLearner to resort the elements into their correct order\n",
        "    \"\"\"\n",
        "    preds = learner.get_preds(ds_type)[0].detach().cpu().numpy()\n",
        "    sampler = [i for i in databunch.dl(ds_type).sampler]\n",
        "    reverse_sampler = np.argsort(sampler)\n",
        "    return preds[reverse_sampler, :]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mQoHddeGz0_n",
        "colab_type": "code",
        "outputId": "404462e8-0b4b-4799-d956-78a3df234b8c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "test_preds = get_preds_as_nparray(DatasetType.Test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-fb0f12f6c183>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_preds_as_nparray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDatasetType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-28-b593d9de5d6e>\u001b[0m in \u001b[0;36mget_preds_as_nparray\u001b[0;34m(ds_type)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mwe\u001b[0m \u001b[0mborrow\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mcode\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mRNNLearner\u001b[0m \u001b[0mto\u001b[0m \u001b[0mresort\u001b[0m \u001b[0mthe\u001b[0m \u001b[0melements\u001b[0m \u001b[0minto\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mcorrect\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \"\"\"\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlearner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_preds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0msampler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdatabunch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msampler\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mreverse_sampler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msampler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mget_preds\u001b[0;34m(self, ds_type, activ, with_loss, n_batch, pbar)\u001b[0m\n\u001b[1;32m    343\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcb_fns_registered\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m         return get_preds(self.model, self.dl(ds_type), cb_handler=CallbackHandler(self.callbacks),\n\u001b[0;32m--> 345\u001b[0;31m                          activ=activ, loss_func=lf, n_batch=n_batch, pbar=pbar)\n\u001b[0m\u001b[1;32m    346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpred_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mds_type\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mDatasetType\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDatasetType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mValid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mTuple\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreconstruct\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwith_dropout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mget_preds\u001b[0;34m(model, dl, pbar, cb_handler, activ, loss_func, n_batch)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;34m\"Tuple of predictions and targets, and optional losses (if `loss_func`) using `dl`, max batches `n_batch`.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     res = [torch.cat(o).cpu() for o in\n\u001b[0;32m---> 44\u001b[0;31m            zip(*validate(model, dl, cb_handler=cb_handler, pbar=pbar, average=False, n_batch=n_batch))]\n\u001b[0m\u001b[1;32m     45\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mloss_func\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mNoneReduceOnCPU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_func\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mlf\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mvalidate\u001b[0;34m(model, dl, loss_func, cb_handler, pbar, average, n_batch)\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprogress_bar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpbar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleave\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpbar\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m             \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb_handler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m             \u001b[0mval_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_listy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0myb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-23-9db3a9ae305c>\u001b[0m in \u001b[0;36mloss_batch_bert\u001b[0;34m(model, xb, yb, loss_func, opt, cb_handler)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_listy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mxb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_listy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0myb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;31m#pdb.set_trace()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pytorch_transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, token_type_ids, attention_mask, labels, position_ids, head_mask)\u001b[0m\n\u001b[1;32m    961\u001b[0m                 position_ids=None, head_mask=None):\n\u001b[1;32m    962\u001b[0m         outputs = self.bert(input_ids, position_ids=position_ids, token_type_ids=token_type_ids,\n\u001b[0;32m--> 963\u001b[0;31m                             attention_mask=attention_mask, head_mask=head_mask)\n\u001b[0m\u001b[1;32m    964\u001b[0m         \u001b[0mpooled_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    965\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pytorch_transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, token_type_ids, attention_mask, position_ids, head_mask)\u001b[0m\n\u001b[1;32m    708\u001b[0m         encoder_outputs = self.encoder(embedding_output,\n\u001b[1;32m    709\u001b[0m                                        \u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 710\u001b[0;31m                                        head_mask=head_mask)\n\u001b[0m\u001b[1;32m    711\u001b[0m         \u001b[0msequence_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    712\u001b[0m         \u001b[0mpooled_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpooler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pytorch_transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask)\u001b[0m\n\u001b[1;32m    429\u001b[0m                 \u001b[0mall_hidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_hidden_states\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 431\u001b[0;31m             \u001b[0mlayer_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    432\u001b[0m             \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pytorch_transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask)\u001b[0m\n\u001b[1;32m    407\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 409\u001b[0;31m         \u001b[0mattention_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    410\u001b[0m         \u001b[0mattention_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattention_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m         \u001b[0mintermediate_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pytorch_transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_tensor, attention_mask, head_mask)\u001b[0m\n\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 366\u001b[0;31m         \u001b[0mself_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    367\u001b[0m         \u001b[0mattention_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mattention_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# add attentions if we output them\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pytorch_transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask)\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0mmixed_query_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0mmixed_key_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m         \u001b[0mmixed_value_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    289\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m         \u001b[0mquery_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose_for_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmixed_query_layer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1369\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1370\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1371\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1372\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1373\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sdkdX-MZ0Msr",
        "colab_type": "code",
        "outputId": "9b87a3de-2b2a-4521-c08a-c888051e04ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "learner.predict(\"I have indefinitely blocked this account\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(MultiCategory ,\n",
              " tensor([0., 0., 0., 0., 0., 0.]),\n",
              " tensor([0.0038, 0.0002, 0.0008, 0.0002, 0.0008, 0.0002]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9dq2mwma2mF5",
        "colab_type": "code",
        "outputId": "efe4d0d8-9978-493b-c9c1-d87c545f77a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "test['comment_text'][20]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'==Indefinitely blocked== \\n I have indefinitely blocked this account.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jHRsOw6822s_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}