{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FastAi-Transformers: Chinese sentiment analysis.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hduongck/AI-ML-Learning/blob/master/Huggingface/FastAi_Transformers_Chinese_sentiment_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KWilcc58y8F5",
        "colab_type": "code",
        "outputId": "db4b4721-b9f0-40b6-e5c5-9fc6b25ac31c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (2.0.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.8.19)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.16.5)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.83)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.35)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from transformers) (4.28.1)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.9.236)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.13.2)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.4)\n",
            "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.2.1)\n",
            "Requirement already satisfied: botocore<1.13.0,>=1.12.236 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.12.236)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2019.9.11)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.236->boto3->transformers) (0.15.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.236->boto3->transformers) (2.5.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mGDCErwE_Rlh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from fastai.text import *\n",
        "\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "import jieba\n",
        "import codecs\n",
        "#from langconv import * # convert Traditional Chinese characters to Simplified Chinese characters\n",
        "import pickle\n",
        "import random"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RSwhVKzQCi3q",
        "colab_type": "text"
      },
      "source": [
        "## Processing data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "69T4VtEczOTp",
        "colab_type": "code",
        "outputId": "86a1ba41-ddd7-4d43-e262-d9b01e580dc7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!git clone https://github.com/Tony607/Chinese_sentiment_analysis.git"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'Chinese_sentiment_analysis' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VGr_Mvs-zkdB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataBaseDirPos = \"/content/Chinese_sentiment_analysis/data/ChnSentiCorp_htl_ba_6000/pos/\"\n",
        "dataBaseDirNeg = \"/content/Chinese_sentiment_analysis/data/ChnSentiCorp_htl_ba_6000/neg/\"\n",
        "positiveFiles = [dataBaseDirPos + f for f in listdir(dataBaseDirPos) if isfile(join(dataBaseDirPos, f))]\n",
        "negativeFiles = [dataBaseDirNeg + f for f in listdir(dataBaseDirNeg) if isfile(join(dataBaseDirNeg, f))]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1dRHM_B6E3Gm",
        "colab_type": "code",
        "outputId": "93a0d4e7-0b19-49a2-d016-f723891ef3d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%cd /content/Chinese_sentiment_analysis/data/"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/Chinese_sentiment_analysis/data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tDq9R-ztAnYc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%load /content/Chinese_sentiment_analysis/zh_wiki.py\n",
        "%loadpy /content/Chinese_sentiment_analysis/langconv.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VRbMvJ5Dce0o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#from langconv import *"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PjyFW9C4A915",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "documents = []\n",
        "for filename in positiveFiles:\n",
        "    text = \"\"\n",
        "    with codecs.open(filename, \"rb\") as doc_file:\n",
        "        for line in doc_file:\n",
        "            try:\n",
        "                line = line.decode(\"GB2312\")\n",
        "            except:\n",
        "                continue\n",
        "            #text+=Converter('zh-hans').convert(line)# Convert from traditional to simplified Chinese\n",
        "            text += line\n",
        "            text = text.replace(\"\\n\", \"\")\n",
        "            text = text.replace(\"\\r\", \"\")\n",
        "    documents.append((text, \"pos\"))\n",
        "\n",
        "for filename in negativeFiles:\n",
        "    text = \"\"\n",
        "    with codecs.open(filename, \"rb\") as doc_file:\n",
        "        for line in doc_file:\n",
        "            try:\n",
        "                line = line.decode(\"GB2312\")\n",
        "            except:\n",
        "                continue\n",
        "            #text+=Converter('zh-hans').convert(line)# Convert from traditional to simplified Chinese\n",
        "            text += line\n",
        "            text = text.replace(\"\\n\", \"\")\n",
        "            text = text.replace(\"\\r\", \"\")\n",
        "    documents.append((text, \"neg\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iCIcwbUVCDjR",
        "colab_type": "code",
        "outputId": "fd11f3d9-4db6-4bf9-efca-32d6125113d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "df = pd.DataFrame(documents,columns=['review','labels'])\n",
        "df.head()"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>我是1月20日入住的。。订的大床房。位于西环的中远，很明显有内地装修的风格。。哈哈。比如电视...</td>\n",
              "      <td>pos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>因为离同学家近，这次就住了海逸。交通比较便利出门5分钟就能到码头，可以坐轮渡到湾仔，价格非常...</td>\n",
              "      <td>pos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>很好．非常干净．是新装修的．服务不错．早餐也很好．对了，被子很厚但非常松软．哈哈满意</td>\n",
              "      <td>pos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>饭店有些旧但房间干净,住高层向北房间安静,假如下次再去大同会再住.</td>\n",
              "      <td>pos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>坐落在香港的老城区，可以体验香港居民生活，门口交通很方便，如果时间不紧，坐叮当车很好呀！周围...</td>\n",
              "      <td>pos</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              review labels\n",
              "0  我是1月20日入住的。。订的大床房。位于西环的中远，很明显有内地装修的风格。。哈哈。比如电视...    pos\n",
              "1  因为离同学家近，这次就住了海逸。交通比较便利出门5分钟就能到码头，可以坐轮渡到湾仔，价格非常...    pos\n",
              "2         很好．非常干净．是新装修的．服务不错．早餐也很好．对了，被子很厚但非常松软．哈哈满意    pos\n",
              "3                  饭店有些旧但房间干净,住高层向北房间安静,假如下次再去大同会再住.    pos\n",
              "4  坐落在香港的老城区，可以体验香港居民生活，门口交通很方便，如果时间不紧，坐叮当车很好呀！周围...    pos"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eL7-rQjLBw_9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.to_excel(\"/content/chinese_hotel_reviews.xls\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6sYFI4qqCoRh",
        "colab_type": "text"
      },
      "source": [
        "## Create Language Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pbIwqL1vfvxB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import *"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SyVRwoG9gR17",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Config(dict):\n",
        "    def __init__(self, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        for k, v in kwargs.items():\n",
        "            setattr(self, k, v)\n",
        "    \n",
        "    def set(self, key, val):\n",
        "        self[key] = val\n",
        "        setattr(self, key, val)\n",
        "\n",
        "config = Config(\n",
        "    bert_model_name=\"bert-base-chinese\",\n",
        "    max_lr=3e-5,\n",
        "    epochs=1,\n",
        "    use_fp16= True,\n",
        "    bs= 64,\n",
        "    discriminative=False,\n",
        "    max_seq_len=128,\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z_ozuBud8-Y4",
        "colab_type": "text"
      },
      "source": [
        "### Import BertTokenizer/vocab to Fastai tokenizer/vocab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Se_z2ZAeg4wN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bert_tok = BertTokenizer.from_pretrained(\n",
        "    config.bert_model_name,\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W5TXmgSTg9tV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class FastAiBertTokenizer(BaseTokenizer):\n",
        "    \"\"\"Wrapper around BertTokenizer to be compatible with fast.ai\"\"\"\n",
        "    def __init__(self, tokenizer: BertTokenizer, max_seq_len: int=128, **kwargs):\n",
        "        self._pretrained_tokenizer = tokenizer\n",
        "        self.max_seq_len = max_seq_len\n",
        "\n",
        "    def __call__(self, *args, **kwargs):\n",
        "        return self\n",
        "\n",
        "    def tokenizer(self, t:str) -> List[str]:\n",
        "        \"\"\"Limits the maximum sequence length\"\"\"\n",
        "        return [\"[CLS]\"] + self._pretrained_tokenizer.tokenize(t)[:self.max_seq_len - 2] + [\"[SEP]\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QBNjY3DmC_jE",
        "colab_type": "text"
      },
      "source": [
        "**Tokenizer**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rPStxykBhA2y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fastai_tokenizer = Tokenizer(tok_func=FastAiBertTokenizer(bert_tok, max_seq_len=config.max_seq_len), pre_rules=[], post_rules=[])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rR79hUtQCyEl",
        "colab_type": "text"
      },
      "source": [
        "**Create vocabulary**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "laBRH2x_hC-T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fastai_bert_vocab =Vocab(list(bert_tok.vocab.keys()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NwVM8PjYDFcQ",
        "colab_type": "text"
      },
      "source": [
        "### Create Databunch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VaW1aorwhL87",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train,val = train_test_split(df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CJVVbdmNh2lH",
        "colab_type": "code",
        "outputId": "78c21870-e6c9-4c48-8662-2695289358e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "train.head()"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>297</th>\n",
              "      <td>交通很方便，从罗湖火车站直接可以坐地铁去，在世界之窗站下一出站就是了。房间很干净，阳台也比较...</td>\n",
              "      <td>pos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2674</th>\n",
              "      <td>开始看了2005年的几位朋友的评价，都不敢去入住。没想到现在改观了很多，房间虽小，但很整洁。...</td>\n",
              "      <td>pos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5331</th>\n",
              "      <td>The position of this hotel is very bad.补充点评 20...</td>\n",
              "      <td>neg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2143</th>\n",
              "      <td>通过携程预订，入住3天，感觉价格和房间差距较大，房间陈旧、卫生间较小、特别是电视机那叫一个破...</td>\n",
              "      <td>pos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2511</th>\n",
              "      <td>酒店周边环境一般，酒店内设施不错，感觉还挺新，价格也尚可接受。</td>\n",
              "      <td>pos</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 review labels\n",
              "297   交通很方便，从罗湖火车站直接可以坐地铁去，在世界之窗站下一出站就是了。房间很干净，阳台也比较...    pos\n",
              "2674  开始看了2005年的几位朋友的评价，都不敢去入住。没想到现在改观了很多，房间虽小，但很整洁。...    pos\n",
              "5331  The position of this hotel is very bad.补充点评 20...    neg\n",
              "2143  通过携程预订，入住3天，感觉价格和房间差距较大，房间陈旧、卫生间较小、特别是电视机那叫一个破...    pos\n",
              "2511                    酒店周边环境一般，酒店内设施不错，感觉还挺新，价格也尚可接受。    pos"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jHsdiRglhS9b",
        "colab_type": "code",
        "outputId": "64d46678-1ab5-4f6a-9cdb-cf82966e66e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        }
      },
      "source": [
        "\n",
        "databunch = TextDataBunch.from_df(\".\", train, val,\n",
        "                  tokenizer=fastai_tokenizer,\n",
        "                  vocab=fastai_bert_vocab,\n",
        "                  include_bos=False,\n",
        "                  include_eos=False,\n",
        "                  text_cols=\"review\",\n",
        "                  label_cols=\"labels\",\n",
        "                  bs=config.bs,\n",
        "                  collate_fn=partial(pad_collate, pad_first=False, pad_idx=0),\n",
        "             )\n",
        "databunch"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TextClasDataBunch;\n",
              "\n",
              "Train: LabelList (4437 items)\n",
              "x: TextList\n",
              "[CLS] 交 通 很 方 便 ， 从 罗 湖 火 车 站 直 接 可 以 坐 地 铁 去 ， 在 世 界 之 窗 站 下 一 出 站 就 是 了 。 房 间 很 干 净 ， 阳 台 也 比 较 大 。 最 喜 欢 就 是 里 面 的 游 泳 池 ， 很 有 威 尼 斯 的 特 色 ， 小 朋 友 去 就 很 喜 欢 了 。 check in 和 check out 的 时 候 有 很 新 鲜 的 苹 果 吃 ， 呵 呵 ， 感 觉 很 舒 服 ！ [SEP],[CLS] 开 始 看 了 2005 年 的 几 位 朋 友 的 评 价 ， 都 不 敢 去 入 住 。 没 想 到 现 在 改 观 了 很 多 ， 房 间 虽 小 ， 但 很 整 洁 。 下 次 再 来 的 话 ， 还 会 选 择 这 个 酒 店 。 只 是 希 望 宽 带 能 一 直 免 费 ！ [SEP],[CLS] [UNK] pos ##ition of this hotel is very bad . 补 充 点 评 2008 年 4 月 6 日 ： 1 。 没 有 暖 气 2 。 有 人 评 论 [UNK] 房 间 有 窗 打 不 开 ， 窗 户 有 玻 璃 不 透 明 ， 房 间 显 得 非 常 闷 [UNK] ， 试 过 打 开 窗 户 ， 看 到 很 多 坟 墓 [SEP],[CLS] 通 过 携 程 预 订 ， 入 住 3 天 ， 感 觉 价 格 和 房 间 差 距 较 大 ， 房 间 陈 旧 、 卫 生 间 较 小 、 特 别 是 电 视 机 那 叫 一 个 破 哦 ， 估 计 成 都 的 招 待 所 都 没 有 这 样 的 电 视 机 了 。 早 餐 不 错 ， 服 务 没 有 体 会 到 。 房 间 价 格 在 158 元 / 间 应 该 差 不 多 了 。 [SEP],[CLS] 酒 店 周 边 环 境 一 般 ， 酒 店 内 设 施 不 错 ， 感 觉 还 挺 新 ， 价 格 也 尚 可 接 受 。 [SEP]\n",
              "y: CategoryList\n",
              "pos,pos,neg,pos,pos\n",
              "Path: .;\n",
              "\n",
              "Valid: LabelList (1479 items)\n",
              "x: TextList\n",
              "[CLS] 该 酒 店 虽 然 价 格 不 高 , 但 服 务 实 在 太 差 , 房 间 例 行 送 的 水 果 和 报 纸 要 打 电 话 问 才 送 过 来 , 早 餐 结 束 的 时 间 被 提 前 到 9 点 也 没 有 任 何 通 知 , 最 可 气 的 是 我 投 诉 没 早 餐 时 , 前 台 还 不 肯 承 认 错 误 , 骗 我 早 餐 在 我 下 楼 之 前 刚 结 束 , 是 我 自 己 下 楼 晚 了 . 这 种 服 务 的 四 星 级 酒 店 我 还 从 来 没 住 过 . [SEP],[CLS] 一 般 设 施 不 错 ， 其 他 一 般 早 餐 也 不 错 [SEP],[CLS] 房 间 设 备 太 破 , 连 喷 头 都 是 不 好 用 , 空 调 几 乎 感 觉 不 到 , 虽 然 我 开 了 最 大 另 外 就 是 设 备 维 修 不 及 时 , 洗 澡 用 品 感 觉 都 是 廉 价 货 , 味 道 很 奇 怪 的 洗 头 液 等 等 . . . 总 体 感 觉 服 务 还 可 以 , 设 备 招 待 所 水 平 . . . [SEP],[CLS] 该 酒 店 在 大 角 湾 景 区 内 的 顶 角 的 位 置 （ 南 方 假 日 酒 店 则 在 角 的 另 一 端 ） ， 对 于 没 车 的 来 说 就 很 不 方 便 了 （ 出 租 、 摩 的 非 常 少 ） ， 远 离 市 区 ， 购 物 、 娱 乐 都 不 方 便 ， 设 施 一 般 、 没 早 餐 ， 服 务 态 度 一 般 ， 不 伦 是 旅 游 还 是 办 事 都 不 是 好 的 选 择 ， 要 是 图 安 静 的 倒 是 比 较 适 合 ， 还 有 就 是 淡 季 不 来 就 [SEP],[CLS] 房 间 设 备 不 是 很 好 ， 不 过 走 的 路 线 不 一 样 ， 设 备 不 好 是 正 常 的 。 干 净 ， 让 人 觉 得 安 心 才 是 目 标 ， 如 家 做 得 不 错 。 只 是 有 一 点 ， 房 间 虽 然 整 理 得 很 干 净 ， 但 是 天 气 热 了 ， 可 能 要 彻 底 消 毒 一 下 ， 第 一 天 入 住 的 时 候 在 房 间 看 到 小 强 了 。 火 车 站 出 来 大 概 走 5 分 钟 就 到 ， 交 通 不 错 ， 打 车 或 者 到 火 车 [SEP]\n",
              "y: CategoryList\n",
              "neg,pos,pos,neg,neg\n",
              "Path: .;\n",
              "\n",
              "Test: None"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6jAYSCpKDKrk",
        "colab_type": "text"
      },
      "source": [
        "### Run model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zSC2Ngebihzl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bert_model = BertForSequenceClassification.from_pretrained(config.bert_model_name, num_labels=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K3NWLuchi3-r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss_func = nn.CrossEntropyLoss()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "skpmA8VIjAJ6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def loss_batch_bert(model:nn.Module, xb:Tensor, yb:Tensor, loss_func:OptLossFunc=None, opt:OptOptimizer=None,\n",
        "               cb_handler:Optional[CallbackHandler]=None)->Tuple[Union[Tensor,int,float,str]]:\n",
        "    \"Calculate loss and metrics for a batch, call out to callbacks as necessary.\"\n",
        "    cb_handler = ifnone(cb_handler, CallbackHandler())\n",
        "    if not is_listy(xb): xb = [xb]\n",
        "    if not is_listy(yb): yb = [yb]\n",
        "    out = model(*xb)\n",
        "    #pdb.set_trace()\n",
        "    out = out[0]\n",
        "    out = cb_handler.on_loss_begin(out)\n",
        "\n",
        "    if not loss_func: return to_detach(out), yb[0].detach()\n",
        "    loss = loss_func(out, *yb)\n",
        "\n",
        "    if opt is not None:\n",
        "        loss,skip_bwd = cb_handler.on_backward_begin(loss)\n",
        "        if not skip_bwd:                     loss.backward()\n",
        "        if not cb_handler.on_backward_end(): opt.step()\n",
        "        if not cb_handler.on_step_end():     opt.zero_grad()\n",
        "\n",
        "    return loss.detach().cpu()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a9nZbjVXjEyM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "module_basic_train = sys.modules['fastai.basic_train']\n",
        "module_basic_train.loss_batch = loss_batch_bert\n",
        "sys.modules['fastai.basic_train'] = module_basic_train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V2wTSnGujINR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learner = Learner(\n",
        "    databunch, bert_model,\n",
        "    loss_func=loss_func, metrics = accuracy\n",
        ").to_fp16()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jT41gdS6jPG8",
        "colab_type": "code",
        "outputId": "de6a5b96-f71e-4897-99ac-e4e6164d69d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        }
      },
      "source": [
        "learner.lr_find()\n",
        "learner.recorder.plot()"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEKCAYAAADjDHn2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nuxqz+mmjAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WJgdFfOomq25",
        "colab_type": "code",
        "outputId": "9e86d40b-8872-4fdb-aa57-8e75a3936479",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "learner.fit_one_cycle(1, max_lr= 1e-04, moms=(0.8,0.7))"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.362582</td>\n",
              "      <td>0.304076</td>\n",
              "      <td>0.874915</td>\n",
              "      <td>05:28</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J2dkjm74m3QP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "75b77bb2-de38-4973-a01f-ed9522dddd32"
      },
      "source": [
        "learner.fit_one_cycle(5, max_lr= 1e-04, moms=(0.8,0.7))"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.245634</td>\n",
              "      <td>0.543296</td>\n",
              "      <td>0.843137</td>\n",
              "      <td>05:12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.245596</td>\n",
              "      <td>0.276064</td>\n",
              "      <td>0.888438</td>\n",
              "      <td>05:18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.193739</td>\n",
              "      <td>0.260084</td>\n",
              "      <td>0.910751</td>\n",
              "      <td>05:47</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.110787</td>\n",
              "      <td>0.262645</td>\n",
              "      <td>0.918864</td>\n",
              "      <td>06:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.066633</td>\n",
              "      <td>0.300045</td>\n",
              "      <td>0.913455</td>\n",
              "      <td>05:17</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NOhsovg8VI2Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401
        },
        "outputId": "4df7624f-e4e8-4db0-ee04-f32a859b454a"
      },
      "source": [
        "learner.freeze_to(-2)\n",
        "learner.fit_one_cycle(5, max_lr= 1e-04, moms=(0.8,0.7))"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='0' class='' max='5', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      0.00% [0/5 00:00<00:00]\n",
              "    </div>\n",
              "    \n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>\n",
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='0' class='progress-bar-interrupted' max='69', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      Interrupted\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-113-23a28d87dc3e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mlearner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfreeze_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlearner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_one_cycle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_lr\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m1e-04\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmoms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastai/train.py\u001b[0m in \u001b[0;36mfit_one_cycle\u001b[0;34m(learn, cyc_len, max_lr, moms, div_factor, pct_start, final_div, wd, callbacks, tot_epochs, start_epoch)\u001b[0m\n\u001b[1;32m     20\u001b[0m     callbacks.append(OneCycleScheduler(learn, max_lr, moms=moms, div_factor=div_factor, pct_start=pct_start,\n\u001b[1;32m     21\u001b[0m                                        final_div=final_div, tot_epochs=tot_epochs, start_epoch=start_epoch))\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcyc_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mlr_find\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mLearner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_lr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_lr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_it\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop_div\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, epochs, lr, wd, callbacks)\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_fns\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlistify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefaults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextra_callback_fns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlistify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcb_fns_registered\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m         \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcreate_opt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m->\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(epochs, learn, callbacks, metrics)\u001b[0m\n\u001b[1;32m     99\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprogress_bar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpbar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-107-9db3a9ae305c>\u001b[0m in \u001b[0;36mloss_batch_bert\u001b[0;34m(model, xb, yb, loss_func, opt, cb_handler)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_listy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mxb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_listy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0myb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;31m#pdb.set_trace()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, labels)\u001b[0m\n\u001b[1;32m    893\u001b[0m                             \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m                             \u001b[0mposition_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mposition_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m                             head_mask=head_mask)\n\u001b[0m\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mpooled_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask)\u001b[0m\n\u001b[1;32m    623\u001b[0m         encoder_outputs = self.encoder(embedding_output,\n\u001b[1;32m    624\u001b[0m                                        \u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m                                        head_mask=head_mask)\n\u001b[0m\u001b[1;32m    626\u001b[0m         \u001b[0msequence_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m         \u001b[0mpooled_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpooler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask)\u001b[0m\n\u001b[1;32m    344\u001b[0m                 \u001b[0mall_hidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_hidden_states\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m             \u001b[0mlayer_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m             \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask)\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[0mattention_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m         \u001b[0mattention_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattention_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m         \u001b[0mintermediate_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    327\u001b[0m         \u001b[0mlayer_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintermediate_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlayer_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mattention_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# add attentions if we output them\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    296\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 298\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate_act_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    299\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mgelu\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0mAlso\u001b[0m \u001b[0msee\u001b[0m \u001b[0mhttps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0marxiv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morg\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m1606.08415\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m     \"\"\"\n\u001b[0;32m--> 126\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m0.5\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1.0\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgelu_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 48.00 MiB (GPU 0; 11.17 GiB total capacity; 10.69 GiB already allocated; 35.69 MiB free; 119.60 MiB cached)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TI7NMbt0BcEl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learner.export(file='chinese_hotel_reviews_classification.pkl')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kOocygM_qSRg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f8e98697-6fc7-4df9-beaa-f5c8110f4413"
      },
      "source": [
        "learner.predict('臨時預定的房間,但房東都很快速且親切的回應!!房間的設備很不錯,乾淨又舒適｡附近居民相當熱心且熱情的與我們打招呼~ 只是可能因為位在一樓,早上隔音稍嫌不足~')"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Category pos, tensor(1), tensor([5.2032e-04, 9.9948e-01]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UAn0F3n4rzlk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "34dd15c1-5162-4762-b364-b7747aa0af64"
      },
      "source": [
        "learner.predict('超级推荐的民宿,特别法式的感觉｡')"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Category pos, tensor(1), tensor([5.7143e-04, 9.9943e-01]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uLqQ4jDrr_nt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ccc04c5e-a75d-496c-ec2b-357705890392"
      },
      "source": [
        "learner.predict('典型的国营酒店，管理层缺乏责任心，管理混乱。房间里的大灯镜灯台灯都是坏的，只有一盏床头灯可用')"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Category neg, tensor(0), tensor([0.9959, 0.0041]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZU81HDK3sbg3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5a1e9e87-3bd6-4c79-d0b7-877fb4aae3e3"
      },
      "source": [
        "learner.predict('房间太旧了,价格上也不实惠,不过在信阳这样的城市估计也没有什么好酒店,也只能将就了!')"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Category neg, tensor(0), tensor([0.9960, 0.0040]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P2eKcPzQVBPL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1c147f6e-35aa-4c9b-c003-796f443093a5"
      },
      "source": [
        "learner.predict('除了位置有点难找确实是很棒的房子!')"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Category pos, tensor(1), tensor([5.7591e-04, 9.9942e-01]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H-kuDwWh_ga2",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    }
  ]
}