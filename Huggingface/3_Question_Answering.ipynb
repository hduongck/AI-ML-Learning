{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3_Question Answering.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hduongck/AI-ML-Learning/blob/master/Huggingface/3_Question_Answering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Mn5MA1k7hXD",
        "colab_type": "text"
      },
      "source": [
        "https://rsilveira79.github.io/fermenting_gradients/machine_learning/nlp/pytorch/pytorch-transformer-squad/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "couMUgaN_VPG",
        "colab_type": "text"
      },
      "source": [
        "# Step-by-step guide to finetune and use question and answering models with pytorch-transformers\n",
        "\n",
        "I have used question and answering systems for some time now, and I’m really impressed how these algorithms evolved recently. My first interaction with QA algorithms was with the BiDAF model (Bidirectional Attention Flow) 1 from the great AllenNLP team. It was back in 2017, and ELMo embeddings 2 were not even used in this BiDAF model (I believe they were using GLove vectors in this first model). Since then, a lot of stuff is happened in the NLP arena, such as the Transformer 3, BERT 4 and the many other members of the Sesame Street family (now there are a whole BERT-like-family such as Facebook RoBERTa 4, VilBERT and maybe(why not?) one day, DilBERT).\n",
        "\n",
        "There are lots of great materias out there (see Probe Further section for more details), so it will be much easier to go on and watch these awesome video materials instead of detailing each model in a blog post.\n",
        "\n",
        "**I would really want to spend time in the practical usage of question and answering models, as they can be very helpful for real-life applications (besides some challenges that will be addressed in other posts - such as model size, response time, model quantization/pruning, etc).**\n",
        "\n",
        "In this regard, all the ML community should give a massive shout-out to Hugging Face team. They are really pushing the limits to make the latest and greatest algorithms available for the broader community, and it is really cool to see how their project is growing rapidly in github (at the time I’m writing this they already surpassed more than 10k ⭐️on github for the pytorch-transformer repo, for example). I will focus on SQuAD 1.1 dataset, more details on how fine-tune/use these models with SQuAD 2.0 dataset will be described in further posts."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uhviJcYf_3PB",
        "colab_type": "text"
      },
      "source": [
        "## Inside pytorch-transformers\n",
        "\n",
        "The pytorch-transformers lib has some special classes, and the nice thing is that they try to be consistent with this architecture independently of the model (BERT, XLNet, RoBERTa, etc). These 3 important classes are:\n",
        "\n",
        "- **Config** → this is the class that defines all the configurations of the model in hand, such as number of hidden layers in Transformer, number of attention heads in the Transformer encoder, activation function, dropout rate, etc. Usually, there are 2 default configurations [base, large], but it is possible to tune the configurations to have different models. The file format of the configuration file is a .json file.\n",
        "\n",
        "- **Tokenizer** → the tokenizer class deals with some linguistic details of each model class, as specific tokenization types are used (such as WordPiece for BERT or SentencePiece for XLNet). It also handles begin-of-sentence (bos), end-of-sentence (eod), unknown, separation, padding, mask and any other special tokens. The tokenizer file can be loaded as a .txt file.\n",
        "\n",
        "- **Model** → finally, we need to specify the model class. In this specific case, we are going to use special classes for Question and Answering [BertForQuestionAnswering, XLNetForQuestionAnswering], but there are other classes for different downstream tasks that can be used. These downstream classes inherit [BertModel, XLNetModel] classes, which will then go into more specific details (embedding type, Transformer configuration, etc). The weights of a fine-tuned downstream task mode are stored in a .bin file.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ta1QOAbHAVYR",
        "colab_type": "text"
      },
      "source": [
        "## Download Fine-tuned models\n",
        "\n",
        "[BERT MODEL for SQuAD 1.1](https://drive.google.com/open?id=1OnvT5sKgi0WVWTXnTaaOPTE5KIh-xg_E)\n",
        "\n",
        "[XLNet Model for SQuAD 1.1](https://drive.google.com/open?id=1e7wu9yI-rGkSzjoPU2TpCC9FMvlKvl8R)\n",
        "\n",
        "\n",
        "Watch out! The BERT model I downloaded directly from Hugging Face repo, the XLNet model I fine-tuned myself for 3 epochs in a Nvidia 1080ti. Also, I noticed that the XLNet model maybe needs some more training - see Results section\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PfBlqc2qA9Ut",
        "colab_type": "text"
      },
      "source": [
        "## Finetuning scripts\n",
        "\n",
        "To run the fine-tuning scripts, the Hugging Face team makes available some dataset-specific files that can be found [here](https://github.com/huggingface/pytorch-transformers/tree/master/examples). These fine-tuning scripts can be highly customizable, for example by passing a config file for a model specified in .json file **e.g. --config_name xlnet_m2.json**. The examples below are showing BERT finetuning with base configuration, and xlnet configuration with specific parameters (**n_head,n_layer**). The models provided for download both use the **large** config."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hOcZXF1BBUCm",
        "colab_type": "text"
      },
      "source": [
        "### Finetuning BERT\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "python run_squad.py \\\n",
        "  --model_type bert \\\n",
        "  --model_name_or_path bert-base-cased \\\n",
        "  --do_train \\\n",
        "  --do_eval \\\n",
        "  --evaluate_during_training \\\n",
        "  --do_lower_case \\\n",
        "  --train_file $SQUAD_DIR/train-v1.1.json \\\n",
        "  --predict_file $SQUAD_DIR/dev-v1.1.json \\\n",
        "  --save_steps 10000 \\\n",
        "  --learning_rate 3e-5 \\\n",
        "  --num_train_epochs 5.0 \\\n",
        "  --max_seq_length 384 \\\n",
        "  --doc_stride 128 \\\n",
        "  --output_dir /home/roberto/tmp/finetuned_xlnet \\\n",
        "  --overwrite_output_dir \\\n",
        "  --overwrite_cache\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qa3W9endBbZw",
        "colab_type": "text"
      },
      "source": [
        "### Finetuning XLNet\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "python -u run_squad.py \\\n",
        "  --model_type xlnet \\\n",
        "  --model_name_or_path xlnet-large-cased \\\n",
        "  --do_train \\\n",
        "  --do_eval \\\n",
        "  --config_name xlnet_m2.json \\\n",
        "  --evaluate_during_training \\\n",
        "  --do_lower_case \\\n",
        "  --train_file $SQUAD_DIR/train-v1.1.json \\\n",
        "  --predict_file $SQUAD_DIR/dev-v1.1.json \\\n",
        "  --save_steps 10000 \\\n",
        "  --learning_rate 3e-5 \\\n",
        "  --num_train_epochs 5.0 \\\n",
        "  --max_seq_length 384 \\\n",
        "  --doc_stride 128 \\\n",
        "  --per_gpu_train_batch_size 1 \\\n",
        "  --output_dir /home/roberto/tmp/finetuned_xlnet \\\n",
        "  --overwrite_output_dir \\\n",
        "  --overwrite_cache\n",
        "```\n",
        "\n",
        "**Config xlnet_m2.json**\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "{\n",
        "  \"attn_type\": \"bi\",\n",
        "  \"bi_data\": false,\n",
        "  \"clamp_len\": -1,\n",
        "  \"d_head\": 64,\n",
        "  \"d_inner\": 4096,\n",
        "  \"d_model\": 1024,\n",
        "  \"dropatt\": 0.1,\n",
        "  \"dropout\": 0.1,\n",
        "  \"end_n_top\": 5,\n",
        "  \"ff_activation\": \"gelu\",\n",
        "  \"finetuning_task\": null,\n",
        "  \"init\": \"normal\",\n",
        "  \"init_range\": 0.1,\n",
        "  \"init_std\": 0.02,\n",
        "  \"initializer_range\": 0.02,\n",
        "  \"layer_norm_eps\": 1e-12,\n",
        "  \"max_position_embeddings\": 512,\n",
        "  \"mem_len\": null,\n",
        "  \"n_head\": 16,\n",
        "  \"n_layer\": 18,\n",
        "  \"n_token\": 32000,\n",
        "  \"num_labels\": 2,\n",
        "  \"output_attentions\": false,\n",
        "  \"output_hidden_states\": false,\n",
        "  \"reuse_len\": null,\n",
        "  \"same_length\": false,\n",
        "  \"start_n_top\": 5,\n",
        "  \"summary_activation\": \"tanh\",\n",
        "  \"summary_last_dropout\": 0.1,\n",
        "  \"summary_type\": \"last\",\n",
        "  \"summary_use_proj\": true,\n",
        "  \"torchscript\": false,\n",
        "  \"untie_r\": true\n",
        "}\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IVpxGiYP32yR",
        "colab_type": "text"
      },
      "source": [
        "## Using the trained models\n",
        "\n",
        "Now to the fun part: using these models for question and answering!\n",
        "\n",
        "First things first, let’s import the model classes from pytorch-transformers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GSLJbOFh0IL8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "d9f41d95-fced-4ad8-ef7f-535006aa890c"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ExxhMb_E23Px",
        "colab_type": "code",
        "outputId": "25e26ccd-80b6-4f8d-84c6-900d2832d593",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 700
        }
      },
      "source": [
        "!pip install pytorch-transformers"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pytorch-transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/b7/d3d18008a67e0b968d1ab93ad444fc05699403fa662f634b2f2c318a508b/pytorch_transformers-1.2.0-py3-none-any.whl (176kB)\n",
            "\r\u001b[K     |█▉                              | 10kB 14.6MB/s eta 0:00:01\r\u001b[K     |███▊                            | 20kB 1.7MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 30kB 2.5MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 40kB 1.6MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 51kB 2.0MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 61kB 2.4MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 71kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 81kB 3.2MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 92kB 3.6MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 102kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 112kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 122kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 133kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 143kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 153kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 163kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 174kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 184kB 2.7MB/s \n",
            "\u001b[?25hCollecting regex (from pytorch-transformers)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6f/a6/99eeb5904ab763db87af4bd71d9b1dfdd9792681240657a4c0a599c10a81/regex-2019.08.19.tar.gz (654kB)\n",
            "\u001b[K     |████████████████████████████████| 655kB 44.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (1.1.0)\n",
            "Collecting sacremoses (from pytorch-transformers)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/df/24/0b86f494d3a5c7531f6d0c77d39fd8f9d42e651244505d3d737e31db9a4d/sacremoses-0.0.33.tar.gz (802kB)\n",
            "\u001b[K     |████████████████████████████████| 808kB 40.9MB/s \n",
            "\u001b[?25hCollecting sentencepiece (from pytorch-transformers)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/3d/efb655a670b98f62ec32d66954e1109f403db4d937c50d779a75b9763a29/sentencepiece-0.1.83-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 33.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (4.28.1)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (1.9.224)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (1.16.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (2.21.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->pytorch-transformers) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->pytorch-transformers) (7.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->pytorch-transformers) (0.13.2)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-transformers) (0.9.4)\n",
            "Requirement already satisfied: botocore<1.13.0,>=1.12.224 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-transformers) (1.12.224)\n",
            "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-transformers) (0.2.1)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-transformers) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-transformers) (2019.6.16)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-transformers) (1.24.3)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.224->boto3->pytorch-transformers) (0.15.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.224->boto3->pytorch-transformers) (2.5.3)\n",
            "Building wheels for collected packages: regex, sacremoses\n",
            "  Building wheel for regex (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for regex: filename=regex-2019.8.19-cp36-cp36m-linux_x86_64.whl size=609225 sha256=083ddd6a7b145e6672d3fc9e6af4ed1c442d46eb997d54d21d02d4e3f49ac56b\n",
            "  Stored in directory: /root/.cache/pip/wheels/90/04/07/b5010fb816721eb3d6dd64ed5cc8111ca23f97fdab8619b5be\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.33-cp36-none-any.whl size=833106 sha256=289150d95bd83736174e298eccd931ce05121f9f92d6e1f21b380bccfadf6d96\n",
            "  Stored in directory: /root/.cache/pip/wheels/70/87/56/e40575cca30d12fee8875d523b8878b7aba866a9f03b2fd983\n",
            "Successfully built regex sacremoses\n",
            "Installing collected packages: regex, sacremoses, sentencepiece, pytorch-transformers\n",
            "Successfully installed pytorch-transformers-1.2.0 regex-2019.8.19 sacremoses-0.0.33 sentencepiece-0.1.83\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wmNlH0eU3tRV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import time\n",
        "import torch\n",
        "from pytorch_transformers import BertConfig, BertTokenizer,BertForQuestionAnswering\n",
        "from pytorch_transformers import XLNetConfig, XLNetForQuestionAnswering,XLNetTokenizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0y6HMxDi6ScY",
        "colab_type": "text"
      },
      "source": [
        "These are the 3 important classes:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "app9Bejz4pEf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MODEL_CLASSES = {\n",
        "    'bert': (BertConfig, BertForQuestionAnswering, BertTokenizer),\n",
        "    'xlnet': (XLNetConfig, XLNetForQuestionAnswering, XLNetTokenizer)\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Sehz2rZ6es7",
        "colab_type": "text"
      },
      "source": [
        "I’ve made this special class to handles all the feature preparation and output formating for both BERT and XLNet, but this could be done in different ways:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CKnQRU_R6g__",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class QuestionAnswering(object):\n",
        "    def __init__(self, config_file, weight_file, tokenizer_file, model_type ):\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.config_class, self.model_class, self.tokenizer_class = MODEL_CLASSES[model_type]\n",
        "        self.config = self.config_class.from_json_file(config_file)\n",
        "        self.model = self.model_class(self.config)\n",
        "        self.model.load_state_dict(torch.load(weight_file, map_location=self.device))\n",
        "        self.tokenizer = self.tokenizer_class(tokenizer_file)\n",
        "        self.model_type = model_type\n",
        "    \n",
        "    def to_list(self, tensor):\n",
        "        return tensor.detach().cpu().tolist()\n",
        "\n",
        "    def get_reply(self, question, passage):\n",
        "        self.model.eval()\n",
        "        with torch.no_grad():\n",
        "            input_ids, _ , tokens = self.prepare_features(question, passage)\n",
        "            if self.model_type == 'bert':\n",
        "                span_start,span_end= self.model(input_ids)\n",
        "                answer = tokens[torch.argmax(span_start):torch.argmax(span_end)+1]\n",
        "                answer = self.bert_convert_tokens_to_string(answer)\n",
        "            elif self.model_type == 'xlnet':\n",
        "                input_vector = {'input_ids': input_ids,\n",
        "                                'start_positions': None,\n",
        "                                'end_positions': None }\n",
        "                outputs = self.model(**input_vector)\n",
        "                answer = tokens[self.to_list(outputs[1])[0][torch.argmax(outputs[0])]:self.to_list(outputs[3])[0][torch.argmax(outputs[2])]+1]\n",
        "                answer = self.xlnet_convert_tokens_to_string(answer)\n",
        "        return answer\n",
        "    \n",
        "    def bert_convert_tokens_to_string(self, tokens):\n",
        "        out_string = ' '.join(tokens).replace(' ##', '').strip()\n",
        "        if '@' in tokens:\n",
        "            out_string = out_string.replace(' ', '')\n",
        "        return out_string\n",
        "\n",
        "    def xlnet_convert_tokens_to_string(self, tokens):\n",
        "        out_string = ''.join(tokens).replace('▁', ' ').strip()\n",
        "        return out_string\n",
        "\n",
        "    def prepare_features(self, question,  passage, max_seq_length = 300, \n",
        "                 zero_pad = False, include_CLS_token = True, include_SEP_token = True):\n",
        "        ## Tokenzine Input\n",
        "        tokens_a = self.tokenizer.tokenize(question)\n",
        "        tokens_b = self.tokenizer.tokenize(passage)\n",
        "        ## Truncate\n",
        "        if len(tokens_a) > max_seq_length - 2:\n",
        "            tokens_a = tokens_a[0:(max_seq_length - 2)]\n",
        "        ## Initialize Tokens\n",
        "        tokens = []\n",
        "        if include_CLS_token:\n",
        "            tokens.append(self.tokenizer.cls_token)\n",
        "        ## Add Tokens and separators\n",
        "        for token in tokens_a:\n",
        "            tokens.append(token)\n",
        "        if include_SEP_token:\n",
        "            tokens.append(self.tokenizer.sep_token)\n",
        "        for token in tokens_b:\n",
        "            tokens.append(token)\n",
        "        ## Convert Tokens to IDs\n",
        "        input_ids = self.tokenizer.convert_tokens_to_ids(tokens)\n",
        "        ## Input Mask \n",
        "        input_mask = [1] * len(input_ids)\n",
        "        ## Zero-pad sequence lenght\n",
        "        if zero_pad:\n",
        "            while len(input_ids) < max_seq_length:\n",
        "                input_ids.append(0)\n",
        "                input_mask.append(0)\n",
        "        return torch.tensor(input_ids).unsqueeze(0), input_mask, tokens"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tGu7ndAw6uv_",
        "colab_type": "text"
      },
      "source": [
        "Finally we just need to instantiate these models and start using them!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b8DpVaSq67-c",
        "colab_type": "text"
      },
      "source": [
        "### BERT:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQFSBPLi6ufK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "bert = QuestionAnswering(\n",
        "    config_file =   'bert-large-cased-whole-word-masking-finetuned-squad-config.json',\n",
        "    weight_file=    'bert-large-cased-whole-word-masking-finetuned-squad-pytorch_model.bin',\n",
        "    tokenizer_file= 'bert-large-cased-whole-word-masking-finetuned-squad-vocab.txt',\n",
        "    model_type =    'bert'\n",
        ")\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AeWDTWfN7GXV",
        "colab_type": "text"
      },
      "source": [
        "### XLNet\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ttzDMiV27KIb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xlnet = QuestionAnswering(\n",
        "    config_file =   '/content/drive/My Drive/xlnet-cased-finetuned-squad.json',\n",
        "    weight_file=    '/content/drive/My Drive/xlnet-cased-finetuned-squad.bin',\n",
        "    tokenizer_file= '/content/drive/My Drive/xlnet-large-cased-spiece.txt',\n",
        "    model_type =    'xlnet'\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qPp6pRyVB8k0",
        "colab_type": "text"
      },
      "source": [
        "## Results\n",
        "\n",
        "I’ve included some sample facts and questions to give these algorithms a go:\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "facts = \" My wife is great. \\\n",
        "My complete name is Roberto Pereira Silveira. \\\n",
        "I am 40 years old. \\\n",
        "My dog is cool. \\\n",
        "My dog breed is jack russel. \\\n",
        "My dog was born in 2014.\\\n",
        "My dog name is Mallu. \\\n",
        "My dog is 5 years old. \\\n",
        "I am an engineer. \\\n",
        "I was born in 1979. \\\n",
        "My e-mail is rsilveira79@gmail.com.\"\n",
        "\n",
        "questions = [\n",
        "    \"What is my complete name?\",\n",
        "    \"What is dog name?\",\n",
        "    \"What is my dog age?\",\n",
        "    \"What is my age?\",\n",
        "    \"What is my dog breed?\",\n",
        "    \"When I was born?\",\n",
        "    \"What is my e-mail?\"\n",
        "]\n",
        "```\n",
        "And here are the results! As you could see I should have trained XLNet a bit more, but it is already returning good results:\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "QUESTION: What is my complete name?\n",
        "  BERT: roberto pereira silveira\n",
        "  XLNET: Roberto Pereira Silveira\n",
        "--------------------------------------------------\n",
        "QUESTION: What is dog name?\n",
        "  BERT: mallu\n",
        "  XLNET: Roberto Pereira Silveira. I am 40 years old. My dog is cool. My dog breed is jack russel. My dog was born in 2014.My dog name is Mallu\n",
        "--------------------------------------------------\n",
        "QUESTION: What is my dog age?\n",
        "  BERT: 5 years old\n",
        "  XLNET: 40 years old\n",
        "--------------------------------------------------\n",
        "QUESTION: What is my age?\n",
        "  BERT: 40\n",
        "  XLNET: 40 years old\n",
        "--------------------------------------------------\n",
        "QUESTION: What is my dog breed?\n",
        "  BERT: jack russel\n",
        "  XLNET: jack russel\n",
        "--------------------------------------------------\n",
        "QUESTION: When I was born?\n",
        "  BERT: 1979\n",
        "  XLNET: 1979\n",
        "--------------------------------------------------\n",
        "QUESTION: What is my e-mail?\n",
        "  BERT: rsilveira79@gmail.com\n",
        "  XLNET: rsilveira79@gmail.com\n",
        "--------------------------------------------------\n",
        "```\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VcqORmI53vrP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "question ='what is check-in time?'\n",
        "context ='CHECK IN/CHECK OUT Check in time is 3:00 p.m. Accommodations before this time cannot be guaranteed. To facilitate the check in process, we suggest that you present a major credit card at the Front Desk upon arrival. A $50.00 deposit will be required at check in for all persons not using a credit card. This fee covers incidental charges that may be accrued. Room reservations will be held until 4:00 p.m. unless the reservation is accompanied by a one night’s deposit or guaranteed with a credit card. Check out time is 12:00 noon. A charge of one full night’s room and tax will be assessed as the Early Departure fee, meaning any guest that checks out before the departure date that was made with the reservation. The following programs were developed to better service the guest: 1-800-CHECK-IN: Allows you to check-in by telephone the day of your arrival. EXPRESS CHECK IN: A self check-in kiosk is conveniently located next to the Front Desk for guests paying by credit card. EXPRESS CHECK OUT: Guests who are utilizing a credit card and are wishing to leave the hotel without stopping by the Front Desk may do so by leaving their keys in their room or dropping them in the express box located at the front desk. VIDEO CHECK OUT: A guest may check out or review their bill from their guest room by simply pressing \"88\" on the television or the green guest services button on the remote control. The bill is prepared at the front desk and may be retrieved shortly after the guest checks out. COAT CHECK Coat check services may be arranged for meetings, conventions or social events. We recommend one attendant per every 150 guests. A hosted coat check has a minimum charge of $100.00 per attendant. Cash on delivery (COD) coat check charges are $1.00 per garment, with a minimum guarantee. Please contact your Catering/Convention Services Manager for details on securing these services. CONCIERGE SERVICES Our concierge staff located in the main lobby at the Bellstand is at your service daily. You may seek assistance from them for dinner or airline reservations. They can also assist you in planning activities around the area, arranging baby-sitting services, along with other services. 11 CREDIT CARDS The following credit cards are accepted for your convenience: American Express Diners Club Discover JCB MasterCard Visa CURRENCY EXCHANGE Foreign currency exchange may be accommodated at the Hotel’s front desk. For currency services not provided by Hyatt Regency we recommend the UMB’s International Department located at 9th and Grand. They can be reached at (816) 860-7000. DANCE FLOOR The hotel has portable dance floor available for your social events. Dance floor pieces are available in 3’x3’ interlocking sections, we also have a few 4’x4’ interlocking sections available. Arrangements for dance floors should be made through your Catering/Convention Services Manager. DIRECTIONS TO HYATT REGENCY CROWN CENTER KCI Airport: Take I-29 south from the airport to U.S. 169 South/Downtown Exit. Take 169 South over the bridge and proceed onto Broadway. Turn left on 20th street. Follow 20th Street to McGee Street and make a right on McGee. The Hyatt is on the left. I-70 East Bound: Follow I-70 East to I-670 East. Continue on I-670 East to I-35 North; then take the Broadway Exit (2A). Follow Broadway to 20th Street and make a left. Follow 20th street to McGee Street and take a right onto McGee. The Hyatt is on the left. I-70 West Bound: Follow I-70 West to the I-35 South Exit. Follow I-35 south to the Broadway Exit (2A). Follow Broadway to 20th Street and make a left. Follow 20th street to McGee Street and take a right onto McGee. The Hyatt is on the left. I-35 South Bound: Follow I-35 south to the Broadway Exit (2A). Follow Broadway to 20th Street and make a left. Follow 20th street to McGee Street and take a right onto McGee. The Hyatt is on the left. I-35 North Bound: Follow I-35 North to the Broadway Exit (2A). Take a right on Broadway. Take a left onto Pershing. Turn left on McGee and the Hyatt is on the right. 12 DIRECTIONS TO HYATT REGENCY CROWN CENTER (CONTINUED) Hwy 71 North Bound: Exit onto 22nd Street and turn left. Take 22nd Street to McGee Street and turn left. The Hyatt is on your left. Hwy 71 South Bound: Follow Hwy 71 south to I-35 South. Follow I-35 south to the Broadway Exit (2A). Follow Broadway to 20th Street and make a left. Follow 20th street to McGee Street and take a right onto McGee. The Hyatt is on the left. ELECTRICAL Capabilities for meeting rooms and ballrooms: Regency Ballroom: 200 and 100 AMP, 208 volt 3-phase, 208 volt single phase and 120 volt spyder box (multiple individual circuits) capability. Pershing Hall: 120 volt, 208 volt single phase and 208 volt 3-phase Empire A: 1 Spyder box B: None (wall outlets only) C: 1 Spyder box Chouteau A: None (wall outlet only) B: 1 Spyder box Van Horn A: None (wall outlets only) B: None (wall outlets only) C: 1 Spyder box Benton A: 1 Spyder box B: None (wall outlets only) Fremont: 1 Spyder box Northrup: 1 Spyder box Executive Boardroom: None (wall outlets only) Electrical requirements must be submitted to your Convention Services Manager before your convention. Drayage companies will provide exhibitors with electrical booth service forms in their exhibitor kits. Electrical forms should be mailed or faxed to the hotel prior to arrival. The Convention Service’s fax line is (816) 398-4931. The current charge for a spyder box is $200.00 per unit/per day. Please ask for a power tie-in estimate and please refer to the booth services agreement form for all other electrical pricing. 13 ENGINEERING SERVICES The Engineering Department is available to provide assistance with all of your mechanical and electrical needs. All electrical needs for meetings must be confirmed with your Convention Services Manager before the convention. The Hotel cannot guarantee availability of electrical resources without advance notice. Please consult your Convention Services Manager for pricing and order forms. Refer to “Electrical” for individual meeting room capabilities. Should you require a lock change for a meeting room, please contact your Catering/Convention Services Manager at least one week in advance. EXHIBIT HALLS Pershing Hall, our 15,360 square feet exhibit hall, can hold approximately (85) 8’x10’ or (75) 10’x10’ exhibit booths. It is located on the lobby level of the hotel. Crown Center Exhibit Hall, a 52,000 square foot exhibit hall is located on the North side of the hotel. It consists of two halls: • Hall A is approximately 37,000 square feet • Hall B is approximately 15,000 square feet There is a 7,000 square foot pre-function space adjacent to both sections of the Center. The ceiling height is approximately 20 feet high with 100 foot adjustable candle lighting. Exhibition Crown Center Halls A and B holds approximately (284) 10’x10’ booths or (324) 8’x10’ booths. It is the responsibility of the group to have the exhibit area clean and clear by the contracted ending date. This includes all trash, boxes, skids and miscellaneous items. This is typically contracted with the Exhibit and Drayage Company. If there is an excess of trash left in the hall, a service charge for disposal will be applied to the Group’s Master Account. The hotel does not provide the use of its ladders or electrical lift for guest or vendor use. For more information on either exhibit hall, please contact your Convention Services Manager. FAX MACHINES The Front Desk can assist you in sending or receiving faxes. The fax number for guests to receive faxes is (816) 435-4190. The secure fax number that credit card authorizations should be sent to is (816) 329-2340. Should you have a fax to send to the Catering/Convention Services department, the fax number is (816) 398-4931.'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d7NwWeQJ32N9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "885d838c-5287-4b91-d9b1-59aade38f0f9"
      },
      "source": [
        "xlnet.get_reply(question,context)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'3:00 p.m'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hq-6NOl9391j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "626338d4-88ed-4e67-c917-5192e17d790f"
      },
      "source": [
        "xlnet.get_reply(\"What is check-out and check-in time?\",context)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'12:00 noon'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "seSiLp_d7G2Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7cdf38be-85c9-4ff2-c330-8da64a6af996"
      },
      "source": [
        "xlnet.get_reply(\"can we check-in early?\",context)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Allows you to check-in by telephone the day of your arrival'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-9WagB0x99e5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}